{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf_qeA1A7JAT",
        "outputId": "19beca4b-8b53-420f-e232-8055b84b9ca8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !pip install plotly\n",
        "# !pip install seaborn\n",
        "# !pip install matplotlib\n",
        "# !pip install transformers\n",
        "# !pip install tokenizers\n",
        "# !pip install scikit-learn\n",
        "# !pip install tensorflow\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install keras_tuner\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQM50iAu7IPf"
      },
      "source": [
        "#\n",
        "<a id=\"data-prep\"></a>\n",
        "<div style=\"background-color: #000D5B; color: white; text-align: center; padding: 6px 0 22px 0\">\n",
        "    <h3 style=\"background-color: #000D5B; color: white; text-align: left\">RMIT School of Computer Science and Technology</h3>\n",
        "    <br/>\n",
        "    <h1>COSC3007: Deep Learning</h1>\n",
        "    <h2>Assignment 2: Stance Twitter Sentiment Analysis and Detection </h2>\n",
        "    <h2> [2] MODELLING AND MODEL EVALUATIONS </h2>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moNIYISM7IPh"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "v3G_-e3j7IPh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enfxab1u7IPi"
      },
      "source": [
        "# [1] Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "bohs2SFF7IPi"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/StanceDataset/processed_train.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_df = train_df.dropna(subset=['processed_tweet'])\n",
        "train_ori = train_df.copy()\n",
        "\n",
        "test_df = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/StanceDataset/processed_test.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtAPp-m17IPi"
      },
      "source": [
        "# [2] Prepare label and fit data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisebO8u7IPi"
      },
      "source": [
        "## Split test and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "pCBu_71Q7IPj"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz2v62Xg7IPj"
      },
      "source": [
        "## Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpUdtQ6y7IPj",
        "outputId": "91a56bbf-3ad8-4b77-db8f-c930393207cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum length across all datasets: 35\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFRobertaModel, RobertaTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "MAX_LENGTH = 512\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "# Assuming train_texts, val_texts, test_texts are your datasets\n",
        "train_processed_tweets = train_df['processed_tweet'].tolist()\n",
        "val_processed_tweets = val_df['processed_tweet'].tolist()\n",
        "test_processed_tweets = test_df['processed_tweet'].tolist()\n",
        "\n",
        "all_processed_tweets = train_processed_tweets + val_processed_tweets + test_processed_tweets\n",
        "tokenized_tweets = [tokenizer.encode(tweet, add_special_tokens=True) for tweet in all_processed_tweets]\n",
        "MAX_LENGTH = max(len(tweet) for tweet in tokenized_tweets)\n",
        "\n",
        "print(\"Maximum length across all datasets:\", MAX_LENGTH)\n",
        "\n",
        "\n",
        "def bert_tokenize(texts, targets, max_length=MAX_LENGTH):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for idx, text in enumerate(texts):\n",
        "        targetID = targets[idx]\n",
        "        target_name = \"\"\n",
        "        if targetID == 0:\n",
        "            target_name = \"Hillary Clinton\"\n",
        "        if targetID == 1:\n",
        "            target_name = \"Legalization of Abortion\"\n",
        "        if targetID == 2:\n",
        "            target_name = \"Atheism\"\n",
        "        if targetID == 3:\n",
        "            target_name = \"Climate Change is a Real Concern\"\n",
        "        if targetID == 4:\n",
        "            target_name = \"Feminist Movement\"\n",
        "        if targetID == 5:\n",
        "            target_name = \"Donald Trump\"\n",
        "        formatted_text = f\"<s> {target_name} </s></s> {text} </s>\"\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            formatted_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf',\n",
        "        )\n",
        "\n",
        "        # Flatten the tensors and remove the extra dimension\n",
        "        input_ids.append(tf.squeeze(encoded['input_ids'], axis=0))\n",
        "        attention_masks.append(tf.squeeze(encoded['attention_mask'], axis=0))\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_masks)\n",
        "\n",
        "# Assuming you have lists of preprocessed texts for training, validation, and test sets\n",
        "train_input_ids, train_attention_masks = bert_tokenize(train_df['processed_tweet'],  train_df['Target'].to_list())\n",
        "val_input_ids, val_attention_masks = bert_tokenize(val_df['processed_tweet'], val_df['Target'].to_list())\n",
        "test_input_ids, test_attention_masks = bert_tokenize(test_df['processed_tweet'], test_df['Target'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELfIUZC7IPk"
      },
      "source": [
        "## Stances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "GizLHQ1j7IPk"
      },
      "outputs": [],
      "source": [
        "def categorized_label(df, label_name):\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(df[label_name])\n",
        "    categorical_labels = to_categorical(encoded_labels)\n",
        "    return categorical_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "moCDHvRP7IPk"
      },
      "outputs": [],
      "source": [
        "train_labels = categorized_label(train_df, \"Stance\")\n",
        "test_labels = categorized_label(test_df, \"Stance\")\n",
        "val_labels = categorized_label(val_df, \"Stance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGuLZ7or7IPk"
      },
      "source": [
        "# [3] Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "uyYbo9A77IPk"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from hyperopt import hp\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "# import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "iuEOWHvi7IPk"
      },
      "outputs": [],
      "source": [
        "def f1_score_class(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    # Convert predictions to one-hot format\n",
        "    y_pred_one_hot = K.one_hot(K.argmax(y_pred), num_classes=3)\n",
        "\n",
        "    # Calculate F1 score for each class\n",
        "    f1s = [f1_score_class(y_true[:, i], y_pred_one_hot[:, i]) for i in range(3)]\n",
        "\n",
        "    # Average F1 scores across all classes\n",
        "    return K.mean(K.stack(f1s), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg1CDkjb7IPk"
      },
      "source": [
        "Set up call backs and learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "FW38TVTK7IPk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "# Define the EarlyStopping and ReduceLROnPlateau callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_path = \"roberta_best_model.h5\"\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,    # Only save a model if 'val_loss' has improved\n",
        "    monitor='val_loss',     # Monitor 'val_loss' during training\n",
        "    mode='min',             # The model is saved when 'val_loss' is minimized\n",
        "    verbose=1)\n",
        "\n",
        "# Combine all callbacks in a list\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "    model_checkpoint_callback\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "Ba5UUffQ7IPl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "# import keras_tuner as kt\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "def build_model(drop, regr, lr):\n",
        "    bert_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    # Define model input (BERT expects two inputs: input_ids and attention_mask)\n",
        "    input_ids = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]  # Use the pooled output here\n",
        "\n",
        "    # Tuning the number of units in the first biLSTM layer\n",
        "    x = Bidirectional(LSTM(units=64,  dropout=drop, recurrent_dropout=drop,return_sequences=True,kernel_regularizer=tf.keras.regularizers.l2(regr))) (bert_output)\n",
        "\n",
        "    # x = Bidirectional(LSTM(units=64,  dropout=drop, recurrent_dropout=drop,return_sequences=True,kernel_regularizer=tf.keras.regularizers.l2(regr))) (x)\n",
        "\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "    # # Dense layer with tunable units\n",
        "    # x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(regr)) (x)\n",
        "\n",
        "    # Tunable dropout rate for the second layer\n",
        "    x = Dropout(drop)(x)\n",
        "\n",
        "    # Final Layer\n",
        "    x = Dense(3, activation='softmax')(x)\n",
        "\n",
        "    # Tuning the learning rate for the optimizer\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "    model = Model(inputs=[input_ids, attention_mask], outputs=x)\n",
        "    model.compile(loss='CategoricalCrossentropy', optimizer=optimizer, metrics=['categorical_accuracy',f1_score])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMYLou_97IPl"
      },
      "source": [
        "Recreate the best model with more training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn9_Rfyp7IPl",
        "outputId": "9a389bf0-ecf7-4c4f-8dbd-8d2396196d59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)      [(None, 35)]                 0         []                            \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer  [(None, 35)]                 0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf_roberta_model_12 (TFRob  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
            " ertaModel)                  ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
            "                             hidden_state=(None, 35, 76                                           \n",
            "                             8),                                                                  \n",
            "                              pooler_output=(None, 768)                                           \n",
            "                             , past_key_values=None, hi                                           \n",
            "                             dden_states=None, attentio                                           \n",
            "                             ns=None, cross_attentions=                                           \n",
            "                             None)                                                                \n",
            "                                                                                                  \n",
            " bidirectional_9 (Bidirecti  (None, 35, 128)              426496    ['tf_roberta_model_12[0][0]'] \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Gl  (None, 128)                  0         ['bidirectional_9[0][0]']     \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " dropout_487 (Dropout)       (None, 128)                  0         ['global_max_pooling1d_1[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_11 (Dense)            (None, 3)                    387       ['dropout_487[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125072515 (477.11 MB)\n",
            "Trainable params: 426883 (1.63 MB)\n",
            "Non-trainable params: 124645632 (475.49 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.6697 - categorical_accuracy: 0.3895 - f1_score: 0.3199\n",
            "Epoch 1: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 53s 464ms/step - loss: 1.6697 - categorical_accuracy: 0.3895 - f1_score: 0.3199 - val_loss: 1.3803 - val_categorical_accuracy: 0.4768 - val_f1_score: 0.2133 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.4205 - categorical_accuracy: 0.4620 - f1_score: 0.3607\n",
            "Epoch 2: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 358ms/step - loss: 1.4205 - categorical_accuracy: 0.4620 - f1_score: 0.3607 - val_loss: 1.3210 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.3344 - categorical_accuracy: 0.4873 - f1_score: 0.3643\n",
            "Epoch 3: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 360ms/step - loss: 1.3344 - categorical_accuracy: 0.4873 - f1_score: 0.3643 - val_loss: 1.2697 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.2739 - categorical_accuracy: 0.5268 - f1_score: 0.3841\n",
            "Epoch 4: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 324ms/step - loss: 1.2739 - categorical_accuracy: 0.5268 - f1_score: 0.3841 - val_loss: 1.2359 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.2410 - categorical_accuracy: 0.5255 - f1_score: 0.3584\n",
            "Epoch 5: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 27s 373ms/step - loss: 1.2410 - categorical_accuracy: 0.5255 - f1_score: 0.3584 - val_loss: 1.2071 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.2138 - categorical_accuracy: 0.5264 - f1_score: 0.3697\n",
            "Epoch 6: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 347ms/step - loss: 1.2138 - categorical_accuracy: 0.5264 - f1_score: 0.3697 - val_loss: 1.1876 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1681 - categorical_accuracy: 0.5474 - f1_score: 0.4007\n",
            "Epoch 7: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 330ms/step - loss: 1.1681 - categorical_accuracy: 0.5474 - f1_score: 0.4007 - val_loss: 1.1667 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1537 - categorical_accuracy: 0.5354 - f1_score: 0.3868\n",
            "Epoch 8: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 350ms/step - loss: 1.1537 - categorical_accuracy: 0.5354 - f1_score: 0.3868 - val_loss: 1.1495 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1361 - categorical_accuracy: 0.5337 - f1_score: 0.3892\n",
            "Epoch 9: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 350ms/step - loss: 1.1361 - categorical_accuracy: 0.5337 - f1_score: 0.3892 - val_loss: 1.1361 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1203 - categorical_accuracy: 0.5384 - f1_score: 0.3951\n",
            "Epoch 10: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 327ms/step - loss: 1.1203 - categorical_accuracy: 0.5384 - f1_score: 0.3951 - val_loss: 1.1147 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.3462 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.1062 - categorical_accuracy: 0.5375 - f1_score: 0.4086\n",
            "Epoch 11: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 353ms/step - loss: 1.1062 - categorical_accuracy: 0.5375 - f1_score: 0.4086 - val_loss: 1.0975 - val_categorical_accuracy: 0.5489 - val_f1_score: 0.3568 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0944 - categorical_accuracy: 0.5577 - f1_score: 0.4354\n",
            "Epoch 12: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 360ms/step - loss: 1.0944 - categorical_accuracy: 0.5577 - f1_score: 0.4354 - val_loss: 1.0804 - val_categorical_accuracy: 0.5472 - val_f1_score: 0.3503 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0800 - categorical_accuracy: 0.5538 - f1_score: 0.4250\n",
            "Epoch 13: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 362ms/step - loss: 1.0800 - categorical_accuracy: 0.5538 - f1_score: 0.4250 - val_loss: 1.0839 - val_categorical_accuracy: 0.5489 - val_f1_score: 0.3805 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0633 - categorical_accuracy: 0.5478 - f1_score: 0.4247\n",
            "Epoch 14: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 338ms/step - loss: 1.0633 - categorical_accuracy: 0.5478 - f1_score: 0.4247 - val_loss: 1.0535 - val_categorical_accuracy: 0.5643 - val_f1_score: 0.4162 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0511 - categorical_accuracy: 0.5684 - f1_score: 0.4763\n",
            "Epoch 15: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 353ms/step - loss: 1.0511 - categorical_accuracy: 0.5684 - f1_score: 0.4763 - val_loss: 1.0546 - val_categorical_accuracy: 0.5557 - val_f1_score: 0.3926 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0413 - categorical_accuracy: 0.5740 - f1_score: 0.4692\n",
            "Epoch 16: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 360ms/step - loss: 1.0413 - categorical_accuracy: 0.5740 - f1_score: 0.4692 - val_loss: 1.0322 - val_categorical_accuracy: 0.5763 - val_f1_score: 0.4614 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0409 - categorical_accuracy: 0.5646 - f1_score: 0.4617\n",
            "Epoch 17: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 323ms/step - loss: 1.0409 - categorical_accuracy: 0.5646 - f1_score: 0.4617 - val_loss: 1.0508 - val_categorical_accuracy: 0.5540 - val_f1_score: 0.3723 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0295 - categorical_accuracy: 0.5847 - f1_score: 0.4804\n",
            "Epoch 18: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 355ms/step - loss: 1.0295 - categorical_accuracy: 0.5847 - f1_score: 0.4804 - val_loss: 1.0454 - val_categorical_accuracy: 0.5609 - val_f1_score: 0.4204 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0252 - categorical_accuracy: 0.5856 - f1_score: 0.4922\n",
            "Epoch 19: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 339ms/step - loss: 1.0252 - categorical_accuracy: 0.5856 - f1_score: 0.4922 - val_loss: 1.0289 - val_categorical_accuracy: 0.5609 - val_f1_score: 0.3989 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0224 - categorical_accuracy: 0.5873 - f1_score: 0.5033\n",
            "Epoch 20: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 23s 321ms/step - loss: 1.0224 - categorical_accuracy: 0.5873 - f1_score: 0.5033 - val_loss: 1.0419 - val_categorical_accuracy: 0.5729 - val_f1_score: 0.4405 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0163 - categorical_accuracy: 0.5899 - f1_score: 0.5015\n",
            "Epoch 21: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 354ms/step - loss: 1.0163 - categorical_accuracy: 0.5899 - f1_score: 0.5015 - val_loss: 1.0244 - val_categorical_accuracy: 0.5746 - val_f1_score: 0.4289 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0041 - categorical_accuracy: 0.6045 - f1_score: 0.5295\n",
            "Epoch 22: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 324ms/step - loss: 1.0041 - categorical_accuracy: 0.6045 - f1_score: 0.5295 - val_loss: 1.0275 - val_categorical_accuracy: 0.5746 - val_f1_score: 0.4489 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0029 - categorical_accuracy: 0.6045 - f1_score: 0.5251\n",
            "Epoch 23: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 342ms/step - loss: 1.0029 - categorical_accuracy: 0.6045 - f1_score: 0.5251 - val_loss: 1.0194 - val_categorical_accuracy: 0.5798 - val_f1_score: 0.4644 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9906 - categorical_accuracy: 0.5873 - f1_score: 0.5022\n",
            "Epoch 24: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 356ms/step - loss: 0.9906 - categorical_accuracy: 0.5873 - f1_score: 0.5022 - val_loss: 1.0143 - val_categorical_accuracy: 0.5832 - val_f1_score: 0.4645 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 1.0021 - categorical_accuracy: 0.5903 - f1_score: 0.5208\n",
            "Epoch 25: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 325ms/step - loss: 1.0021 - categorical_accuracy: 0.5903 - f1_score: 0.5208 - val_loss: 1.0099 - val_categorical_accuracy: 0.5575 - val_f1_score: 0.3838 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9832 - categorical_accuracy: 0.6083 - f1_score: 0.5305\n",
            "Epoch 26: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 350ms/step - loss: 0.9832 - categorical_accuracy: 0.6083 - f1_score: 0.5305 - val_loss: 1.0056 - val_categorical_accuracy: 0.5918 - val_f1_score: 0.4844 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9946 - categorical_accuracy: 0.6023 - f1_score: 0.5192\n",
            "Epoch 27: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 352ms/step - loss: 0.9946 - categorical_accuracy: 0.6023 - f1_score: 0.5192 - val_loss: 1.0241 - val_categorical_accuracy: 0.5506 - val_f1_score: 0.4403 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9937 - categorical_accuracy: 0.5972 - f1_score: 0.5153\n",
            "Epoch 28: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 363ms/step - loss: 0.9937 - categorical_accuracy: 0.5972 - f1_score: 0.5153 - val_loss: 0.9895 - val_categorical_accuracy: 0.6003 - val_f1_score: 0.5039 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9739 - categorical_accuracy: 0.6036 - f1_score: 0.5280\n",
            "Epoch 29: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 332ms/step - loss: 0.9739 - categorical_accuracy: 0.6036 - f1_score: 0.5280 - val_loss: 0.9867 - val_categorical_accuracy: 0.5832 - val_f1_score: 0.4625 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9627 - categorical_accuracy: 0.6148 - f1_score: 0.5425\n",
            "Epoch 30: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 358ms/step - loss: 0.9627 - categorical_accuracy: 0.6148 - f1_score: 0.5425 - val_loss: 0.9783 - val_categorical_accuracy: 0.6038 - val_f1_score: 0.5235 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9797 - categorical_accuracy: 0.6027 - f1_score: 0.5328\n",
            "Epoch 31: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 332ms/step - loss: 0.9797 - categorical_accuracy: 0.6027 - f1_score: 0.5328 - val_loss: 0.9838 - val_categorical_accuracy: 0.5849 - val_f1_score: 0.5200 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9735 - categorical_accuracy: 0.6096 - f1_score: 0.5296\n",
            "Epoch 32: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 362ms/step - loss: 0.9735 - categorical_accuracy: 0.6096 - f1_score: 0.5296 - val_loss: 0.9795 - val_categorical_accuracy: 0.5901 - val_f1_score: 0.5546 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9769 - categorical_accuracy: 0.5963 - f1_score: 0.5273\n",
            "Epoch 33: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 357ms/step - loss: 0.9769 - categorical_accuracy: 0.5963 - f1_score: 0.5273 - val_loss: 0.9743 - val_categorical_accuracy: 0.6021 - val_f1_score: 0.5403 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9540 - categorical_accuracy: 0.6251 - f1_score: 0.5672\n",
            "Epoch 34: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 342ms/step - loss: 0.9540 - categorical_accuracy: 0.6251 - f1_score: 0.5672 - val_loss: 0.9862 - val_categorical_accuracy: 0.6021 - val_f1_score: 0.5480 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9772 - categorical_accuracy: 0.6225 - f1_score: 0.5489\n",
            "Epoch 35: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 23s 318ms/step - loss: 0.9772 - categorical_accuracy: 0.6225 - f1_score: 0.5489 - val_loss: 0.9879 - val_categorical_accuracy: 0.5883 - val_f1_score: 0.5032 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9440 - categorical_accuracy: 0.6289 - f1_score: 0.5662\n",
            "Epoch 36: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 357ms/step - loss: 0.9440 - categorical_accuracy: 0.6289 - f1_score: 0.5662 - val_loss: 0.9668 - val_categorical_accuracy: 0.6106 - val_f1_score: 0.5678 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9590 - categorical_accuracy: 0.6109 - f1_score: 0.5476\n",
            "Epoch 37: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 341ms/step - loss: 0.9590 - categorical_accuracy: 0.6109 - f1_score: 0.5476 - val_loss: 0.9750 - val_categorical_accuracy: 0.5798 - val_f1_score: 0.5225 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9621 - categorical_accuracy: 0.6139 - f1_score: 0.5538\n",
            "Epoch 38: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 325ms/step - loss: 0.9621 - categorical_accuracy: 0.6139 - f1_score: 0.5538 - val_loss: 0.9710 - val_categorical_accuracy: 0.6038 - val_f1_score: 0.5327 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9546 - categorical_accuracy: 0.6152 - f1_score: 0.5456\n",
            "Epoch 39: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 355ms/step - loss: 0.9546 - categorical_accuracy: 0.6152 - f1_score: 0.5456 - val_loss: 0.9718 - val_categorical_accuracy: 0.6038 - val_f1_score: 0.5455 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9546 - categorical_accuracy: 0.6083 - f1_score: 0.5397\n",
            "Epoch 40: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 330ms/step - loss: 0.9546 - categorical_accuracy: 0.6083 - f1_score: 0.5397 - val_loss: 0.9626 - val_categorical_accuracy: 0.6106 - val_f1_score: 0.5543 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9600 - categorical_accuracy: 0.6233 - f1_score: 0.5556\n",
            "Epoch 41: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 337ms/step - loss: 0.9600 - categorical_accuracy: 0.6233 - f1_score: 0.5556 - val_loss: 0.9772 - val_categorical_accuracy: 0.6089 - val_f1_score: 0.5254 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9630 - categorical_accuracy: 0.6186 - f1_score: 0.5429\n",
            "Epoch 42: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 349ms/step - loss: 0.9630 - categorical_accuracy: 0.6186 - f1_score: 0.5429 - val_loss: 0.9869 - val_categorical_accuracy: 0.5952 - val_f1_score: 0.4758 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9520 - categorical_accuracy: 0.6156 - f1_score: 0.5519\n",
            "Epoch 43: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 337ms/step - loss: 0.9520 - categorical_accuracy: 0.6156 - f1_score: 0.5519 - val_loss: 0.9745 - val_categorical_accuracy: 0.5986 - val_f1_score: 0.5382 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9435 - categorical_accuracy: 0.6182 - f1_score: 0.5527\n",
            "Epoch 44: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 346ms/step - loss: 0.9435 - categorical_accuracy: 0.6182 - f1_score: 0.5527 - val_loss: 0.9780 - val_categorical_accuracy: 0.6055 - val_f1_score: 0.5658 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9571 - categorical_accuracy: 0.6195 - f1_score: 0.5456\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 45: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 348ms/step - loss: 0.9571 - categorical_accuracy: 0.6195 - f1_score: 0.5456 - val_loss: 0.9864 - val_categorical_accuracy: 0.6158 - val_f1_score: 0.5719 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9414 - categorical_accuracy: 0.6306 - f1_score: 0.5704\n",
            "Epoch 46: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 23s 321ms/step - loss: 0.9414 - categorical_accuracy: 0.6306 - f1_score: 0.5704 - val_loss: 0.9787 - val_categorical_accuracy: 0.6123 - val_f1_score: 0.5559 - lr: 2.0000e-04\n",
            "Epoch 47/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9338 - categorical_accuracy: 0.6276 - f1_score: 0.5597\n",
            "Epoch 47: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 26s 357ms/step - loss: 0.9338 - categorical_accuracy: 0.6276 - f1_score: 0.5597 - val_loss: 0.9857 - val_categorical_accuracy: 0.5969 - val_f1_score: 0.5613 - lr: 2.0000e-04\n",
            "Epoch 48/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9219 - categorical_accuracy: 0.6422 - f1_score: 0.5910\n",
            "Epoch 48: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 25s 346ms/step - loss: 0.9219 - categorical_accuracy: 0.6422 - f1_score: 0.5910 - val_loss: 0.9772 - val_categorical_accuracy: 0.6003 - val_f1_score: 0.5643 - lr: 2.0000e-04\n",
            "Epoch 49/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9218 - categorical_accuracy: 0.6362 - f1_score: 0.5759\n",
            "Epoch 49: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 24s 327ms/step - loss: 0.9218 - categorical_accuracy: 0.6362 - f1_score: 0.5759 - val_loss: 0.9710 - val_categorical_accuracy: 0.6123 - val_f1_score: 0.5716 - lr: 2.0000e-04\n",
            "Epoch 50/100\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.9341 - categorical_accuracy: 0.6345 - f1_score: 0.5773Restoring model weights from the end of the best epoch: 40.\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\n",
            "Epoch 50: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 27s 365ms/step - loss: 0.9341 - categorical_accuracy: 0.6345 - f1_score: 0.5773 - val_loss: 0.9644 - val_categorical_accuracy: 0.6141 - val_f1_score: 0.5687 - lr: 2.0000e-04\n",
            "Epoch 50: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = {}\n",
        "inital_model = build_model(0.8, 0.0005, 0.001)\n",
        "history['tuned_stance_model_custom'] = inital_model.fit([train_input_ids, train_attention_masks], train_labels,\n",
        "                    epochs=100,\n",
        "                    validation_data=([val_input_ids, val_attention_masks], val_labels),\n",
        "                    batch_size=32,\n",
        "                    callbacks=callbacks,\n",
        "                    shuffle = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p8ahqNJ9JA4",
        "outputId": "185cc0bf-7184-4833-fc2c-cc1fa36e3406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 5s 87ms/step - loss: 1.0199 - categorical_accuracy: 0.5757 - f1_score: 0.3775\n",
            "Test accuracy: [1.0199480056762695, 0.5756646394729614, 0.3775193989276886]\n"
          ]
        }
      ],
      "source": [
        "results = inital_model.evaluate([test_input_ids, test_attention_masks], test_labels)\n",
        "print('Test accuracy:', results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioai3mLD9Pza",
        "outputId": "5f5f5025-5da4-46c6-b1d2-dc877ce79d14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 8s 67ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.68      0.67      1014\n",
            "           1       0.71      0.30      0.42       452\n",
            "           2       0.43      0.61      0.50       490\n",
            "\n",
            "    accuracy                           0.58      1956\n",
            "   macro avg       0.59      0.53      0.53      1956\n",
            "weighted avg       0.61      0.58      0.57      1956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "predictions = inital_model.predict([test_input_ids, test_attention_masks])\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels are one-hot encoded, convert them to class labels\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "0BO_wLOUiGjY"
      },
      "outputs": [],
      "source": [
        "def load_classification_rp_per_target(model):\n",
        "    targets = test_df.Target.unique()\n",
        "    metrics_df = pd.DataFrame()\n",
        "    for target in targets:\n",
        "        extracted_df = test_df[test_df['Target'] == target]\n",
        "        input_ids, attention_masks = bert_tokenize(extracted_df['processed_tweet'], extracted_df['Target'].to_list())\n",
        "        labels = categorized_label(extracted_df, \"Stance\")\n",
        "\n",
        "        # Convert one-hot encoded labels to single integer class labels\n",
        "        true_labels = np.argmax(labels, axis=1)\n",
        "\n",
        "        # Get model predictions\n",
        "        predictions = model.predict([input_ids, attention_masks])\n",
        "\n",
        "        # Convert predictions to class labels\n",
        "        predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Generate a classification report\n",
        "        report = classification_report(true_labels, predicted_labels, target_names=['AGAINST', 'FAVOR', 'NONE'])\n",
        "        target_name = \"\"\n",
        "        if target == 0:\n",
        "            target_name = \"Hillary Clinton\"\n",
        "        if target == 1:\n",
        "            target_name = \"Legalization of Abortion\"\n",
        "        if target == 2:\n",
        "            target_name = \"Atheism\"\n",
        "        if target == 3:\n",
        "            target_name = \"Climate Change is a Real Concern\"\n",
        "        if target == 4:\n",
        "            target_name = \"Feminist Movement\"\n",
        "        if target == 5:\n",
        "            target_name = \"Donald Trump\"\n",
        "\n",
        "        print('Target: ', target_name)\n",
        "        print(report)\n",
        "        print(\"-----------------------------------------\", \"\\n\")\n",
        "\n",
        "        # Flatten the report into a single row and add target name\n",
        "        report = classification_report(true_labels, predicted_labels, target_names=['AGAINST', 'FAVOR', 'NONE'], output_dict=True)\n",
        "\n",
        "        # Extract weighted f1, macro f1, and accuracy\n",
        "        report_data = {\n",
        "            'Target': target_name,\n",
        "            'Weighted F1': report['weighted avg']['f1-score'],\n",
        "            'Macro F1': report['macro avg']['f1-score'],\n",
        "            'Accuracy': report['accuracy']\n",
        "        }\n",
        "\n",
        "        # Append to the DataFrame\n",
        "        metrics_df = metrics_df.append(report_data, ignore_index=True)\n",
        "    metrics_df.set_index('Target', inplace=True)\n",
        "\n",
        "    return metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-UGgHLpivYn",
        "outputId": "454f9014-8a30-4d0f-f57d-7694e5ff1c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 0s 67ms/step\n",
            "Target:  Atheism\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.79      0.88      0.83       160\n",
            "       FAVOR       0.77      0.31      0.44        32\n",
            "        NONE       0.36      0.36      0.36        28\n",
            "\n",
            "    accuracy                           0.73       220\n",
            "   macro avg       0.64      0.52      0.54       220\n",
            "weighted avg       0.73      0.73      0.72       220\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 62ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target:  Climate Change is a Real Concern\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.88      0.80      0.83       123\n",
            "        NONE       0.49      0.80      0.61        35\n",
            "\n",
            "    accuracy                           0.75       169\n",
            "   macro avg       0.46      0.53      0.48       169\n",
            "weighted avg       0.74      0.75      0.73       169\n",
            "\n",
            "----------------------------------------- \n",
            "\n",
            "9/9 [==============================] - 1s 72ms/step\n",
            "Target:  Feminist Movement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.69      0.81      0.74       183\n",
            "       FAVOR       0.23      0.14      0.17        58\n",
            "        NONE       0.58      0.43      0.49        44\n",
            "\n",
            "    accuracy                           0.62       285\n",
            "   macro avg       0.50      0.46      0.47       285\n",
            "weighted avg       0.58      0.62      0.59       285\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 90ms/step\n",
            "Target:  Hillary Clinton\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.61      0.89      0.73       172\n",
            "       FAVOR       0.33      0.02      0.04        45\n",
            "        NONE       0.52      0.28      0.37        78\n",
            "\n",
            "    accuracy                           0.60       295\n",
            "   macro avg       0.49      0.40      0.38       295\n",
            "weighted avg       0.55      0.60      0.53       295\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 94ms/step\n",
            "Target:  Legalization of Abortion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.78      0.69      0.73       189\n",
            "       FAVOR       0.60      0.33      0.42        46\n",
            "        NONE       0.36      0.71      0.48        45\n",
            "\n",
            "    accuracy                           0.63       280\n",
            "   macro avg       0.58      0.58      0.54       280\n",
            "weighted avg       0.68      0.63      0.64       280\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 2s 78ms/step\n",
            "Target:  Donald Trump\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.48      0.39      0.43       299\n",
            "       FAVOR       1.00      0.01      0.03       148\n",
            "        NONE       0.42      0.73      0.53       260\n",
            "\n",
            "    accuracy                           0.44       707\n",
            "   macro avg       0.63      0.38      0.33       707\n",
            "weighted avg       0.56      0.44      0.38       707\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d98339d7-dd1b-4181-917b-a8c6ac01a4a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>0.715089</td>\n",
              "      <td>0.544482</td>\n",
              "      <td>0.731818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>0.733086</td>\n",
              "      <td>0.480913</td>\n",
              "      <td>0.745562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>0.589571</td>\n",
              "      <td>0.470183</td>\n",
              "      <td>0.617544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>0.526086</td>\n",
              "      <td>0.377817</td>\n",
              "      <td>0.596610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>0.639730</td>\n",
              "      <td>0.544692</td>\n",
              "      <td>0.632143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>0.382949</td>\n",
              "      <td>0.329366</td>\n",
              "      <td>0.438472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d98339d7-dd1b-4181-917b-a8c6ac01a4a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d98339d7-dd1b-4181-917b-a8c6ac01a4a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d98339d7-dd1b-4181-917b-a8c6ac01a4a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a4d5765-1cb3-4e8e-86ab-22f010d388df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4d5765-1cb3-4e8e-86ab-22f010d388df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a4d5765-1cb3-4e8e-86ab-22f010d388df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d364f68b-80f6-4c06-9e5d-66126b3ebbca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d364f68b-80f6-4c06-9e5d-66126b3ebbca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                  Weighted F1  Macro F1  Accuracy\n",
              "Target                                                           \n",
              "Atheism                              0.715089  0.544482  0.731818\n",
              "Climate Change is a Real Concern     0.733086  0.480913  0.745562\n",
              "Feminist Movement                    0.589571  0.470183  0.617544\n",
              "Hillary Clinton                      0.526086  0.377817  0.596610\n",
              "Legalization of Abortion             0.639730  0.544692  0.632143\n",
              "Donald Trump                         0.382949  0.329366  0.438472"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use the function to get the metrics DataFrame\n",
        "model_metrics_df = load_classification_rp_per_target(inital_model)\n",
        "model_metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcCRugBtjsz1"
      },
      "source": [
        "[4] Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBRlPb3ljy18",
        "outputId": "762cddf0-671d-45ff-b8d8-30013beed87f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_12/roberta/pooler/dense/kernel:0', 'tf_roberta_model_12/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_12/roberta/pooler/dense/kernel:0', 'tf_roberta_model_12/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "73/73 [==============================] - ETA: 0s - loss: 0.9470 - categorical_accuracy: 0.6345 - f1_score: 0.5731\n",
            "Epoch 1: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 58s 488ms/step - loss: 0.9470 - categorical_accuracy: 0.6345 - f1_score: 0.5731 - val_loss: 0.9378 - val_categorical_accuracy: 0.6158 - val_f1_score: 0.5535 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8468 - categorical_accuracy: 0.6971 - f1_score: 0.6495\n",
            "Epoch 2: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 414ms/step - loss: 0.8468 - categorical_accuracy: 0.6971 - f1_score: 0.6495 - val_loss: 0.9106 - val_categorical_accuracy: 0.6449 - val_f1_score: 0.5918 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.8079 - categorical_accuracy: 0.6993 - f1_score: 0.6592\n",
            "Epoch 3: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 403ms/step - loss: 0.8079 - categorical_accuracy: 0.6993 - f1_score: 0.6592 - val_loss: 0.9077 - val_categorical_accuracy: 0.6449 - val_f1_score: 0.5866 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7465 - categorical_accuracy: 0.7426 - f1_score: 0.7082\n",
            "Epoch 4: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 406ms/step - loss: 0.7465 - categorical_accuracy: 0.7426 - f1_score: 0.7082 - val_loss: 0.9027 - val_categorical_accuracy: 0.6655 - val_f1_score: 0.6126 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.7148 - categorical_accuracy: 0.7495 - f1_score: 0.7197\n",
            "Epoch 5: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 29s 401ms/step - loss: 0.7148 - categorical_accuracy: 0.7495 - f1_score: 0.7197 - val_loss: 0.9217 - val_categorical_accuracy: 0.6844 - val_f1_score: 0.6415 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.6715 - categorical_accuracy: 0.7804 - f1_score: 0.7567\n",
            "Epoch 6: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 409ms/step - loss: 0.6715 - categorical_accuracy: 0.7804 - f1_score: 0.7567 - val_loss: 0.9009 - val_categorical_accuracy: 0.7050 - val_f1_score: 0.6668 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5914 - categorical_accuracy: 0.8160 - f1_score: 0.7985\n",
            "Epoch 7: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 411ms/step - loss: 0.5914 - categorical_accuracy: 0.8160 - f1_score: 0.7985 - val_loss: 0.9121 - val_categorical_accuracy: 0.6878 - val_f1_score: 0.6538 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5353 - categorical_accuracy: 0.8507 - f1_score: 0.8356\n",
            "Epoch 8: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 410ms/step - loss: 0.5353 - categorical_accuracy: 0.8507 - f1_score: 0.8356 - val_loss: 0.9153 - val_categorical_accuracy: 0.6998 - val_f1_score: 0.6557 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.5072 - categorical_accuracy: 0.8644 - f1_score: 0.8477\n",
            "Epoch 9: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 410ms/step - loss: 0.5072 - categorical_accuracy: 0.8644 - f1_score: 0.8477 - val_loss: 0.9537 - val_categorical_accuracy: 0.6741 - val_f1_score: 0.6324 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4604 - categorical_accuracy: 0.8820 - f1_score: 0.8720\n",
            "Epoch 10: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 413ms/step - loss: 0.4604 - categorical_accuracy: 0.8820 - f1_score: 0.8720 - val_loss: 1.0162 - val_categorical_accuracy: 0.6792 - val_f1_score: 0.6364 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.4136 - categorical_accuracy: 0.9091 - f1_score: 0.8992\n",
            "Epoch 11: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 410ms/step - loss: 0.4136 - categorical_accuracy: 0.9091 - f1_score: 0.8992 - val_loss: 1.0811 - val_categorical_accuracy: 0.6741 - val_f1_score: 0.6372 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3880 - categorical_accuracy: 0.9176 - f1_score: 0.9076\n",
            "Epoch 12: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 413ms/step - loss: 0.3880 - categorical_accuracy: 0.9176 - f1_score: 0.9076 - val_loss: 1.0184 - val_categorical_accuracy: 0.6655 - val_f1_score: 0.6321 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3760 - categorical_accuracy: 0.9198 - f1_score: 0.9106\n",
            "Epoch 13: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 412ms/step - loss: 0.3760 - categorical_accuracy: 0.9198 - f1_score: 0.9106 - val_loss: 1.0627 - val_categorical_accuracy: 0.6895 - val_f1_score: 0.6671 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.3289 - categorical_accuracy: 0.9369 - f1_score: 0.9267\n",
            "Epoch 14: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 31s 417ms/step - loss: 0.3289 - categorical_accuracy: 0.9369 - f1_score: 0.9267 - val_loss: 1.0445 - val_categorical_accuracy: 0.7050 - val_f1_score: 0.6671 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.2981 - categorical_accuracy: 0.9571 - f1_score: 0.9533\n",
            "Epoch 15: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 30s 414ms/step - loss: 0.2981 - categorical_accuracy: 0.9571 - f1_score: 0.9533 - val_loss: 1.1430 - val_categorical_accuracy: 0.6792 - val_f1_score: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "73/73 [==============================] - ETA: 0s - loss: 0.2743 - categorical_accuracy: 0.9614 - f1_score: 0.9569Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "Epoch 16: saving model to roberta_best_model.h5\n",
            "73/73 [==============================] - 31s 421ms/step - loss: 0.2743 - categorical_accuracy: 0.9614 - f1_score: 0.9569 - val_loss: 1.1969 - val_categorical_accuracy: 0.6775 - val_f1_score: 0.6493 - lr: 1.0000e-05\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ],
      "source": [
        "for layer in inital_model.layers:\n",
        "    layer.trainable = True\n",
        "   # Tuning the learning rate for the optimizer\n",
        "inital_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['categorical_accuracy', f1_score])\n",
        "\n",
        "history['fine_tuned_bert'] = inital_model.fit([train_input_ids, train_attention_masks], train_labels,\n",
        "                    epochs=30,\n",
        "                    validation_data=([val_input_ids, val_attention_masks], val_labels),\n",
        "                    batch_size=32,\n",
        "                    callbacks=callbacks,\n",
        "                    shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WAOA3PAJoSuU",
        "outputId": "71f63028-2848-430f-961e-385269c52f90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 4s 66ms/step\n",
            "Target:  Atheism\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.87      0.80      0.83       160\n",
            "       FAVOR       0.45      0.47      0.46        32\n",
            "        NONE       0.40      0.57      0.47        28\n",
            "\n",
            "    accuracy                           0.72       220\n",
            "   macro avg       0.58      0.61      0.59       220\n",
            "weighted avg       0.75      0.72      0.73       220\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 64ms/step\n",
            "Target:  Climate Change is a Real Concern\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.87      0.89      0.88       123\n",
            "        NONE       0.65      0.74      0.69        35\n",
            "\n",
            "    accuracy                           0.80       169\n",
            "   macro avg       0.51      0.54      0.52       169\n",
            "weighted avg       0.76      0.80      0.78       169\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 67ms/step\n",
            "Target:  Feminist Movement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.65      0.70       183\n",
            "       FAVOR       0.31      0.38      0.34        58\n",
            "        NONE       0.51      0.66      0.57        44\n",
            "\n",
            "    accuracy                           0.60       285\n",
            "   macro avg       0.53      0.56      0.54       285\n",
            "weighted avg       0.63      0.60      0.61       285\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 65ms/step\n",
            "Target:  Hillary Clinton\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.83      0.74       172\n",
            "       FAVOR       0.45      0.20      0.28        45\n",
            "        NONE       0.54      0.45      0.49        78\n",
            "\n",
            "    accuracy                           0.63       295\n",
            "   macro avg       0.55      0.49      0.50       295\n",
            "weighted avg       0.61      0.63      0.61       295\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 66ms/step\n",
            "Target:  Legalization of Abortion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.84      0.71      0.77       189\n",
            "       FAVOR       0.54      0.48      0.51        46\n",
            "        NONE       0.43      0.76      0.55        45\n",
            "\n",
            "    accuracy                           0.68       280\n",
            "   macro avg       0.60      0.65      0.61       280\n",
            "weighted avg       0.72      0.68      0.69       280\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/23 [==============================] - 2s 66ms/step\n",
            "Target:  Donald Trump\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.49      0.43      0.46       299\n",
            "       FAVOR       0.51      0.13      0.21       148\n",
            "        NONE       0.45      0.69      0.54       260\n",
            "\n",
            "    accuracy                           0.47       707\n",
            "   macro avg       0.48      0.42      0.40       707\n",
            "weighted avg       0.48      0.47      0.44       707\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-112-7822421f7f5a>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cb228dbc-638f-48ea-8dab-3b1c43cf309b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>0.733481</td>\n",
              "      <td>0.588668</td>\n",
              "      <td>0.722727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>0.780789</td>\n",
              "      <td>0.522945</td>\n",
              "      <td>0.798817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>0.608337</td>\n",
              "      <td>0.538261</td>\n",
              "      <td>0.596491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>0.605145</td>\n",
              "      <td>0.503296</td>\n",
              "      <td>0.630508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>0.689559</td>\n",
              "      <td>0.607348</td>\n",
              "      <td>0.678571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>0.436997</td>\n",
              "      <td>0.402584</td>\n",
              "      <td>0.465347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb228dbc-638f-48ea-8dab-3b1c43cf309b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cb228dbc-638f-48ea-8dab-3b1c43cf309b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cb228dbc-638f-48ea-8dab-3b1c43cf309b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7b48c0b1-131a-427e-a2d8-f2141baf2432\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b48c0b1-131a-427e-a2d8-f2141baf2432')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7b48c0b1-131a-427e-a2d8-f2141baf2432 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_98aa09bf-0c15-4962-a821-ee82aee19f37\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_98aa09bf-0c15-4962-a821-ee82aee19f37 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                  Weighted F1  Macro F1  Accuracy\n",
              "Target                                                           \n",
              "Atheism                              0.733481  0.588668  0.722727\n",
              "Climate Change is a Real Concern     0.780789  0.522945  0.798817\n",
              "Feminist Movement                    0.608337  0.538261  0.596491\n",
              "Hillary Clinton                      0.605145  0.503296  0.630508\n",
              "Legalization of Abortion             0.689559  0.607348  0.678571\n",
              "Donald Trump                         0.436997  0.402584  0.465347"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use the function to get the metrics DataFrame\n",
        "model_metrics_df = load_classification_rp_per_target(inital_model)\n",
        "model_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YRDLteVolOe",
        "outputId": "12503a55-101b-4815-d146-e2526da5965e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/62 [==============================] - 5s 79ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.64      0.67      1014\n",
            "           1       0.60      0.43      0.50       452\n",
            "           2       0.47      0.65      0.54       490\n",
            "\n",
            "    accuracy                           0.60      1956\n",
            "   macro avg       0.59      0.58      0.57      1956\n",
            "weighted avg       0.61      0.60      0.60      1956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "predictions = inital_model.predict([test_input_ids, test_attention_masks])\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels are one-hot encoded, convert them to class labels\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byHt9y_SpOCY",
        "outputId": "0fec8096-400c-4d12-b947-7a7c3612b870"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "inital_model.save('roberta_model_2.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
