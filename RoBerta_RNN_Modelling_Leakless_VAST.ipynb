{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zf_qeA1A7JAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e5c156-996d-4698-bb17-b7db85d413bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# !pip install plotly\n",
        "# !pip install seaborn\n",
        "# !pip install matplotlib\n",
        "# !pip install transformers\n",
        "# !pip install tokenizers\n",
        "# !pip install scikit-learn\n",
        "# !pip install tensorflow\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install keras_tuner\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQM50iAu7IPf"
      },
      "source": [
        "#\n",
        "<a id=\"data-prep\"></a>\n",
        "<div style=\"background-color: #000D5B; color: white; text-align: center; padding: 6px 0 22px 0\">\n",
        "    <h3 style=\"background-color: #000D5B; color: white; text-align: left\">RMIT School of Computer Science and Technology</h3>\n",
        "    <br/>\n",
        "    <h1>COSC3007: Deep Learning</h1>\n",
        "    <h2>Assignment 2: Stance Twitter Sentiment Analysis and Detection </h2>\n",
        "    <h2> [2] MODELLING AND MODEL EVALUATIONS </h2>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moNIYISM7IPh"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v3G_-e3j7IPh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enfxab1u7IPi"
      },
      "source": [
        "# [1] Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bohs2SFF7IPi"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/StanceDataset/processed_train_augumented_vast.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_ori = train_df.copy()\n",
        "\n",
        "test_df = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/StanceDataset/processed_test_augumented_vast.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaP0MCGJ3ij",
        "outputId": "29626b79-2465-4a26-9049-fa8ffc47f435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16391\n",
            "1956\n"
          ]
        }
      ],
      "source": [
        "print(len(train_ori))\n",
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtAPp-m17IPi"
      },
      "source": [
        "# [2] Prepare label and fit data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisebO8u7IPi"
      },
      "source": [
        "## Split test and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pCBu_71Q7IPj"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['Stance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz2v62Xg7IPj"
      },
      "source": [
        "## Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpUdtQ6y7IPj",
        "outputId": "d692b42b-2edd-494b-bf7f-388219b4f285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length across all datasets: 128\n",
            "(13112, 128)\n",
            "(3279, 128)\n",
            "(1956, 128)\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFRobertaModel, RobertaTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "MAX_LENGTH = 512\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "# Assuming train_texts, val_texts, test_texts are your datasets\n",
        "train_processed_tweets = train_df['Tweet'].tolist()\n",
        "val_processed_tweets = val_df['Tweet'].tolist()\n",
        "test_processed_tweets = test_df['Tweet'].tolist()\n",
        "\n",
        "all_processed_tweets = train_processed_tweets + val_processed_tweets + test_processed_tweets\n",
        "tokenized_tweets = [tokenizer.encode(tweet, add_special_tokens=True) for tweet in all_processed_tweets]\n",
        "MAX_LENGTH = max(len(tweet) for tweet in tokenized_tweets)\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "print(\"Maximum length across all datasets:\", MAX_LENGTH)\n",
        "\n",
        "target_names = {\n",
        "    0: \"Hillary Clinton\",\n",
        "    1: \"Legalization of Abortion\",\n",
        "    2: \"Atheism\",\n",
        "    3: \"Climate Change is a Real Concern\",\n",
        "    4: \"Feminist Movement\",\n",
        "    5: \"Donald Trump\",\n",
        "    6: \"Joe Biden\",\n",
        "    7: \"Barack Obama\",\n",
        "    8: \"Kamala Harris\",\n",
        "    9: \"Bernie Sanders\",\n",
        "    10: \"Vu\",\n",
        "}\n",
        "\n",
        "def bert_tokenize(texts, targets, max_length=MAX_LENGTH):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for idx, text in enumerate(texts):\n",
        "        target_name = targets[idx]\n",
        "        # target_name = target_names.get(targetID, \"\")\n",
        "        formatted_text = f\"<s> {target_name} </s></s> {text} </s>\"\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            formatted_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf',\n",
        "        )\n",
        "\n",
        "        # Flatten the tensors and remove the extra dimension\n",
        "        input_ids.append(tf.squeeze(encoded['input_ids'], axis=0))\n",
        "        attention_masks.append(tf.squeeze(encoded['attention_mask'], axis=0))\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_masks)\n",
        "\n",
        "# Assuming you have lists of preprocessed texts for training, validation, and test sets\n",
        "train_input_ids, train_attention_masks = bert_tokenize(train_df['Tweet'],  train_df['Target'].to_list())\n",
        "val_input_ids, val_attention_masks = bert_tokenize(val_df['Tweet'], val_df['Target'].to_list())\n",
        "test_input_ids, test_attention_masks = bert_tokenize(test_df['Tweet'], test_df['Target'].to_list())\n",
        "\n",
        "print(train_input_ids.shape)\n",
        "print(val_input_ids.shape)\n",
        "print(test_input_ids.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELfIUZC7IPk"
      },
      "source": [
        "## Stances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GizLHQ1j7IPk"
      },
      "outputs": [],
      "source": [
        "def categorized_label(df, label_name):\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(df[label_name])\n",
        "    categorical_labels = to_categorical(encoded_labels)\n",
        "    return categorical_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "moCDHvRP7IPk"
      },
      "outputs": [],
      "source": [
        "train_labels = categorized_label(train_df, \"Stance\")\n",
        "test_labels = categorized_label(test_df, \"Stance\")\n",
        "val_labels = categorized_label(val_df, \"Stance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGuLZ7or7IPk"
      },
      "source": [
        "# [3] Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uyYbo9A77IPk"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from hyperopt import hp\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "# import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iuEOWHvi7IPk"
      },
      "outputs": [],
      "source": [
        "def f1_score_class(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    # Convert predictions to one-hot format\n",
        "    y_pred_one_hot = K.one_hot(K.argmax(y_pred), num_classes=3)\n",
        "\n",
        "    # Calculate F1 score for each class\n",
        "    f1s = [f1_score_class(y_true[:, i], y_pred_one_hot[:, i]) for i in range(3)]\n",
        "\n",
        "    # Average F1 scores across all classes\n",
        "    return K.mean(K.stack(f1s), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg1CDkjb7IPk"
      },
      "source": [
        "Set up call backs and learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FW38TVTK7IPk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "# Define the EarlyStopping and ReduceLROnPlateau callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_path = \"roberta_best_model.h5\"\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,    # Only save a model if 'val_loss' has improved\n",
        "    monitor='val_loss',     # Monitor 'val_loss' during training\n",
        "    mode='min',             # The model is saved when 'val_loss' is minimized\n",
        "    verbose=1)\n",
        "\n",
        "# Combine all callbacks in a list\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "    model_checkpoint_callback\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ba5UUffQ7IPl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "# import keras_tuner as kt\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "def build_model(drop, regr, lr):\n",
        "    bert_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    # Define model input (BERT expects two inputs: input_ids and attention_mask)\n",
        "    input_ids = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]  # Use the pooled output here\n",
        "\n",
        "    # Tuning the number of units in the first biLSTM layer\n",
        "    x = Bidirectional(LSTM(units=64,  dropout=drop, recurrent_dropout=drop,return_sequences=True,kernel_regularizer=tf.keras.regularizers.l2(regr))) (bert_output)\n",
        "\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "    # Dense layer with tunable units\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(regr)) (x)\n",
        "\n",
        "    # Tunable dropout rate for the second layer\n",
        "    x = Dropout(drop)(x)\n",
        "\n",
        "    # Final Layer\n",
        "    x = Dense(3, activation='softmax')(x)\n",
        "\n",
        "    # Tuning the learning rate for the optimizer\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "    model = Model(inputs=[input_ids, attention_mask], outputs=x)\n",
        "    model.compile(loss='CategoricalCrossentropy', optimizer=optimizer, metrics=['categorical_accuracy',f1_score])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMYLou_97IPl"
      },
      "source": [
        "Recreate the best model with more training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn9_Rfyp7IPl",
        "outputId": "cab8fbb2-28a4-468c-8881-d083f6df2bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.embeddings.position_ids', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer  [(None, 128)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobe  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
            " rtaModel)                   ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
            "                             hidden_state=(None, 128, 7                                           \n",
            "                             68),                                                                 \n",
            "                              pooler_output=(None, 768)                                           \n",
            "                             , past_key_values=None, hi                                           \n",
            "                             dden_states=None, attentio                                           \n",
            "                             ns=None, cross_attentions=                                           \n",
            "                             None)                                                                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 128, 128)             426496    ['tf_roberta_model_1[0][0]']  \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 128)                  0         ['bidirectional[0][0]']       \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  16512     ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dropout_74 (Dropout)        (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3)                    387       ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125089027 (477.18 MB)\n",
            "Trainable params: 443395 (1.69 MB)\n",
            "Non-trainable params: 124645632 (475.49 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.5406 - categorical_accuracy: 0.3994 - f1_score: 0.2969\n",
            "Epoch 1: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 83s 1s/step - loss: 1.5406 - categorical_accuracy: 0.3994 - f1_score: 0.2969 - val_loss: 1.4239 - val_categorical_accuracy: 0.4239 - val_f1_score: 0.2003 - lr: 0.0010\n",
            "Epoch 2/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.3501 - categorical_accuracy: 0.4244 - f1_score: 0.2835\n",
            "Epoch 2: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.3501 - categorical_accuracy: 0.4244 - f1_score: 0.2835 - val_loss: 1.3185 - val_categorical_accuracy: 0.4263 - val_f1_score: 0.1985 - lr: 0.0010\n",
            "Epoch 3/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.2661 - categorical_accuracy: 0.4365 - f1_score: 0.2915\n",
            "Epoch 3: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.2661 - categorical_accuracy: 0.4365 - f1_score: 0.2915 - val_loss: 1.2435 - val_categorical_accuracy: 0.4446 - val_f1_score: 0.2438 - lr: 0.0010\n",
            "Epoch 4/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.2091 - categorical_accuracy: 0.4459 - f1_score: 0.3165\n",
            "Epoch 4: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.2091 - categorical_accuracy: 0.4459 - f1_score: 0.3165 - val_loss: 1.1904 - val_categorical_accuracy: 0.4819 - val_f1_score: 0.3268 - lr: 0.0010\n",
            "Epoch 5/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.1720 - categorical_accuracy: 0.4520 - f1_score: 0.3256\n",
            "Epoch 5: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.1720 - categorical_accuracy: 0.4520 - f1_score: 0.3256 - val_loss: 1.1722 - val_categorical_accuracy: 0.4364 - val_f1_score: 0.2255 - lr: 0.0010\n",
            "Epoch 6/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.1384 - categorical_accuracy: 0.4680 - f1_score: 0.3316\n",
            "Epoch 6: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.1384 - categorical_accuracy: 0.4680 - f1_score: 0.3316 - val_loss: 1.1416 - val_categorical_accuracy: 0.4834 - val_f1_score: 0.3208 - lr: 0.0010\n",
            "Epoch 7/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.1088 - categorical_accuracy: 0.4858 - f1_score: 0.3515\n",
            "Epoch 7: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.1088 - categorical_accuracy: 0.4858 - f1_score: 0.3515 - val_loss: 1.1042 - val_categorical_accuracy: 0.4873 - val_f1_score: 0.3191 - lr: 0.0010\n",
            "Epoch 8/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0810 - categorical_accuracy: 0.4969 - f1_score: 0.3710\n",
            "Epoch 8: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0810 - categorical_accuracy: 0.4969 - f1_score: 0.3710 - val_loss: 1.0563 - val_categorical_accuracy: 0.5249 - val_f1_score: 0.3824 - lr: 0.0010\n",
            "Epoch 9/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0559 - categorical_accuracy: 0.5065 - f1_score: 0.4044\n",
            "Epoch 9: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0559 - categorical_accuracy: 0.5065 - f1_score: 0.4044 - val_loss: 1.0383 - val_categorical_accuracy: 0.5422 - val_f1_score: 0.4743 - lr: 0.0010\n",
            "Epoch 10/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0387 - categorical_accuracy: 0.5168 - f1_score: 0.4386\n",
            "Epoch 10: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0387 - categorical_accuracy: 0.5168 - f1_score: 0.4386 - val_loss: 1.0419 - val_categorical_accuracy: 0.4846 - val_f1_score: 0.3558 - lr: 0.0010\n",
            "Epoch 11/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0310 - categorical_accuracy: 0.5239 - f1_score: 0.4570\n",
            "Epoch 11: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0310 - categorical_accuracy: 0.5239 - f1_score: 0.4570 - val_loss: 0.9991 - val_categorical_accuracy: 0.5694 - val_f1_score: 0.5297 - lr: 0.0010\n",
            "Epoch 12/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0146 - categorical_accuracy: 0.5264 - f1_score: 0.4722\n",
            "Epoch 12: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0146 - categorical_accuracy: 0.5264 - f1_score: 0.4722 - val_loss: 0.9843 - val_categorical_accuracy: 0.5855 - val_f1_score: 0.5604 - lr: 0.0010\n",
            "Epoch 13/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0148 - categorical_accuracy: 0.5380 - f1_score: 0.4867\n",
            "Epoch 13: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0148 - categorical_accuracy: 0.5380 - f1_score: 0.4867 - val_loss: 0.9775 - val_categorical_accuracy: 0.5758 - val_f1_score: 0.5574 - lr: 0.0010\n",
            "Epoch 14/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 1.0002 - categorical_accuracy: 0.5468 - f1_score: 0.4991\n",
            "Epoch 14: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 1.0002 - categorical_accuracy: 0.5468 - f1_score: 0.4991 - val_loss: 0.9665 - val_categorical_accuracy: 0.5886 - val_f1_score: 0.5618 - lr: 0.0010\n",
            "Epoch 15/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9964 - categorical_accuracy: 0.5490 - f1_score: 0.5009\n",
            "Epoch 15: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9964 - categorical_accuracy: 0.5490 - f1_score: 0.5009 - val_loss: 0.9692 - val_categorical_accuracy: 0.5865 - val_f1_score: 0.5765 - lr: 0.0010\n",
            "Epoch 16/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9908 - categorical_accuracy: 0.5487 - f1_score: 0.5058\n",
            "Epoch 16: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9908 - categorical_accuracy: 0.5487 - f1_score: 0.5058 - val_loss: 0.9639 - val_categorical_accuracy: 0.5825 - val_f1_score: 0.5730 - lr: 0.0010\n",
            "Epoch 17/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9829 - categorical_accuracy: 0.5577 - f1_score: 0.5204\n",
            "Epoch 17: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9829 - categorical_accuracy: 0.5577 - f1_score: 0.5204 - val_loss: 0.9669 - val_categorical_accuracy: 0.5852 - val_f1_score: 0.5654 - lr: 0.0010\n",
            "Epoch 18/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9868 - categorical_accuracy: 0.5510 - f1_score: 0.5121\n",
            "Epoch 18: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9868 - categorical_accuracy: 0.5510 - f1_score: 0.5121 - val_loss: 0.9636 - val_categorical_accuracy: 0.5715 - val_f1_score: 0.5459 - lr: 0.0010\n",
            "Epoch 19/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9756 - categorical_accuracy: 0.5587 - f1_score: 0.5266\n",
            "Epoch 19: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9756 - categorical_accuracy: 0.5587 - f1_score: 0.5266 - val_loss: 0.9641 - val_categorical_accuracy: 0.5788 - val_f1_score: 0.5635 - lr: 0.0010\n",
            "Epoch 20/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9716 - categorical_accuracy: 0.5615 - f1_score: 0.5271\n",
            "Epoch 20: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9716 - categorical_accuracy: 0.5615 - f1_score: 0.5271 - val_loss: 0.9407 - val_categorical_accuracy: 0.5858 - val_f1_score: 0.5772 - lr: 0.0010\n",
            "Epoch 21/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9667 - categorical_accuracy: 0.5697 - f1_score: 0.5367\n",
            "Epoch 21: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9667 - categorical_accuracy: 0.5697 - f1_score: 0.5367 - val_loss: 0.9251 - val_categorical_accuracy: 0.5938 - val_f1_score: 0.5791 - lr: 0.0010\n",
            "Epoch 22/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9599 - categorical_accuracy: 0.5733 - f1_score: 0.5412\n",
            "Epoch 22: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9599 - categorical_accuracy: 0.5733 - f1_score: 0.5412 - val_loss: 0.9271 - val_categorical_accuracy: 0.5953 - val_f1_score: 0.5775 - lr: 0.0010\n",
            "Epoch 23/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9589 - categorical_accuracy: 0.5755 - f1_score: 0.5480\n",
            "Epoch 23: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9589 - categorical_accuracy: 0.5755 - f1_score: 0.5480 - val_loss: 0.9135 - val_categorical_accuracy: 0.6066 - val_f1_score: 0.5929 - lr: 0.0010\n",
            "Epoch 24/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9585 - categorical_accuracy: 0.5697 - f1_score: 0.5346\n",
            "Epoch 24: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9585 - categorical_accuracy: 0.5697 - f1_score: 0.5346 - val_loss: 0.9236 - val_categorical_accuracy: 0.5828 - val_f1_score: 0.5737 - lr: 0.0010\n",
            "Epoch 25/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9503 - categorical_accuracy: 0.5741 - f1_score: 0.5431\n",
            "Epoch 25: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9503 - categorical_accuracy: 0.5741 - f1_score: 0.5431 - val_loss: 0.9363 - val_categorical_accuracy: 0.5740 - val_f1_score: 0.5600 - lr: 0.0010\n",
            "Epoch 26/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9488 - categorical_accuracy: 0.5761 - f1_score: 0.5512\n",
            "Epoch 26: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9488 - categorical_accuracy: 0.5761 - f1_score: 0.5512 - val_loss: 0.9385 - val_categorical_accuracy: 0.5779 - val_f1_score: 0.5645 - lr: 0.0010\n",
            "Epoch 27/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9479 - categorical_accuracy: 0.5831 - f1_score: 0.5521\n",
            "Epoch 27: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9479 - categorical_accuracy: 0.5831 - f1_score: 0.5521 - val_loss: 0.9251 - val_categorical_accuracy: 0.5877 - val_f1_score: 0.5786 - lr: 0.0010\n",
            "Epoch 28/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9340 - categorical_accuracy: 0.5889 - f1_score: 0.5631\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 28: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9340 - categorical_accuracy: 0.5889 - f1_score: 0.5631 - val_loss: 0.9203 - val_categorical_accuracy: 0.5858 - val_f1_score: 0.5620 - lr: 0.0010\n",
            "Epoch 29/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9265 - categorical_accuracy: 0.5944 - f1_score: 0.5709\n",
            "Epoch 29: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9265 - categorical_accuracy: 0.5944 - f1_score: 0.5709 - val_loss: 0.8914 - val_categorical_accuracy: 0.6005 - val_f1_score: 0.5906 - lr: 2.0000e-04\n",
            "Epoch 30/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9246 - categorical_accuracy: 0.5933 - f1_score: 0.5711\n",
            "Epoch 30: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9246 - categorical_accuracy: 0.5933 - f1_score: 0.5711 - val_loss: 0.8947 - val_categorical_accuracy: 0.5959 - val_f1_score: 0.5837 - lr: 2.0000e-04\n",
            "Epoch 31/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9197 - categorical_accuracy: 0.5988 - f1_score: 0.5755\n",
            "Epoch 31: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9197 - categorical_accuracy: 0.5988 - f1_score: 0.5755 - val_loss: 0.9030 - val_categorical_accuracy: 0.5968 - val_f1_score: 0.5809 - lr: 2.0000e-04\n",
            "Epoch 32/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9142 - categorical_accuracy: 0.5965 - f1_score: 0.5762\n",
            "Epoch 32: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9142 - categorical_accuracy: 0.5965 - f1_score: 0.5762 - val_loss: 0.8851 - val_categorical_accuracy: 0.6054 - val_f1_score: 0.5893 - lr: 2.0000e-04\n",
            "Epoch 33/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9093 - categorical_accuracy: 0.6030 - f1_score: 0.5822\n",
            "Epoch 33: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9093 - categorical_accuracy: 0.6030 - f1_score: 0.5822 - val_loss: 0.8888 - val_categorical_accuracy: 0.6020 - val_f1_score: 0.5832 - lr: 2.0000e-04\n",
            "Epoch 34/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9077 - categorical_accuracy: 0.6009 - f1_score: 0.5798\n",
            "Epoch 34: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9077 - categorical_accuracy: 0.6009 - f1_score: 0.5798 - val_loss: 0.8815 - val_categorical_accuracy: 0.6069 - val_f1_score: 0.5934 - lr: 2.0000e-04\n",
            "Epoch 35/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9105 - categorical_accuracy: 0.5951 - f1_score: 0.5710\n",
            "Epoch 35: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9105 - categorical_accuracy: 0.5951 - f1_score: 0.5710 - val_loss: 0.8934 - val_categorical_accuracy: 0.6002 - val_f1_score: 0.5791 - lr: 2.0000e-04\n",
            "Epoch 36/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9107 - categorical_accuracy: 0.6043 - f1_score: 0.5822\n",
            "Epoch 36: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9107 - categorical_accuracy: 0.6043 - f1_score: 0.5822 - val_loss: 0.8796 - val_categorical_accuracy: 0.6118 - val_f1_score: 0.5970 - lr: 2.0000e-04\n",
            "Epoch 37/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9115 - categorical_accuracy: 0.5988 - f1_score: 0.5773\n",
            "Epoch 37: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.9115 - categorical_accuracy: 0.5988 - f1_score: 0.5773 - val_loss: 0.8826 - val_categorical_accuracy: 0.6121 - val_f1_score: 0.5939 - lr: 2.0000e-04\n",
            "Epoch 38/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9026 - categorical_accuracy: 0.6019 - f1_score: 0.5819\n",
            "Epoch 38: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9026 - categorical_accuracy: 0.6019 - f1_score: 0.5819 - val_loss: 0.8692 - val_categorical_accuracy: 0.6212 - val_f1_score: 0.6056 - lr: 2.0000e-04\n",
            "Epoch 39/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8996 - categorical_accuracy: 0.6059 - f1_score: 0.5859\n",
            "Epoch 39: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.8996 - categorical_accuracy: 0.6059 - f1_score: 0.5859 - val_loss: 0.8729 - val_categorical_accuracy: 0.6145 - val_f1_score: 0.6023 - lr: 2.0000e-04\n",
            "Epoch 40/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8953 - categorical_accuracy: 0.6094 - f1_score: 0.5907\n",
            "Epoch 40: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.8953 - categorical_accuracy: 0.6094 - f1_score: 0.5907 - val_loss: 0.8590 - val_categorical_accuracy: 0.6243 - val_f1_score: 0.6112 - lr: 2.0000e-04\n",
            "Epoch 41/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.9036 - categorical_accuracy: 0.6019 - f1_score: 0.5795\n",
            "Epoch 41: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.9036 - categorical_accuracy: 0.6019 - f1_score: 0.5795 - val_loss: 0.8694 - val_categorical_accuracy: 0.6112 - val_f1_score: 0.5993 - lr: 2.0000e-04\n",
            "Epoch 42/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8970 - categorical_accuracy: 0.6025 - f1_score: 0.5821\n",
            "Epoch 42: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.8970 - categorical_accuracy: 0.6025 - f1_score: 0.5821 - val_loss: 0.8639 - val_categorical_accuracy: 0.6188 - val_f1_score: 0.6043 - lr: 2.0000e-04\n",
            "Epoch 43/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8995 - categorical_accuracy: 0.6097 - f1_score: 0.5900\n",
            "Epoch 43: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.8995 - categorical_accuracy: 0.6097 - f1_score: 0.5900 - val_loss: 0.8650 - val_categorical_accuracy: 0.6127 - val_f1_score: 0.5981 - lr: 2.0000e-04\n",
            "Epoch 44/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8892 - categorical_accuracy: 0.6101 - f1_score: 0.5873\n",
            "Epoch 44: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.8892 - categorical_accuracy: 0.6101 - f1_score: 0.5873 - val_loss: 0.8723 - val_categorical_accuracy: 0.6048 - val_f1_score: 0.5854 - lr: 2.0000e-04\n",
            "Epoch 45/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8936 - categorical_accuracy: 0.6094 - f1_score: 0.5902\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\n",
            "Epoch 45: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.8936 - categorical_accuracy: 0.6094 - f1_score: 0.5902 - val_loss: 0.8661 - val_categorical_accuracy: 0.6102 - val_f1_score: 0.5935 - lr: 2.0000e-04\n",
            "Epoch 46/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8880 - categorical_accuracy: 0.6111 - f1_score: 0.5925\n",
            "Epoch 46: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.8880 - categorical_accuracy: 0.6111 - f1_score: 0.5925 - val_loss: 0.8622 - val_categorical_accuracy: 0.6130 - val_f1_score: 0.5977 - lr: 4.0000e-05\n",
            "Epoch 47/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8917 - categorical_accuracy: 0.6132 - f1_score: 0.5931\n",
            "Epoch 47: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.8917 - categorical_accuracy: 0.6132 - f1_score: 0.5931 - val_loss: 0.8647 - val_categorical_accuracy: 0.6087 - val_f1_score: 0.5924 - lr: 4.0000e-05\n",
            "Epoch 48/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8832 - categorical_accuracy: 0.6136 - f1_score: 0.5920\n",
            "Epoch 48: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 59s 1s/step - loss: 0.8832 - categorical_accuracy: 0.6136 - f1_score: 0.5920 - val_loss: 0.8606 - val_categorical_accuracy: 0.6136 - val_f1_score: 0.5996 - lr: 4.0000e-05\n",
            "Epoch 49/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8851 - categorical_accuracy: 0.6130 - f1_score: 0.5942\n",
            "Epoch 49: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.8851 - categorical_accuracy: 0.6130 - f1_score: 0.5942 - val_loss: 0.8623 - val_categorical_accuracy: 0.6102 - val_f1_score: 0.5939 - lr: 4.0000e-05\n",
            "Epoch 50/1000\n",
            "52/52 [==============================] - ETA: 0s - loss: 0.8879 - categorical_accuracy: 0.6117 - f1_score: 0.5920Restoring model weights from the end of the best epoch: 40.\n",
            "\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 50: saving model to roberta_best_model.h5\n",
            "52/52 [==============================] - 60s 1s/step - loss: 0.8879 - categorical_accuracy: 0.6117 - f1_score: 0.5920 - val_loss: 0.8604 - val_categorical_accuracy: 0.6124 - val_f1_score: 0.5975 - lr: 4.0000e-05\n",
            "Epoch 50: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = {}\n",
        "inital_model = build_model(0.8, 0.0005, 0.001)\n",
        "history['tuned_stance_model_custom'] = inital_model.fit([train_input_ids, train_attention_masks], train_labels,\n",
        "                    epochs=1000,\n",
        "                    validation_data=([val_input_ids, val_attention_masks], val_labels),\n",
        "                    batch_size=256,\n",
        "                    callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p8ahqNJ9JA4",
        "outputId": "15390eb3-fb3c-4e53-de3f-9dd68e546f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 8s 135ms/step - loss: 0.8633 - categorical_accuracy: 0.6355 - f1_score: 0.4178\n",
            "Test accuracy: [0.8632698059082031, 0.6354805827140808, 0.41783618927001953]\n"
          ]
        }
      ],
      "source": [
        "results = inital_model.evaluate([test_input_ids, test_attention_masks], test_labels)\n",
        "print('Test accuracy:', results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioai3mLD9Pza",
        "outputId": "ec6ec88f-ace9-4e72-b65f-7114e828fa8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 12s 133ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.82      0.72      1014\n",
            "           1       0.62      0.41      0.50       452\n",
            "           2       0.62      0.45      0.52       490\n",
            "\n",
            "    accuracy                           0.64      1956\n",
            "   macro avg       0.63      0.56      0.58      1956\n",
            "weighted avg       0.63      0.64      0.62      1956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "predictions = inital_model.predict([test_input_ids, test_attention_masks])\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels are one-hot encoded, convert them to class labels\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0BO_wLOUiGjY"
      },
      "outputs": [],
      "source": [
        "def load_classification_rp_per_target(model):\n",
        "    targets = test_df.Target.unique()\n",
        "    metrics_df = pd.DataFrame()\n",
        "    for target in targets:\n",
        "        extracted_df = test_df[test_df['Target'] == target]\n",
        "        input_ids, attention_masks = bert_tokenize(extracted_df['Tweet'], extracted_df['Target'].to_list())\n",
        "        labels = categorized_label(extracted_df, \"Stance\")\n",
        "\n",
        "        # Convert one-hot encoded labels to single integer class labels\n",
        "        true_labels = np.argmax(labels, axis=1)\n",
        "\n",
        "        # Get model predictions\n",
        "        predictions = model.predict([input_ids, attention_masks])\n",
        "\n",
        "        # Convert predictions to class labels\n",
        "        predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Generate a classification report\n",
        "        report = classification_report(true_labels, predicted_labels, target_names=['AGAINST', 'FAVOR', 'NONE'])\n",
        "        target_name = target\n",
        "        # if target == 0:\n",
        "        #     target_name = \"Hillary Clinton\"\n",
        "        # if target == 1:\n",
        "        #     target_name = \"Legalization of Abortion\"\n",
        "        # if target == 2:\n",
        "        #     target_name = \"Atheism\"\n",
        "        # if target == 3:\n",
        "        #     target_name = \"Climate Change is a Real Concern\"\n",
        "        # if target == 4:\n",
        "        #     target_name = \"Feminist Movement\"\n",
        "        # if target == 5:\n",
        "        #     target_name = \"Donald Trump\"\n",
        "\n",
        "        print('Target: ', target_name)\n",
        "        print(report)\n",
        "        print(\"-----------------------------------------\", \"\\n\")\n",
        "\n",
        "        # Flatten the report into a single row and add target name\n",
        "        report = classification_report(true_labels, predicted_labels, target_names=['AGAINST', 'FAVOR', 'NONE'], output_dict=True)\n",
        "\n",
        "        # Extract weighted f1, macro f1, and accuracy\n",
        "        report_data = {\n",
        "            'Target': target_name,\n",
        "            'Weighted F1': report['weighted avg']['f1-score'],\n",
        "            'Macro F1': report['macro avg']['f1-score'],\n",
        "            'Accuracy': report['accuracy']\n",
        "        }\n",
        "\n",
        "        # Append to the DataFrame\n",
        "        metrics_df = metrics_df.append(report_data, ignore_index=True)\n",
        "    metrics_df.set_index('Target', inplace=True)\n",
        "\n",
        "    return metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-UGgHLpivYn",
        "outputId": "f1cba444-493c-490a-901d-5a334a50760d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 137ms/step\n",
            "Target:  Atheism\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.90      0.67      0.77       160\n",
            "       FAVOR       0.50      0.69      0.58        32\n",
            "        NONE       0.44      0.89      0.59        28\n",
            "\n",
            "    accuracy                           0.70       220\n",
            "   macro avg       0.61      0.75      0.64       220\n",
            "weighted avg       0.78      0.70      0.72       220\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 135ms/step\n",
            "Target:  Climate Change is a Real Concern\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.88      0.59      0.70       123\n",
            "        NONE       0.40      0.97      0.56        35\n",
            "\n",
            "    accuracy                           0.63       169\n",
            "   macro avg       0.42      0.52      0.42       169\n",
            "weighted avg       0.72      0.63      0.63       169\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 134ms/step\n",
            "Target:  Feminist Movement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.79      0.60      0.68       183\n",
            "       FAVOR       0.36      0.55      0.44        58\n",
            "        NONE       0.57      0.73      0.64        44\n",
            "\n",
            "    accuracy                           0.61       285\n",
            "   macro avg       0.57      0.63      0.59       285\n",
            "weighted avg       0.67      0.61      0.62       285\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 130ms/step\n",
            "Target:  Hillary Clinton\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.82      0.82       172\n",
            "       FAVOR       0.74      0.58      0.65        45\n",
            "        NONE       0.72      0.82      0.77        78\n",
            "\n",
            "    accuracy                           0.78       295\n",
            "   macro avg       0.76      0.74      0.75       295\n",
            "weighted avg       0.78      0.78      0.78       295\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 132ms/step\n",
            "Target:  Legalization of Abortion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.67      0.74       189\n",
            "       FAVOR       0.47      0.52      0.49        46\n",
            "        NONE       0.43      0.73      0.55        45\n",
            "\n",
            "    accuracy                           0.65       280\n",
            "   macro avg       0.58      0.64      0.59       280\n",
            "weighted avg       0.70      0.65      0.67       280\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 3s 132ms/step\n",
            "Target:  Donald Trump\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.56      0.64      0.60       299\n",
            "       FAVOR       0.78      0.33      0.46       148\n",
            "        NONE       0.68      0.80      0.74       260\n",
            "\n",
            "    accuracy                           0.64       707\n",
            "   macro avg       0.68      0.59      0.60       707\n",
            "weighted avg       0.65      0.64      0.62       707\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Weighted F1  Macro F1  Accuracy\n",
              "Target                                                           \n",
              "Atheism                              0.716913  0.644736  0.700000\n",
              "Climate Change is a Real Concern     0.627630  0.421474  0.627219\n",
              "Feminist Movement                    0.624757  0.585496  0.610526\n",
              "Hillary Clinton                      0.781171  0.746208  0.783051\n",
              "Legalization of Abortion             0.666327  0.592381  0.653571\n",
              "Donald Trump                         0.622621  0.600994  0.635078"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab3ee4e0-a77b-48d5-9969-54d4886f14e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>0.716913</td>\n",
              "      <td>0.644736</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>0.627630</td>\n",
              "      <td>0.421474</td>\n",
              "      <td>0.627219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>0.624757</td>\n",
              "      <td>0.585496</td>\n",
              "      <td>0.610526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>0.781171</td>\n",
              "      <td>0.746208</td>\n",
              "      <td>0.783051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>0.666327</td>\n",
              "      <td>0.592381</td>\n",
              "      <td>0.653571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>0.622621</td>\n",
              "      <td>0.600994</td>\n",
              "      <td>0.635078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab3ee4e0-a77b-48d5-9969-54d4886f14e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab3ee4e0-a77b-48d5-9969-54d4886f14e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab3ee4e0-a77b-48d5-9969-54d4886f14e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-46c97528-7168-4cd0-88f8-4d4ef7209259\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46c97528-7168-4cd0-88f8-4d4ef7209259')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-46c97528-7168-4cd0-88f8-4d4ef7209259 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b3b8c122-bc98-4942-a445-889e740e89be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b3b8c122-bc98-4942-a445-889e740e89be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Use the function to get the metrics DataFrame\n",
        "model_metrics_df = load_classification_rp_per_target(inital_model)\n",
        "model_metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcCRugBtjsz1"
      },
      "source": [
        "[4] Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBRlPb3ljy18",
        "outputId": "52cfa1e1-fb26-46e7-ccb8-739fc425f9f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "410/410 [==============================] - ETA: 0s - loss: 0.8556 - categorical_accuracy: 0.6289 - f1_score: 0.6080\n",
            "Epoch 1: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 353s 809ms/step - loss: 0.8556 - categorical_accuracy: 0.6289 - f1_score: 0.6080 - val_loss: 0.7461 - val_categorical_accuracy: 0.6905 - val_f1_score: 0.6877 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.7742 - categorical_accuracy: 0.6839 - f1_score: 0.6717\n",
            "Epoch 2: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 329s 801ms/step - loss: 0.7742 - categorical_accuracy: 0.6839 - f1_score: 0.6717 - val_loss: 0.7194 - val_categorical_accuracy: 0.7048 - val_f1_score: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.7212 - categorical_accuracy: 0.7208 - f1_score: 0.7145\n",
            "Epoch 3: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 329s 802ms/step - loss: 0.7212 - categorical_accuracy: 0.7208 - f1_score: 0.7145 - val_loss: 0.7004 - val_categorical_accuracy: 0.7274 - val_f1_score: 0.7263 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.6887 - categorical_accuracy: 0.7361 - f1_score: 0.7308\n",
            "Epoch 4: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 800ms/step - loss: 0.6887 - categorical_accuracy: 0.7361 - f1_score: 0.7308 - val_loss: 0.6729 - val_categorical_accuracy: 0.7368 - val_f1_score: 0.7351 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.6436 - categorical_accuracy: 0.7614 - f1_score: 0.7582\n",
            "Epoch 5: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 800ms/step - loss: 0.6436 - categorical_accuracy: 0.7614 - f1_score: 0.7582 - val_loss: 0.6723 - val_categorical_accuracy: 0.7344 - val_f1_score: 0.7328 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.6198 - categorical_accuracy: 0.7733 - f1_score: 0.7693\n",
            "Epoch 6: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 327s 798ms/step - loss: 0.6198 - categorical_accuracy: 0.7733 - f1_score: 0.7693 - val_loss: 0.6632 - val_categorical_accuracy: 0.7246 - val_f1_score: 0.7308 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.5832 - categorical_accuracy: 0.7913 - f1_score: 0.7903\n",
            "Epoch 7: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 800ms/step - loss: 0.5832 - categorical_accuracy: 0.7913 - f1_score: 0.7903 - val_loss: 0.6490 - val_categorical_accuracy: 0.7368 - val_f1_score: 0.7383 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.5575 - categorical_accuracy: 0.8041 - f1_score: 0.8054\n",
            "Epoch 8: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 799ms/step - loss: 0.5575 - categorical_accuracy: 0.8041 - f1_score: 0.8054 - val_loss: 0.6539 - val_categorical_accuracy: 0.7371 - val_f1_score: 0.7416 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.5274 - categorical_accuracy: 0.8166 - f1_score: 0.8178\n",
            "Epoch 9: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 800ms/step - loss: 0.5274 - categorical_accuracy: 0.8166 - f1_score: 0.8178 - val_loss: 0.6737 - val_categorical_accuracy: 0.7261 - val_f1_score: 0.7323 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.4987 - categorical_accuracy: 0.8309 - f1_score: 0.8335\n",
            "Epoch 10: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 799ms/step - loss: 0.4987 - categorical_accuracy: 0.8309 - f1_score: 0.8335 - val_loss: 0.6576 - val_categorical_accuracy: 0.7353 - val_f1_score: 0.7384 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.4708 - categorical_accuracy: 0.8430 - f1_score: 0.8466\n",
            "Epoch 11: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 801ms/step - loss: 0.4708 - categorical_accuracy: 0.8430 - f1_score: 0.8466 - val_loss: 0.6702 - val_categorical_accuracy: 0.7377 - val_f1_score: 0.7432 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.4509 - categorical_accuracy: 0.8456 - f1_score: 0.8510\n",
            "Epoch 12: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 327s 798ms/step - loss: 0.4509 - categorical_accuracy: 0.8456 - f1_score: 0.8510 - val_loss: 0.6773 - val_categorical_accuracy: 0.7362 - val_f1_score: 0.7368 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.4302 - categorical_accuracy: 0.8541 - f1_score: 0.8563\n",
            "Epoch 13: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 327s 799ms/step - loss: 0.4302 - categorical_accuracy: 0.8541 - f1_score: 0.8563 - val_loss: 0.6793 - val_categorical_accuracy: 0.7405 - val_f1_score: 0.7426 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.4189 - categorical_accuracy: 0.8604 - f1_score: 0.8642\n",
            "Epoch 14: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 801ms/step - loss: 0.4189 - categorical_accuracy: 0.8604 - f1_score: 0.8642 - val_loss: 0.7107 - val_categorical_accuracy: 0.7368 - val_f1_score: 0.7335 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.4112 - categorical_accuracy: 0.8632 - f1_score: 0.8669\n",
            "Epoch 15: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 800ms/step - loss: 0.4112 - categorical_accuracy: 0.8632 - f1_score: 0.8669 - val_loss: 0.6997 - val_categorical_accuracy: 0.7344 - val_f1_score: 0.7315 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.3934 - categorical_accuracy: 0.8723 - f1_score: 0.8764\n",
            "Epoch 16: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 800ms/step - loss: 0.3934 - categorical_accuracy: 0.8723 - f1_score: 0.8764 - val_loss: 0.7507 - val_categorical_accuracy: 0.7322 - val_f1_score: 0.7328 - lr: 1.0000e-05\n",
            "Epoch 17/30\n",
            "410/410 [==============================] - ETA: 0s - loss: 0.3561 - categorical_accuracy: 0.8844 - f1_score: 0.8882Restoring model weights from the end of the best epoch: 7.\n",
            "\n",
            "Epoch 17: saving model to roberta_best_model.h5\n",
            "410/410 [==============================] - 328s 801ms/step - loss: 0.3561 - categorical_accuracy: 0.8844 - f1_score: 0.8882 - val_loss: 0.7938 - val_categorical_accuracy: 0.7368 - val_f1_score: 0.7396 - lr: 1.0000e-05\n",
            "Epoch 17: early stopping\n"
          ]
        }
      ],
      "source": [
        "for layer in inital_model.layers:\n",
        "    layer.trainable = True\n",
        "   # Tuning the learning rate for the optimizer\n",
        "inital_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['categorical_accuracy', f1_score])\n",
        "\n",
        "history['fine_tuned_bert'] = inital_model.fit([train_input_ids, train_attention_masks], train_labels,\n",
        "                    epochs=30,\n",
        "                    validation_data=([val_input_ids, val_attention_masks], val_labels),\n",
        "                    batch_size=32,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WAOA3PAJoSuU",
        "outputId": "81028cec-79a6-46ce-a68b-1e8db3453b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 133ms/step\n",
            "Target:  Atheism\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.90      0.67      0.77       160\n",
            "       FAVOR       0.50      0.69      0.58        32\n",
            "        NONE       0.44      0.89      0.59        28\n",
            "\n",
            "    accuracy                           0.70       220\n",
            "   macro avg       0.61      0.75      0.64       220\n",
            "weighted avg       0.78      0.70      0.72       220\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 127ms/step\n",
            "Target:  Climate Change is a Real Concern\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.88      0.59      0.70       123\n",
            "        NONE       0.40      0.97      0.56        35\n",
            "\n",
            "    accuracy                           0.63       169\n",
            "   macro avg       0.42      0.52      0.42       169\n",
            "weighted avg       0.72      0.63      0.63       169\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 135ms/step\n",
            "Target:  Feminist Movement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.79      0.60      0.68       183\n",
            "       FAVOR       0.36      0.55      0.44        58\n",
            "        NONE       0.57      0.73      0.64        44\n",
            "\n",
            "    accuracy                           0.61       285\n",
            "   macro avg       0.57      0.63      0.59       285\n",
            "weighted avg       0.67      0.61      0.62       285\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 130ms/step\n",
            "Target:  Hillary Clinton\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.82      0.82       172\n",
            "       FAVOR       0.74      0.58      0.65        45\n",
            "        NONE       0.72      0.82      0.77        78\n",
            "\n",
            "    accuracy                           0.78       295\n",
            "   macro avg       0.76      0.74      0.75       295\n",
            "weighted avg       0.78      0.78      0.78       295\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 132ms/step\n",
            "Target:  Legalization of Abortion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.67      0.74       189\n",
            "       FAVOR       0.47      0.52      0.49        46\n",
            "        NONE       0.43      0.73      0.55        45\n",
            "\n",
            "    accuracy                           0.65       280\n",
            "   macro avg       0.58      0.64      0.59       280\n",
            "weighted avg       0.70      0.65      0.67       280\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 3s 131ms/step\n",
            "Target:  Donald Trump\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.56      0.64      0.60       299\n",
            "       FAVOR       0.78      0.33      0.46       148\n",
            "        NONE       0.68      0.80      0.74       260\n",
            "\n",
            "    accuracy                           0.64       707\n",
            "   macro avg       0.68      0.59      0.60       707\n",
            "weighted avg       0.65      0.64      0.62       707\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-653adaea9b0f>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Weighted F1  Macro F1  Accuracy\n",
              "Target                                                           \n",
              "Atheism                              0.716913  0.644736  0.700000\n",
              "Climate Change is a Real Concern     0.627630  0.421474  0.627219\n",
              "Feminist Movement                    0.624757  0.585496  0.610526\n",
              "Hillary Clinton                      0.781171  0.746208  0.783051\n",
              "Legalization of Abortion             0.666327  0.592381  0.653571\n",
              "Donald Trump                         0.622621  0.600994  0.635078"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8b9917a-c2f8-4ec2-bae8-ab0e4c699f39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>0.716913</td>\n",
              "      <td>0.644736</td>\n",
              "      <td>0.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>0.627630</td>\n",
              "      <td>0.421474</td>\n",
              "      <td>0.627219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>0.624757</td>\n",
              "      <td>0.585496</td>\n",
              "      <td>0.610526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>0.781171</td>\n",
              "      <td>0.746208</td>\n",
              "      <td>0.783051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>0.666327</td>\n",
              "      <td>0.592381</td>\n",
              "      <td>0.653571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>0.622621</td>\n",
              "      <td>0.600994</td>\n",
              "      <td>0.635078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b9917a-c2f8-4ec2-bae8-ab0e4c699f39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8b9917a-c2f8-4ec2-bae8-ab0e4c699f39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8b9917a-c2f8-4ec2-bae8-ab0e4c699f39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38795c31-c4c8-423b-956b-6719577981d1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38795c31-c4c8-423b-956b-6719577981d1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38795c31-c4c8-423b-956b-6719577981d1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f09660de-dcb2-4e0d-a04f-870261aac5d9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f09660de-dcb2-4e0d-a04f-870261aac5d9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Use the function to get the metrics DataFrame\n",
        "model_metrics_df = load_classification_rp_per_target(inital_model)\n",
        "model_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YRDLteVolOe",
        "outputId": "c79109a0-166c-499f-df65-47da9330d604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 8s 134ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.67      0.70      1014\n",
            "           1       0.62      0.50      0.55       452\n",
            "           2       0.59      0.81      0.68       490\n",
            "\n",
            "    accuracy                           0.66      1956\n",
            "   macro avg       0.65      0.66      0.64      1956\n",
            "weighted avg       0.67      0.66      0.66      1956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "predictions = inital_model.predict([test_input_ids, test_attention_masks])\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels are one-hot encoded, convert them to class labels\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byHt9y_SpOCY",
        "outputId": "73fcd6e0-869e-480f-95fa-6dc356531b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "inital_model.save('roberta_model_66.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}