{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "<a id=\"data-prep\"></a>\n",
    "<div style=\"background-color: #000D5B; color: white; text-align: center; padding: 6px 0 22px 0\">\n",
    "    <h3 style=\"background-color: #000D5B; color: white; text-align: left\">RMIT School of Computer Science and Technology</h3>\n",
    "    <br/>\n",
    "    <h1>COSC3007: Deep Learning</h1>\n",
    "    <h2>Assignment 2: Stance Twitter Sentiment Analysis and Detection </h2>\n",
    "    <h2> [2] MODELLING AND MODEL EVALUATIONS </h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./StanceDataset/processed_train.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])\n",
    "test_df = pd.read_csv(\"./StanceDataset/processed_test.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Prepare label and fit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split test and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df, val_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 200\n",
    "\n",
    "# Train\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df['processed_tweet'])\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['processed_tweet'])\n",
    "\n",
    "# Test\n",
    "tokenizer2 = Tokenizer()\n",
    "tokenizer2.fit_on_texts(train_df['processed_tweet'])\n",
    "test_sequences = tokenizer2.texts_to_sequences(test_df['processed_tweet'])\n",
    "\n",
    "# Val\n",
    "tokenizer3 = Tokenizer()\n",
    "tokenizer3.fit_on_texts(train_df['processed_tweet'])\n",
    "val_sequences = tokenizer3.texts_to_sequences(val_df['processed_tweet'])\n",
    "\n",
    "train_pad = pad_sequences(train_sequences, maxlen=MAX_LENGTH, padding='post')\n",
    "test_pad = pad_sequences(test_sequences, maxlen=MAX_LENGTH, padding='post')\n",
    "val_pad = pad_sequences(val_sequences, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorized_label(df, label_name):\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(df[label_name])\n",
    "    categorical_labels = to_categorical(encoded_labels)\n",
    "    return categorical_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = categorized_label(train_df, \"Stance\")\n",
    "test_labels = categorized_label(test_df, \"Stance\")\n",
    "val_labels = categorized_label(val_df, \"Stance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 13:12:34.647460: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2023-12-19 13:12:34.647479: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-12-19 13:12:34.647485: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-12-19 13:12:34.647515: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-19 13:12:34.647530: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=16, input_length=200))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))  # 3 classes: FAVOUR, AGAINST, NEITHER\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 13:12:35.630744: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/92 [==>...........................] - ETA: 2:06:51 - loss: 1.0825 - accuracy: 0.4594"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_pad, train_labels, epochs=10, validation_data=(val_pad, val_labels), batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
