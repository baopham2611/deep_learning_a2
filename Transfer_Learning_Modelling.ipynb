{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \n",
    "<a id=\"data-prep\"></a>\n",
    "<div style=\"background-color: #000D5B; color: white; text-align: center; padding: 6px 0 22px 0\">\n",
    "    <h3 style=\"background-color: #000D5B; color: white; text-align: left\">RMIT School of Computer Science and Technology</h3>\n",
    "    <br/>\n",
    "    <h1>COSC3007: Deep Learning</h1>\n",
    "    <h2>Assignment 2: Stance Twitter Sentiment Analysis and Detection </h2>\n",
    "    <h2> [2] MODELLING AND MODEL EVALUATIONS </h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import tempfile\n",
    "import re\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= pd.read_csv('./StanceDataset/TrainFileCleaned.csv',sep=',',encoding = 'unicode_escape')\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "train_ori = train_df.copy()\n",
    "\n",
    "test_df= pd.read_csv('./StanceDataset/TestFileCleaned.csv',sep=',',encoding = 'unicode_escape')\n",
    "\n",
    "# Filter out rows where the 'target' column contains 'Donald Trump'\n",
    "filtered_test_df = test_df[~test_df['Target'].str.contains(\"Donald Trump\", case=False, na=False)]\n",
    "\n",
    "# Save the filtered dataset\n",
    "test_df = filtered_test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Prepare label and fit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split test and val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GloVe embeddings\n",
    "embedding_dim = 100  # This should match the GloVe\n",
    "embeddings_index = {}\n",
    "with open(\"./glove.6B.100d.txt\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace '@' and '#' with a space in each tweet of train and test set and save to new lists\n",
    "list_clean = list()\n",
    "test_clean = list()\n",
    "lines = train_df[\"preprocessed_tweet\"].values.tolist()\n",
    "testlines = test_df[\"preprocessed_tweet\"].values.tolist()\n",
    "\n",
    "for line in lines:\n",
    "    line = re.sub(r'@','', line)\n",
    "    line = re.sub(r'#','', line)\n",
    "    words = line.split(\" \")\n",
    "    list_clean.append(words)\n",
    "    \n",
    "for line in testlines:\n",
    "    line = re.sub(r'@','', line)\n",
    "    line = re.sub(r'#','', line)\n",
    "    words = line.split(\" \")\n",
    "    test_clean.append(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 17\n",
      "Unique tokens: 6432\n",
      "Vocabulary size: 6433\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(list_clean)\n",
    "\n",
    "# Convert texts to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(list_clean)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_clean)\n",
    "\n",
    "# Find the maximum sequence length\n",
    "max_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in test_sequences))\n",
    "print(f\"Maximum sequence length: {max_length}\")\n",
    "\n",
    "# Get word index and vocabulary size\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "print(f\"Unique tokens: {len(word_index)}\")\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Pad sequences\n",
    "train_pad = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "test_pad = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Extract target labels\n",
    "train_stance = train_df[\"Stance\"].values\n",
    "train_target = train_df[\"Target\"].values\n",
    "test_stance = test_df[\"Stance\"].values\n",
    "\n",
    "# Create an embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "validation_split = 0.20\n",
    "\n",
    "# Define the number of validation samples\n",
    "num_validation_samples = int(validation_split * train_pad.shape[0])\n",
    "\n",
    "# Shuffle the training data\n",
    "indices = np.arange(train_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_pad = train_pad[indices]\n",
    "train_stance = train_stance[indices]\n",
    "train_target = train_target[indices]\n",
    "\n",
    "# One-hot encoding for stance and target classes\n",
    "n_values_stance = np.max(train_stance) + 1\n",
    "n_values_target = np.max(train_target) + 1\n",
    "n_values_test = np.max(test_stance) + 1\n",
    "\n",
    "train_stance_labels = np.eye(n_values_stance)[train_stance]\n",
    "train_target_labels = np.eye(n_values_target)[train_target]\n",
    "test_stance_labels = np.eye(n_values_test)[test_stance]\n",
    "\n",
    "# Split the training data into train and validation sets\n",
    "val_pad = train_pad[-num_validation_samples:]\n",
    "val_stance_labels = train_stance_labels[-num_validation_samples:]\n",
    "val_target_labels = train_target_labels[-num_validation_samples:]\n",
    "\n",
    "train_pad = train_pad[:-num_validation_samples]\n",
    "train_stance_labels = train_stance_labels[:-num_validation_samples]\n",
    "train_target_labels = train_target_labels[:-num_validation_samples]\n",
    "\n",
    "# Test dataset remains unchanged\n",
    "test_pad_labels = test_stance_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_lad: (2332, 17)\n",
      "Shape of train_target: (2332, 5)\n",
      "Shape of train_stance: (2332, 3)\n",
      "Shape of val_pad: (582, 17)\n",
      "Shape of val_target: (582, 5)\n",
      "Shape of val_stance: (582, 3)\n",
      "Shape of test_pad: (1249, 17)\n",
      "Shape of test_labels: (1249, 3)\n"
     ]
    }
   ],
   "source": [
    "#Print shape of train val test split for both target and stance\n",
    "print('Shape of train_lad:', train_pad.shape)\n",
    "print('Shape of train_target:', train_target_labels.shape)\n",
    "print('Shape of train_stance:', train_stance_labels.shape)\n",
    "\n",
    "print('Shape of val_pad:', val_pad.shape)\n",
    "print('Shape of val_target:', val_target_labels.shape)\n",
    "print('Shape of val_stance:', val_stance_labels.shape)\n",
    "\n",
    "print('Shape of test_pad:', test_pad.shape)\n",
    "print('Shape of test_labels:', test_pad_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from hyperopt import hp\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create f1 metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_class(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    # Convert predictions to one-hot format\n",
    "    y_pred_one_hot = K.one_hot(K.argmax(y_pred), num_classes=3)\n",
    "\n",
    "    # Calculate F1 score for each class\n",
    "    f1s = [f1_score_class(y_true[:, i], y_pred_one_hot[:, i]) for i in range(3)]\n",
    "\n",
    "    # Average F1 scores across all classes\n",
    "    return K.mean(K.stack(f1s), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom adam rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_adam(lr):\n",
    "    STEPS_PER_EPOCH = 73\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "        initial_learning_rate=lr,\n",
    "        decay_steps=STEPS_PER_EPOCH * 1000,\n",
    "        decay_rate=10,\n",
    "        staircase=False)\n",
    "\n",
    "    # Visualize the learning rate curve\n",
    "    steps = np.linspace(0, 100000)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(steps / STEPS_PER_EPOCH, lr_schedule(steps))\n",
    "    plt.ylim([0, max(plt.ylim())])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "\n",
    "    return Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Call backs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up call backs and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# Define the EarlyStopping and ReduceLROnPlateau callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-5,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Define the ModelCheckpoint callback\n",
    "checkpoint_path = \"transfer_learning_baseline_weight.h5\"\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,    # Only save a model if 'val_loss' has improved\n",
    "    monitor='val_loss',     # Monitor 'val_loss' during training\n",
    "    mode='min',             # The model is saved when 'val_loss' is minimized\n",
    "    verbose=1)\n",
    "\n",
    "# Combine all callbacks in a list\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "    model_checkpoint_callback\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up call backs for trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Failed to launch TensorBoard (exited with 1).\n",
       "Contents of stderr:\n",
       "Address already in use\n",
       "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Specify location to save model checkpoints\n",
    "checkpoint_path = './'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "#function definition for model callback; \n",
    "#Params {'name' : Name of the model, 'early_stop' : Specify early stopping (True/False) } \n",
    "\n",
    "def get_callbacks(name,early_stop=True):\n",
    "  if early_stop:\n",
    "      return [\n",
    "              tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True),\n",
    "              tf.keras.callbacks.TensorBoard(logdir/name, histogram_freq=60, embeddings_freq=60),\n",
    "              tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path+name,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "      ]\n",
    "\n",
    "  else:\n",
    "    return [tf.keras.callbacks.TensorBoard(logdir/name)]\n",
    "  \n",
    "#Load the TensorBoard\n",
    "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
    "shutil.rmtree(logdir, ignore_errors=True)\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Open an embedded TensorBoard viewer\n",
    "%tensorboard --logdir {logdir}/models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "def build_model(isStance, drop, regr):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "    model.add(Bidirectional(LSTM(units=128,  dropout=drop, recurrent_dropout=drop,return_sequences=True,kernel_regularizer=tf.keras.regularizers.l2(regr))))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(regr)))\n",
    "    model.add(Dropout(drop))\n",
    "        \n",
    "    if isStance:\n",
    "    # Final Layer\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "      # Define the optimizer within the function\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    model.compile(loss='CategoricalCrossentropy', optimizer=optimizer, metrics=['categorical_accuracy',f1_score])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] Training For Baseline Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training for base target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCH\n",
    "EPOCH = 100\n",
    "#Selection of dropouts and lambda values for model training\n",
    "m_histories = {}\n",
    "\n",
    "#Fine tuning the hyper parameters on trainable layers\n",
    "dropout_rate = [0.7, 0.8]\n",
    "lambda_vals = [0.005, 0.001, 0.0005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 14:47:38.968543: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2023-12-29 14:47:38.968575: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-12-29 14:47:38.968585: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-12-29 14:47:38.968637: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-29 14:47:38.968664: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 17, 100)           643300    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 17, 256)           234496    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4352)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               557184    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1435625 (5.48 MB)\n",
      "Trainable params: 792325 (3.02 MB)\n",
      "Non-trainable params: 643300 (2.45 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 14:47:40.808433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - ETA: 0s - loss: 3.5916 - categorical_accuracy: 0.3375 - f1_score: 0.3252"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 14:49:21.002921: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 105s 1s/step - loss: 3.5916 - categorical_accuracy: 0.3375 - f1_score: 0.3252 - val_loss: 2.5196 - val_categorical_accuracy: 0.5103 - val_f1_score: 0.5031\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 2.2563 - categorical_accuracy: 0.4275 - f1_score: 0.4095\n",
      "Epoch 2: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 97s 1s/step - loss: 2.2563 - categorical_accuracy: 0.4275 - f1_score: 0.4095 - val_loss: 1.8160 - val_categorical_accuracy: 0.5825 - val_f1_score: 0.5413\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.8359 - categorical_accuracy: 0.4533 - f1_score: 0.4392\n",
      "Epoch 3: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 99s 1s/step - loss: 1.8359 - categorical_accuracy: 0.4533 - f1_score: 0.4392 - val_loss: 1.6038 - val_categorical_accuracy: 0.5430 - val_f1_score: 0.5418\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.6348 - categorical_accuracy: 0.4884 - f1_score: 0.4789\n",
      "Epoch 4: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.6348 - categorical_accuracy: 0.4884 - f1_score: 0.4789 - val_loss: 1.4315 - val_categorical_accuracy: 0.6426 - val_f1_score: 0.5722\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.5380 - categorical_accuracy: 0.4871 - f1_score: 0.4837\n",
      "Epoch 5: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.5380 - categorical_accuracy: 0.4871 - f1_score: 0.4837 - val_loss: 1.3773 - val_categorical_accuracy: 0.6443 - val_f1_score: 0.5874\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4656 - categorical_accuracy: 0.5073 - f1_score: 0.4763\n",
      "Epoch 6: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.4656 - categorical_accuracy: 0.5073 - f1_score: 0.4763 - val_loss: 1.3152 - val_categorical_accuracy: 0.6409 - val_f1_score: 0.5650\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4200 - categorical_accuracy: 0.5124 - f1_score: 0.5015\n",
      "Epoch 7: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.4200 - categorical_accuracy: 0.5124 - f1_score: 0.5015 - val_loss: 1.3102 - val_categorical_accuracy: 0.6409 - val_f1_score: 0.6065\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3951 - categorical_accuracy: 0.5133 - f1_score: 0.4894\n",
      "Epoch 8: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.3951 - categorical_accuracy: 0.5133 - f1_score: 0.4894 - val_loss: 1.2612 - val_categorical_accuracy: 0.6443 - val_f1_score: 0.6086\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3601 - categorical_accuracy: 0.5399 - f1_score: 0.5101\n",
      "Epoch 9: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.3601 - categorical_accuracy: 0.5399 - f1_score: 0.5101 - val_loss: 1.2751 - val_categorical_accuracy: 0.6306 - val_f1_score: 0.5972\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3415 - categorical_accuracy: 0.5437 - f1_score: 0.5264\n",
      "Epoch 10: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.3415 - categorical_accuracy: 0.5437 - f1_score: 0.5264 - val_loss: 1.2146 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.5856\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3494 - categorical_accuracy: 0.5283 - f1_score: 0.5159\n",
      "Epoch 11: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 97s 1s/step - loss: 1.3494 - categorical_accuracy: 0.5283 - f1_score: 0.5159 - val_loss: 1.2296 - val_categorical_accuracy: 0.6512 - val_f1_score: 0.6184\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3202 - categorical_accuracy: 0.5446 - f1_score: 0.5343\n",
      "Epoch 12: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 97s 1s/step - loss: 1.3202 - categorical_accuracy: 0.5446 - f1_score: 0.5343 - val_loss: 1.2239 - val_categorical_accuracy: 0.6289 - val_f1_score: 0.5953\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3306 - categorical_accuracy: 0.5399 - f1_score: 0.5234\n",
      "Epoch 13: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.3306 - categorical_accuracy: 0.5399 - f1_score: 0.5234 - val_loss: 1.2231 - val_categorical_accuracy: 0.6203 - val_f1_score: 0.5971\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3084 - categorical_accuracy: 0.5502 - f1_score: 0.5284\n",
      "Epoch 14: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 97s 1s/step - loss: 1.3084 - categorical_accuracy: 0.5502 - f1_score: 0.5284 - val_loss: 1.2012 - val_categorical_accuracy: 0.6409 - val_f1_score: 0.6084\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2730 - categorical_accuracy: 0.5617 - f1_score: 0.5531\n",
      "Epoch 15: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 99s 1s/step - loss: 1.2730 - categorical_accuracy: 0.5617 - f1_score: 0.5531 - val_loss: 1.2110 - val_categorical_accuracy: 0.6082 - val_f1_score: 0.5832\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2716 - categorical_accuracy: 0.5690 - f1_score: 0.5528\n",
      "Epoch 16: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.2716 - categorical_accuracy: 0.5690 - f1_score: 0.5528 - val_loss: 1.2089 - val_categorical_accuracy: 0.6323 - val_f1_score: 0.6036\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2434 - categorical_accuracy: 0.5729 - f1_score: 0.5615\n",
      "Epoch 17: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.2434 - categorical_accuracy: 0.5729 - f1_score: 0.5615 - val_loss: 1.1641 - val_categorical_accuracy: 0.6340 - val_f1_score: 0.6093\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2669 - categorical_accuracy: 0.5553 - f1_score: 0.5436\n",
      "Epoch 18: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 101s 1s/step - loss: 1.2669 - categorical_accuracy: 0.5553 - f1_score: 0.5436 - val_loss: 1.1830 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6143\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2491 - categorical_accuracy: 0.5733 - f1_score: 0.5498\n",
      "Epoch 19: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 105s 1s/step - loss: 1.2491 - categorical_accuracy: 0.5733 - f1_score: 0.5498 - val_loss: 1.1233 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6535\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2306 - categorical_accuracy: 0.5806 - f1_score: 0.5750\n",
      "Epoch 20: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 108s 1s/step - loss: 1.2306 - categorical_accuracy: 0.5806 - f1_score: 0.5750 - val_loss: 1.1872 - val_categorical_accuracy: 0.6443 - val_f1_score: 0.6171\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2358 - categorical_accuracy: 0.5815 - f1_score: 0.5669\n",
      "Epoch 21: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 133s 2s/step - loss: 1.2358 - categorical_accuracy: 0.5815 - f1_score: 0.5669 - val_loss: 1.1590 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.6261\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2420 - categorical_accuracy: 0.5853 - f1_score: 0.5706\n",
      "Epoch 22: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 147s 2s/step - loss: 1.2420 - categorical_accuracy: 0.5853 - f1_score: 0.5706 - val_loss: 1.1531 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.6261\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2186 - categorical_accuracy: 0.5810 - f1_score: 0.5676\n",
      "Epoch 23: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.2186 - categorical_accuracy: 0.5810 - f1_score: 0.5676 - val_loss: 1.1182 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6313\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2075 - categorical_accuracy: 0.5866 - f1_score: 0.5826\n",
      "Epoch 24: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.2075 - categorical_accuracy: 0.5866 - f1_score: 0.5826 - val_loss: 1.1330 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6378\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1908 - categorical_accuracy: 0.5909 - f1_score: 0.5750\n",
      "Epoch 25: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1908 - categorical_accuracy: 0.5909 - f1_score: 0.5750 - val_loss: 1.0945 - val_categorical_accuracy: 0.6890 - val_f1_score: 0.6588\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2124 - categorical_accuracy: 0.5943 - f1_score: 0.5823\n",
      "Epoch 26: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.2124 - categorical_accuracy: 0.5943 - f1_score: 0.5823 - val_loss: 1.1159 - val_categorical_accuracy: 0.6770 - val_f1_score: 0.6383\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2065 - categorical_accuracy: 0.5918 - f1_score: 0.5767\n",
      "Epoch 27: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.2065 - categorical_accuracy: 0.5918 - f1_score: 0.5767 - val_loss: 1.1200 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6279\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1930 - categorical_accuracy: 0.5986 - f1_score: 0.5867\n",
      "Epoch 28: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1930 - categorical_accuracy: 0.5986 - f1_score: 0.5867 - val_loss: 1.1023 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6567\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2070 - categorical_accuracy: 0.5879 - f1_score: 0.5718\n",
      "Epoch 29: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.2070 - categorical_accuracy: 0.5879 - f1_score: 0.5718 - val_loss: 1.1286 - val_categorical_accuracy: 0.6598 - val_f1_score: 0.6275\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1946 - categorical_accuracy: 0.5905 - f1_score: 0.5708\n",
      "Epoch 30: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.1946 - categorical_accuracy: 0.5905 - f1_score: 0.5708 - val_loss: 1.0935 - val_categorical_accuracy: 0.7062 - val_f1_score: 0.6628\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1687 - categorical_accuracy: 0.6093 - f1_score: 0.5826\n",
      "Epoch 31: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1687 - categorical_accuracy: 0.6093 - f1_score: 0.5826 - val_loss: 1.0884 - val_categorical_accuracy: 0.6993 - val_f1_score: 0.6463\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1666 - categorical_accuracy: 0.6145 - f1_score: 0.5993\n",
      "Epoch 32: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1666 - categorical_accuracy: 0.6145 - f1_score: 0.5993 - val_loss: 1.1000 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6364\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1591 - categorical_accuracy: 0.6003 - f1_score: 0.5779\n",
      "Epoch 33: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1591 - categorical_accuracy: 0.6003 - f1_score: 0.5779 - val_loss: 1.0998 - val_categorical_accuracy: 0.6821 - val_f1_score: 0.6423\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1963 - categorical_accuracy: 0.5961 - f1_score: 0.5833\n",
      "Epoch 34: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 139s 2s/step - loss: 1.1963 - categorical_accuracy: 0.5961 - f1_score: 0.5833 - val_loss: 1.0896 - val_categorical_accuracy: 0.6770 - val_f1_score: 0.6401\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1573 - categorical_accuracy: 0.6076 - f1_score: 0.5871\n",
      "Epoch 35: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.1573 - categorical_accuracy: 0.6076 - f1_score: 0.5871 - val_loss: 1.1098 - val_categorical_accuracy: 0.6821 - val_f1_score: 0.6531\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1716 - categorical_accuracy: 0.6111 - f1_score: 0.5875\n",
      "Epoch 36: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 142s 2s/step - loss: 1.1716 - categorical_accuracy: 0.6111 - f1_score: 0.5875 - val_loss: 1.1111 - val_categorical_accuracy: 0.6821 - val_f1_score: 0.6528\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1704 - categorical_accuracy: 0.6008 - f1_score: 0.5785\n",
      "Epoch 37: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.1704 - categorical_accuracy: 0.6008 - f1_score: 0.5785 - val_loss: 1.0915 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6250\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1575 - categorical_accuracy: 0.6111 - f1_score: 0.6008\n",
      "Epoch 38: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.1575 - categorical_accuracy: 0.6111 - f1_score: 0.6008 - val_loss: 1.0792 - val_categorical_accuracy: 0.6856 - val_f1_score: 0.6590\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1421 - categorical_accuracy: 0.6179 - f1_score: 0.6025\n",
      "Epoch 39: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1421 - categorical_accuracy: 0.6179 - f1_score: 0.6025 - val_loss: 1.0833 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6478\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1473 - categorical_accuracy: 0.6128 - f1_score: 0.6035\n",
      "Epoch 40: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1473 - categorical_accuracy: 0.6128 - f1_score: 0.6035 - val_loss: 1.0973 - val_categorical_accuracy: 0.6838 - val_f1_score: 0.6532\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1478 - categorical_accuracy: 0.6209 - f1_score: 0.6190\n",
      "Epoch 41: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 151s 2s/step - loss: 1.1478 - categorical_accuracy: 0.6209 - f1_score: 0.6190 - val_loss: 1.1006 - val_categorical_accuracy: 0.6804 - val_f1_score: 0.6318\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1410 - categorical_accuracy: 0.6252 - f1_score: 0.6019\n",
      "Epoch 42: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.1410 - categorical_accuracy: 0.6252 - f1_score: 0.6019 - val_loss: 1.0888 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6310\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1281 - categorical_accuracy: 0.6269 - f1_score: 0.6124\n",
      "Epoch 43: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.1281 - categorical_accuracy: 0.6269 - f1_score: 0.6124 - val_loss: 1.0784 - val_categorical_accuracy: 0.6890 - val_f1_score: 0.6532\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1350 - categorical_accuracy: 0.6055 - f1_score: 0.5817\n",
      "Epoch 44: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1350 - categorical_accuracy: 0.6055 - f1_score: 0.5817 - val_loss: 1.0772 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6084\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1321 - categorical_accuracy: 0.6192 - f1_score: 0.6122\n",
      "Epoch 45: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1321 - categorical_accuracy: 0.6192 - f1_score: 0.6122 - val_loss: 1.0795 - val_categorical_accuracy: 0.7010 - val_f1_score: 0.6611\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1240 - categorical_accuracy: 0.6231 - f1_score: 0.6102\n",
      "Epoch 46: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.1240 - categorical_accuracy: 0.6231 - f1_score: 0.6102 - val_loss: 1.0742 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.6085\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1328 - categorical_accuracy: 0.6098 - f1_score: 0.5867\n",
      "Epoch 47: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1328 - categorical_accuracy: 0.6098 - f1_score: 0.5867 - val_loss: 1.0635 - val_categorical_accuracy: 0.6873 - val_f1_score: 0.6529\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1179 - categorical_accuracy: 0.6166 - f1_score: 0.6058\n",
      "Epoch 48: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1179 - categorical_accuracy: 0.6166 - f1_score: 0.6058 - val_loss: 1.0513 - val_categorical_accuracy: 0.6856 - val_f1_score: 0.6521\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1288 - categorical_accuracy: 0.6209 - f1_score: 0.6042\n",
      "Epoch 49: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1288 - categorical_accuracy: 0.6209 - f1_score: 0.6042 - val_loss: 1.0634 - val_categorical_accuracy: 0.6856 - val_f1_score: 0.6527\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1310 - categorical_accuracy: 0.6265 - f1_score: 0.6143\n",
      "Epoch 50: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1310 - categorical_accuracy: 0.6265 - f1_score: 0.6143 - val_loss: 1.0604 - val_categorical_accuracy: 0.6856 - val_f1_score: 0.6484\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1287 - categorical_accuracy: 0.6106 - f1_score: 0.6001\n",
      "Epoch 51: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 144s 2s/step - loss: 1.1287 - categorical_accuracy: 0.6106 - f1_score: 0.6001 - val_loss: 1.0620 - val_categorical_accuracy: 0.6907 - val_f1_score: 0.6464\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1210 - categorical_accuracy: 0.6226 - f1_score: 0.6119\n",
      "Epoch 52: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 1.1210 - categorical_accuracy: 0.6226 - f1_score: 0.6119 - val_loss: 1.0544 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6476\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1252 - categorical_accuracy: 0.6205 - f1_score: 0.5941\n",
      "Epoch 53: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1252 - categorical_accuracy: 0.6205 - f1_score: 0.5941 - val_loss: 1.0640 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6560\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1044 - categorical_accuracy: 0.6329 - f1_score: 0.6105\n",
      "Epoch 54: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 1.1044 - categorical_accuracy: 0.6329 - f1_score: 0.6105 - val_loss: 1.0478 - val_categorical_accuracy: 0.6890 - val_f1_score: 0.6467\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1171 - categorical_accuracy: 0.6214 - f1_score: 0.6068\n",
      "Epoch 55: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.1171 - categorical_accuracy: 0.6214 - f1_score: 0.6068 - val_loss: 1.0607 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6420\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1336 - categorical_accuracy: 0.6188 - f1_score: 0.5988\n",
      "Epoch 56: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 1.1336 - categorical_accuracy: 0.6188 - f1_score: 0.5988 - val_loss: 1.0892 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6402\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1097 - categorical_accuracy: 0.6252 - f1_score: 0.6032\n",
      "Epoch 57: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 1.1097 - categorical_accuracy: 0.6252 - f1_score: 0.6032 - val_loss: 1.0493 - val_categorical_accuracy: 0.6924 - val_f1_score: 0.6545\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1190 - categorical_accuracy: 0.6256 - f1_score: 0.6140\n",
      "Epoch 58: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.1190 - categorical_accuracy: 0.6256 - f1_score: 0.6140 - val_loss: 1.0769 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6401\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1176 - categorical_accuracy: 0.6295 - f1_score: 0.6246\n",
      "Epoch 59: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.1176 - categorical_accuracy: 0.6295 - f1_score: 0.6246 - val_loss: 1.0485 - val_categorical_accuracy: 0.6890 - val_f1_score: 0.6586\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1128 - categorical_accuracy: 0.6312 - f1_score: 0.6210\n",
      "Epoch 60: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.1128 - categorical_accuracy: 0.6312 - f1_score: 0.6210 - val_loss: 1.0739 - val_categorical_accuracy: 0.6564 - val_f1_score: 0.6303\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1041 - categorical_accuracy: 0.6351 - f1_score: 0.6240\n",
      "Epoch 61: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1041 - categorical_accuracy: 0.6351 - f1_score: 0.6240 - val_loss: 1.0746 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6442\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1024 - categorical_accuracy: 0.6316 - f1_score: 0.6122\n",
      "Epoch 62: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 139s 2s/step - loss: 1.1024 - categorical_accuracy: 0.6316 - f1_score: 0.6122 - val_loss: 1.0579 - val_categorical_accuracy: 0.6873 - val_f1_score: 0.6566\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1139 - categorical_accuracy: 0.6325 - f1_score: 0.6154\n",
      "Epoch 63: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 139s 2s/step - loss: 1.1139 - categorical_accuracy: 0.6325 - f1_score: 0.6154 - val_loss: 1.0726 - val_categorical_accuracy: 0.6873 - val_f1_score: 0.6525\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1007 - categorical_accuracy: 0.6441 - f1_score: 0.6287\n",
      "Epoch 64: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 140s 2s/step - loss: 1.1007 - categorical_accuracy: 0.6441 - f1_score: 0.6287 - val_loss: 1.0668 - val_categorical_accuracy: 0.6718 - val_f1_score: 0.6439\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 17, 100)           643300    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 17, 256)           234496    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4352)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               557184    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1435625 (5.48 MB)\n",
      "Trainable params: 792325 (3.02 MB)\n",
      "Non-trainable params: 643300 (2.45 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 17:06:22.300897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - ETA: 0s - loss: 4.0819 - categorical_accuracy: 0.2907 - f1_score: 0.2848"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 17:08:44.171111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 4.0819 - categorical_accuracy: 0.2907 - f1_score: 0.2848 - val_loss: 2.9677 - val_categorical_accuracy: 0.3918 - val_f1_score: 0.3004\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 2.7289 - categorical_accuracy: 0.3611 - f1_score: 0.3483\n",
      "Epoch 2: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 144s 2s/step - loss: 2.7289 - categorical_accuracy: 0.3611 - f1_score: 0.3483 - val_loss: 2.2486 - val_categorical_accuracy: 0.5155 - val_f1_score: 0.4676\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 2.2006 - categorical_accuracy: 0.3679 - f1_score: 0.3481\n",
      "Epoch 3: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 147s 2s/step - loss: 2.2006 - categorical_accuracy: 0.3679 - f1_score: 0.3481 - val_loss: 1.9084 - val_categorical_accuracy: 0.5258 - val_f1_score: 0.4852\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.9356 - categorical_accuracy: 0.4009 - f1_score: 0.4022\n",
      "Epoch 4: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.9356 - categorical_accuracy: 0.4009 - f1_score: 0.4022 - val_loss: 1.7167 - val_categorical_accuracy: 0.5739 - val_f1_score: 0.5127\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.7670 - categorical_accuracy: 0.4117 - f1_score: 0.3940\n",
      "Epoch 5: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 151s 2s/step - loss: 1.7670 - categorical_accuracy: 0.4117 - f1_score: 0.3940 - val_loss: 1.6060 - val_categorical_accuracy: 0.5928 - val_f1_score: 0.5338\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.6812 - categorical_accuracy: 0.4297 - f1_score: 0.4186\n",
      "Epoch 6: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.6812 - categorical_accuracy: 0.4297 - f1_score: 0.4186 - val_loss: 1.5276 - val_categorical_accuracy: 0.5876 - val_f1_score: 0.5536\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.6344 - categorical_accuracy: 0.4228 - f1_score: 0.4025\n",
      "Epoch 7: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 145s 2s/step - loss: 1.6344 - categorical_accuracy: 0.4228 - f1_score: 0.4025 - val_loss: 1.4955 - val_categorical_accuracy: 0.5722 - val_f1_score: 0.5158\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.5702 - categorical_accuracy: 0.4340 - f1_score: 0.4267\n",
      "Epoch 8: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 146s 2s/step - loss: 1.5702 - categorical_accuracy: 0.4340 - f1_score: 0.4267 - val_loss: 1.4277 - val_categorical_accuracy: 0.5619 - val_f1_score: 0.4265\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.5592 - categorical_accuracy: 0.4288 - f1_score: 0.4157\n",
      "Epoch 9: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 147s 2s/step - loss: 1.5592 - categorical_accuracy: 0.4288 - f1_score: 0.4157 - val_loss: 1.4203 - val_categorical_accuracy: 0.6031 - val_f1_score: 0.5997\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.5310 - categorical_accuracy: 0.4331 - f1_score: 0.4208\n",
      "Epoch 10: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 142s 2s/step - loss: 1.5310 - categorical_accuracy: 0.4331 - f1_score: 0.4208 - val_loss: 1.4238 - val_categorical_accuracy: 0.5550 - val_f1_score: 0.5179\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4704 - categorical_accuracy: 0.4708 - f1_score: 0.4633\n",
      "Epoch 11: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 146s 2s/step - loss: 1.4704 - categorical_accuracy: 0.4708 - f1_score: 0.4633 - val_loss: 1.3731 - val_categorical_accuracy: 0.6151 - val_f1_score: 0.5899\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4859 - categorical_accuracy: 0.4687 - f1_score: 0.4608\n",
      "Epoch 12: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.4859 - categorical_accuracy: 0.4687 - f1_score: 0.4608 - val_loss: 1.3714 - val_categorical_accuracy: 0.6203 - val_f1_score: 0.5987\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4668 - categorical_accuracy: 0.4734 - f1_score: 0.4559\n",
      "Epoch 13: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 151s 2s/step - loss: 1.4668 - categorical_accuracy: 0.4734 - f1_score: 0.4559 - val_loss: 1.3454 - val_categorical_accuracy: 0.6100 - val_f1_score: 0.5770\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4433 - categorical_accuracy: 0.4910 - f1_score: 0.4716\n",
      "Epoch 14: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 152s 2s/step - loss: 1.4433 - categorical_accuracy: 0.4910 - f1_score: 0.4716 - val_loss: 1.3173 - val_categorical_accuracy: 0.6031 - val_f1_score: 0.5783\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4235 - categorical_accuracy: 0.4764 - f1_score: 0.4644\n",
      "Epoch 15: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 158s 2s/step - loss: 1.4235 - categorical_accuracy: 0.4764 - f1_score: 0.4644 - val_loss: 1.3172 - val_categorical_accuracy: 0.6409 - val_f1_score: 0.6096\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4458 - categorical_accuracy: 0.4734 - f1_score: 0.4551\n",
      "Epoch 16: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 198s 3s/step - loss: 1.4458 - categorical_accuracy: 0.4734 - f1_score: 0.4551 - val_loss: 1.3221 - val_categorical_accuracy: 0.6014 - val_f1_score: 0.5342\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4057 - categorical_accuracy: 0.5009 - f1_score: 0.4968\n",
      "Epoch 17: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 223s 3s/step - loss: 1.4057 - categorical_accuracy: 0.5009 - f1_score: 0.4968 - val_loss: 1.2912 - val_categorical_accuracy: 0.6168 - val_f1_score: 0.5874\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4132 - categorical_accuracy: 0.4889 - f1_score: 0.4670\n",
      "Epoch 18: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 160s 2s/step - loss: 1.4132 - categorical_accuracy: 0.4889 - f1_score: 0.4670 - val_loss: 1.2853 - val_categorical_accuracy: 0.6306 - val_f1_score: 0.5817\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4033 - categorical_accuracy: 0.5060 - f1_score: 0.4983\n",
      "Epoch 19: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 155s 2s/step - loss: 1.4033 - categorical_accuracy: 0.5060 - f1_score: 0.4983 - val_loss: 1.2939 - val_categorical_accuracy: 0.6460 - val_f1_score: 0.6098\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3920 - categorical_accuracy: 0.5000 - f1_score: 0.4922\n",
      "Epoch 20: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 155s 2s/step - loss: 1.3920 - categorical_accuracy: 0.5000 - f1_score: 0.4922 - val_loss: 1.2500 - val_categorical_accuracy: 0.6460 - val_f1_score: 0.6103\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3465 - categorical_accuracy: 0.5210 - f1_score: 0.5141\n",
      "Epoch 21: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 158s 2s/step - loss: 1.3465 - categorical_accuracy: 0.5210 - f1_score: 0.5141 - val_loss: 1.2854 - val_categorical_accuracy: 0.6581 - val_f1_score: 0.6197\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3463 - categorical_accuracy: 0.5227 - f1_score: 0.5102\n",
      "Epoch 22: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 209s 3s/step - loss: 1.3463 - categorical_accuracy: 0.5227 - f1_score: 0.5102 - val_loss: 1.2738 - val_categorical_accuracy: 0.6443 - val_f1_score: 0.6096\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3660 - categorical_accuracy: 0.5227 - f1_score: 0.5192\n",
      "Epoch 23: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 227s 3s/step - loss: 1.3660 - categorical_accuracy: 0.5227 - f1_score: 0.5192 - val_loss: 1.2676 - val_categorical_accuracy: 0.6082 - val_f1_score: 0.5343\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3524 - categorical_accuracy: 0.5210 - f1_score: 0.5289\n",
      "Epoch 24: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 184s 3s/step - loss: 1.3524 - categorical_accuracy: 0.5210 - f1_score: 0.5289 - val_loss: 1.2514 - val_categorical_accuracy: 0.6375 - val_f1_score: 0.5992\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3637 - categorical_accuracy: 0.5116 - f1_score: 0.5020\n",
      "Epoch 25: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 171s 2s/step - loss: 1.3637 - categorical_accuracy: 0.5116 - f1_score: 0.5020 - val_loss: 1.2415 - val_categorical_accuracy: 0.6460 - val_f1_score: 0.6099\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3138 - categorical_accuracy: 0.5455 - f1_score: 0.5353\n",
      "Epoch 26: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.3138 - categorical_accuracy: 0.5455 - f1_score: 0.5353 - val_loss: 1.2105 - val_categorical_accuracy: 0.6460 - val_f1_score: 0.6061\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3056 - categorical_accuracy: 0.5326 - f1_score: 0.5232\n",
      "Epoch 27: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 159s 2s/step - loss: 1.3056 - categorical_accuracy: 0.5326 - f1_score: 0.5232 - val_loss: 1.2317 - val_categorical_accuracy: 0.6409 - val_f1_score: 0.6177\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3028 - categorical_accuracy: 0.5390 - f1_score: 0.5267\n",
      "Epoch 28: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.3028 - categorical_accuracy: 0.5390 - f1_score: 0.5267 - val_loss: 1.2135 - val_categorical_accuracy: 0.6392 - val_f1_score: 0.6009\n",
      "Epoch 29/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3074 - categorical_accuracy: 0.5266 - f1_score: 0.5117\n",
      "Epoch 29: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 156s 2s/step - loss: 1.3074 - categorical_accuracy: 0.5266 - f1_score: 0.5117 - val_loss: 1.2060 - val_categorical_accuracy: 0.6375 - val_f1_score: 0.5715\n",
      "Epoch 30/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2960 - categorical_accuracy: 0.5630 - f1_score: 0.5461\n",
      "Epoch 30: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 163s 2s/step - loss: 1.2960 - categorical_accuracy: 0.5630 - f1_score: 0.5461 - val_loss: 1.2210 - val_categorical_accuracy: 0.6495 - val_f1_score: 0.6126\n",
      "Epoch 31/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3133 - categorical_accuracy: 0.5343 - f1_score: 0.5284\n",
      "Epoch 31: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 167s 2s/step - loss: 1.3133 - categorical_accuracy: 0.5343 - f1_score: 0.5284 - val_loss: 1.2067 - val_categorical_accuracy: 0.6615 - val_f1_score: 0.6317\n",
      "Epoch 32/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3150 - categorical_accuracy: 0.5506 - f1_score: 0.5422\n",
      "Epoch 32: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 134s 2s/step - loss: 1.3150 - categorical_accuracy: 0.5506 - f1_score: 0.5422 - val_loss: 1.1904 - val_categorical_accuracy: 0.6546 - val_f1_score: 0.6230\n",
      "Epoch 33/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3012 - categorical_accuracy: 0.5407 - f1_score: 0.5342\n",
      "Epoch 33: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 132s 2s/step - loss: 1.3012 - categorical_accuracy: 0.5407 - f1_score: 0.5342 - val_loss: 1.1931 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.5934\n",
      "Epoch 34/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2893 - categorical_accuracy: 0.5386 - f1_score: 0.5290\n",
      "Epoch 34: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 159s 2s/step - loss: 1.2893 - categorical_accuracy: 0.5386 - f1_score: 0.5290 - val_loss: 1.2037 - val_categorical_accuracy: 0.6615 - val_f1_score: 0.6476\n",
      "Epoch 35/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2851 - categorical_accuracy: 0.5433 - f1_score: 0.5436\n",
      "Epoch 35: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 146s 2s/step - loss: 1.2851 - categorical_accuracy: 0.5433 - f1_score: 0.5436 - val_loss: 1.1949 - val_categorical_accuracy: 0.6512 - val_f1_score: 0.6099\n",
      "Epoch 36/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2795 - categorical_accuracy: 0.5617 - f1_score: 0.5481\n",
      "Epoch 36: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 152s 2s/step - loss: 1.2795 - categorical_accuracy: 0.5617 - f1_score: 0.5481 - val_loss: 1.1654 - val_categorical_accuracy: 0.6581 - val_f1_score: 0.6166\n",
      "Epoch 37/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2789 - categorical_accuracy: 0.5605 - f1_score: 0.5501\n",
      "Epoch 37: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 144s 2s/step - loss: 1.2789 - categorical_accuracy: 0.5605 - f1_score: 0.5501 - val_loss: 1.1827 - val_categorical_accuracy: 0.6581 - val_f1_score: 0.6202\n",
      "Epoch 38/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2713 - categorical_accuracy: 0.5553 - f1_score: 0.5450\n",
      "Epoch 38: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.2713 - categorical_accuracy: 0.5553 - f1_score: 0.5450 - val_loss: 1.1770 - val_categorical_accuracy: 0.6804 - val_f1_score: 0.6401\n",
      "Epoch 39/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2797 - categorical_accuracy: 0.5566 - f1_score: 0.5331\n",
      "Epoch 39: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 145s 2s/step - loss: 1.2797 - categorical_accuracy: 0.5566 - f1_score: 0.5331 - val_loss: 1.1689 - val_categorical_accuracy: 0.6718 - val_f1_score: 0.6248\n",
      "Epoch 40/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2599 - categorical_accuracy: 0.5566 - f1_score: 0.5517\n",
      "Epoch 40: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 284s 4s/step - loss: 1.2599 - categorical_accuracy: 0.5566 - f1_score: 0.5517 - val_loss: 1.1730 - val_categorical_accuracy: 0.6564 - val_f1_score: 0.6239\n",
      "Epoch 41/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2644 - categorical_accuracy: 0.5596 - f1_score: 0.5552 \n",
      "Epoch 41: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 1420s 20s/step - loss: 1.2644 - categorical_accuracy: 0.5596 - f1_score: 0.5552 - val_loss: 1.1873 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6365\n",
      "Epoch 42/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2616 - categorical_accuracy: 0.5596 - f1_score: 0.5527\n",
      "Epoch 42: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 230s 3s/step - loss: 1.2616 - categorical_accuracy: 0.5596 - f1_score: 0.5527 - val_loss: 1.1737 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6308\n",
      "Epoch 43/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2707 - categorical_accuracy: 0.5639 - f1_score: 0.5410\n",
      "Epoch 43: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 156s 2s/step - loss: 1.2707 - categorical_accuracy: 0.5639 - f1_score: 0.5410 - val_loss: 1.1705 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6302\n",
      "Epoch 44/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2628 - categorical_accuracy: 0.5630 - f1_score: 0.5504\n",
      "Epoch 44: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 151s 2s/step - loss: 1.2628 - categorical_accuracy: 0.5630 - f1_score: 0.5504 - val_loss: 1.1686 - val_categorical_accuracy: 0.6615 - val_f1_score: 0.6238\n",
      "Epoch 45/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2592 - categorical_accuracy: 0.5617 - f1_score: 0.5416\n",
      "Epoch 45: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 152s 2s/step - loss: 1.2592 - categorical_accuracy: 0.5617 - f1_score: 0.5416 - val_loss: 1.1581 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6349\n",
      "Epoch 46/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2396 - categorical_accuracy: 0.5725 - f1_score: 0.5605\n",
      "Epoch 46: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.2396 - categorical_accuracy: 0.5725 - f1_score: 0.5605 - val_loss: 1.1629 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.6301\n",
      "Epoch 47/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2556 - categorical_accuracy: 0.5553 - f1_score: 0.5578\n",
      "Epoch 47: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 151s 2s/step - loss: 1.2556 - categorical_accuracy: 0.5553 - f1_score: 0.5578 - val_loss: 1.1759 - val_categorical_accuracy: 0.6718 - val_f1_score: 0.6296\n",
      "Epoch 48/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2530 - categorical_accuracy: 0.5673 - f1_score: 0.5558\n",
      "Epoch 48: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.2530 - categorical_accuracy: 0.5673 - f1_score: 0.5558 - val_loss: 1.1659 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6387\n",
      "Epoch 49/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2280 - categorical_accuracy: 0.5669 - f1_score: 0.5448\n",
      "Epoch 49: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 141s 2s/step - loss: 1.2280 - categorical_accuracy: 0.5669 - f1_score: 0.5448 - val_loss: 1.1540 - val_categorical_accuracy: 0.6804 - val_f1_score: 0.6476\n",
      "Epoch 50/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2377 - categorical_accuracy: 0.5806 - f1_score: 0.5684\n",
      "Epoch 50: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 146s 2s/step - loss: 1.2377 - categorical_accuracy: 0.5806 - f1_score: 0.5684 - val_loss: 1.1460 - val_categorical_accuracy: 0.6873 - val_f1_score: 0.6558\n",
      "Epoch 51/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2343 - categorical_accuracy: 0.5750 - f1_score: 0.5641\n",
      "Epoch 51: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 1.2343 - categorical_accuracy: 0.5750 - f1_score: 0.5641 - val_loss: 1.1576 - val_categorical_accuracy: 0.6667 - val_f1_score: 0.6289\n",
      "Epoch 52/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2452 - categorical_accuracy: 0.5772 - f1_score: 0.5733\n",
      "Epoch 52: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.2452 - categorical_accuracy: 0.5772 - f1_score: 0.5733 - val_loss: 1.1518 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6332\n",
      "Epoch 53/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2322 - categorical_accuracy: 0.5703 - f1_score: 0.5652\n",
      "Epoch 53: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 143s 2s/step - loss: 1.2322 - categorical_accuracy: 0.5703 - f1_score: 0.5652 - val_loss: 1.1422 - val_categorical_accuracy: 0.6770 - val_f1_score: 0.6485\n",
      "Epoch 54/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2432 - categorical_accuracy: 0.5660 - f1_score: 0.5498\n",
      "Epoch 54: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 146s 2s/step - loss: 1.2432 - categorical_accuracy: 0.5660 - f1_score: 0.5498 - val_loss: 1.1403 - val_categorical_accuracy: 0.6667 - val_f1_score: 0.6379\n",
      "Epoch 55/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2107 - categorical_accuracy: 0.5909 - f1_score: 0.5915\n",
      "Epoch 55: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.2107 - categorical_accuracy: 0.5909 - f1_score: 0.5915 - val_loss: 1.1366 - val_categorical_accuracy: 0.6667 - val_f1_score: 0.6052\n",
      "Epoch 56/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2398 - categorical_accuracy: 0.5643 - f1_score: 0.5572\n",
      "Epoch 56: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 133s 2s/step - loss: 1.2398 - categorical_accuracy: 0.5643 - f1_score: 0.5572 - val_loss: 1.1375 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6377\n",
      "Epoch 57/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2415 - categorical_accuracy: 0.5755 - f1_score: 0.5716\n",
      "Epoch 57: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 102s 1s/step - loss: 1.2415 - categorical_accuracy: 0.5755 - f1_score: 0.5716 - val_loss: 1.1313 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6371\n",
      "Epoch 58/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2141 - categorical_accuracy: 0.5883 - f1_score: 0.5796\n",
      "Epoch 58: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.2141 - categorical_accuracy: 0.5883 - f1_score: 0.5796 - val_loss: 1.1222 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6201\n",
      "Epoch 59/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2405 - categorical_accuracy: 0.5780 - f1_score: 0.5641\n",
      "Epoch 59: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.2405 - categorical_accuracy: 0.5780 - f1_score: 0.5641 - val_loss: 1.1401 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6335\n",
      "Epoch 60/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2057 - categorical_accuracy: 0.5862 - f1_score: 0.5836\n",
      "Epoch 60: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 98s 1s/step - loss: 1.2057 - categorical_accuracy: 0.5862 - f1_score: 0.5836 - val_loss: 1.1409 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6363\n",
      "Epoch 61/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2126 - categorical_accuracy: 0.5742 - f1_score: 0.5631\n",
      "Epoch 61: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.2126 - categorical_accuracy: 0.5742 - f1_score: 0.5631 - val_loss: 1.1478 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6284\n",
      "Epoch 62/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2237 - categorical_accuracy: 0.5626 - f1_score: 0.5472\n",
      "Epoch 62: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 101s 1s/step - loss: 1.2237 - categorical_accuracy: 0.5626 - f1_score: 0.5472 - val_loss: 1.1368 - val_categorical_accuracy: 0.6804 - val_f1_score: 0.6412\n",
      "Epoch 63/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2250 - categorical_accuracy: 0.5870 - f1_score: 0.5660\n",
      "Epoch 63: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 102s 1s/step - loss: 1.2250 - categorical_accuracy: 0.5870 - f1_score: 0.5660 - val_loss: 1.1213 - val_categorical_accuracy: 0.6718 - val_f1_score: 0.6408\n",
      "Epoch 64/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2194 - categorical_accuracy: 0.5725 - f1_score: 0.5631\n",
      "Epoch 64: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 101s 1s/step - loss: 1.2194 - categorical_accuracy: 0.5725 - f1_score: 0.5631 - val_loss: 1.1201 - val_categorical_accuracy: 0.6667 - val_f1_score: 0.6345\n",
      "Epoch 65/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1970 - categorical_accuracy: 0.5901 - f1_score: 0.5774\n",
      "Epoch 65: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.1970 - categorical_accuracy: 0.5901 - f1_score: 0.5774 - val_loss: 1.1309 - val_categorical_accuracy: 0.6770 - val_f1_score: 0.6447\n",
      "Epoch 66/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2032 - categorical_accuracy: 0.5879 - f1_score: 0.5827\n",
      "Epoch 66: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 100s 1s/step - loss: 1.2032 - categorical_accuracy: 0.5879 - f1_score: 0.5827 - val_loss: 1.1280 - val_categorical_accuracy: 0.6615 - val_f1_score: 0.6239\n",
      "Epoch 67/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2221 - categorical_accuracy: 0.5840 - f1_score: 0.5801\n",
      "Epoch 67: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 102s 1s/step - loss: 1.2221 - categorical_accuracy: 0.5840 - f1_score: 0.5801 - val_loss: 1.1424 - val_categorical_accuracy: 0.6804 - val_f1_score: 0.6551\n",
      "Epoch 68/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2274 - categorical_accuracy: 0.5793 - f1_score: 0.5741\n",
      "Epoch 68: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 107s 1s/step - loss: 1.2274 - categorical_accuracy: 0.5793 - f1_score: 0.5741 - val_loss: 1.1307 - val_categorical_accuracy: 0.6838 - val_f1_score: 0.6507\n",
      "Epoch 69/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2254 - categorical_accuracy: 0.5836 - f1_score: 0.5708\n",
      "Epoch 69: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 105s 1s/step - loss: 1.2254 - categorical_accuracy: 0.5836 - f1_score: 0.5708 - val_loss: 1.1357 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6368\n",
      "Epoch 70/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1729 - categorical_accuracy: 0.6068 - f1_score: 0.5991\n",
      "Epoch 70: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 104s 1s/step - loss: 1.1729 - categorical_accuracy: 0.6068 - f1_score: 0.5991 - val_loss: 1.1115 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6315\n",
      "Epoch 71/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1990 - categorical_accuracy: 0.5939 - f1_score: 0.5773\n",
      "Epoch 71: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 104s 1s/step - loss: 1.1990 - categorical_accuracy: 0.5939 - f1_score: 0.5773 - val_loss: 1.1253 - val_categorical_accuracy: 0.6701 - val_f1_score: 0.6313\n",
      "Epoch 72/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2196 - categorical_accuracy: 0.5866 - f1_score: 0.5724\n",
      "Epoch 72: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 110s 2s/step - loss: 1.2196 - categorical_accuracy: 0.5866 - f1_score: 0.5724 - val_loss: 1.1389 - val_categorical_accuracy: 0.6598 - val_f1_score: 0.6224\n",
      "Epoch 73/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2217 - categorical_accuracy: 0.5836 - f1_score: 0.5833\n",
      "Epoch 73: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 114s 2s/step - loss: 1.2217 - categorical_accuracy: 0.5836 - f1_score: 0.5833 - val_loss: 1.1314 - val_categorical_accuracy: 0.6701 - val_f1_score: 0.6371\n",
      "Epoch 74/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2055 - categorical_accuracy: 0.5858 - f1_score: 0.5720\n",
      "Epoch 74: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 120s 2s/step - loss: 1.2055 - categorical_accuracy: 0.5858 - f1_score: 0.5720 - val_loss: 1.1175 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6376\n",
      "Epoch 75/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2057 - categorical_accuracy: 0.5896 - f1_score: 0.5825\n",
      "Epoch 75: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 155s 2s/step - loss: 1.2057 - categorical_accuracy: 0.5896 - f1_score: 0.5825 - val_loss: 1.1349 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6301\n",
      "Epoch 76/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2144 - categorical_accuracy: 0.5862 - f1_score: 0.5706\n",
      "Epoch 76: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 153s 2s/step - loss: 1.2144 - categorical_accuracy: 0.5862 - f1_score: 0.5706 - val_loss: 1.1231 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6413\n",
      "Epoch 77/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2051 - categorical_accuracy: 0.5943 - f1_score: 0.5733\n",
      "Epoch 77: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 148s 2s/step - loss: 1.2051 - categorical_accuracy: 0.5943 - f1_score: 0.5733 - val_loss: 1.1343 - val_categorical_accuracy: 0.6667 - val_f1_score: 0.6343\n",
      "Epoch 78/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2215 - categorical_accuracy: 0.5935 - f1_score: 0.5921\n",
      "Epoch 78: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 139s 2s/step - loss: 1.2215 - categorical_accuracy: 0.5935 - f1_score: 0.5921 - val_loss: 1.1265 - val_categorical_accuracy: 0.6770 - val_f1_score: 0.6490\n",
      "Epoch 79/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2031 - categorical_accuracy: 0.5926 - f1_score: 0.5807\n",
      "Epoch 79: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 145s 2s/step - loss: 1.2031 - categorical_accuracy: 0.5926 - f1_score: 0.5807 - val_loss: 1.1326 - val_categorical_accuracy: 0.6735 - val_f1_score: 0.6207\n",
      "Epoch 80/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2028 - categorical_accuracy: 0.5862 - f1_score: 0.5710\n",
      "Epoch 80: saving model to ./models/base_target_with_TL_h_0.005\n",
      "73/73 [==============================] - 147s 2s/step - loss: 1.2028 - categorical_accuracy: 0.5862 - f1_score: 0.5710 - val_loss: 1.1246 - val_categorical_accuracy: 0.6856 - val_f1_score: 0.6468\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 17, 100)           643300    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 17, 256)           234496    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4352)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               557184    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1435625 (5.48 MB)\n",
      "Trainable params: 792325 (3.02 MB)\n",
      "Non-trainable params: 643300 (2.45 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 20:41:09.270201: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - ETA: 0s - loss: 2.2147 - categorical_accuracy: 0.3379 - f1_score: 0.3229"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 20:43:39.996177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 158s 2s/step - loss: 2.2147 - categorical_accuracy: 0.3379 - f1_score: 0.3229 - val_loss: 1.6720 - val_categorical_accuracy: 0.5928 - val_f1_score: 0.5025\n",
      "Epoch 2/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.8395 - categorical_accuracy: 0.4288 - f1_score: 0.4110\n",
      "Epoch 2: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.8395 - categorical_accuracy: 0.4288 - f1_score: 0.4110 - val_loss: 1.5381 - val_categorical_accuracy: 0.6203 - val_f1_score: 0.5684\n",
      "Epoch 3/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.6921 - categorical_accuracy: 0.4687 - f1_score: 0.4605\n",
      "Epoch 3: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 153s 2s/step - loss: 1.6921 - categorical_accuracy: 0.4687 - f1_score: 0.4605 - val_loss: 1.4008 - val_categorical_accuracy: 0.5962 - val_f1_score: 0.5034\n",
      "Epoch 4/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.5701 - categorical_accuracy: 0.5206 - f1_score: 0.5033\n",
      "Epoch 4: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.5701 - categorical_accuracy: 0.5206 - f1_score: 0.5033 - val_loss: 1.3420 - val_categorical_accuracy: 0.6014 - val_f1_score: 0.5106\n",
      "Epoch 5/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.5410 - categorical_accuracy: 0.5129 - f1_score: 0.4914\n",
      "Epoch 5: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.5410 - categorical_accuracy: 0.5129 - f1_score: 0.4914 - val_loss: 1.2896 - val_categorical_accuracy: 0.6495 - val_f1_score: 0.5986\n",
      "Epoch 6/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4404 - categorical_accuracy: 0.5326 - f1_score: 0.5040\n",
      "Epoch 6: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 150s 2s/step - loss: 1.4404 - categorical_accuracy: 0.5326 - f1_score: 0.5040 - val_loss: 1.2565 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6217\n",
      "Epoch 7/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.4176 - categorical_accuracy: 0.5459 - f1_score: 0.5362\n",
      "Epoch 7: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 149s 2s/step - loss: 1.4176 - categorical_accuracy: 0.5459 - f1_score: 0.5362 - val_loss: 1.2281 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.6043\n",
      "Epoch 8/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3620 - categorical_accuracy: 0.5566 - f1_score: 0.5496\n",
      "Epoch 8: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 154s 2s/step - loss: 1.3620 - categorical_accuracy: 0.5566 - f1_score: 0.5496 - val_loss: 1.2011 - val_categorical_accuracy: 0.6667 - val_f1_score: 0.6054\n",
      "Epoch 9/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3580 - categorical_accuracy: 0.5502 - f1_score: 0.5365\n",
      "Epoch 9: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 158s 2s/step - loss: 1.3580 - categorical_accuracy: 0.5502 - f1_score: 0.5365 - val_loss: 1.2072 - val_categorical_accuracy: 0.6375 - val_f1_score: 0.5849\n",
      "Epoch 10/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3239 - categorical_accuracy: 0.5703 - f1_score: 0.5473\n",
      "Epoch 10: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 161s 2s/step - loss: 1.3239 - categorical_accuracy: 0.5703 - f1_score: 0.5473 - val_loss: 1.1609 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6196\n",
      "Epoch 11/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3330 - categorical_accuracy: 0.5575 - f1_score: 0.5498\n",
      "Epoch 11: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 164s 2s/step - loss: 1.3330 - categorical_accuracy: 0.5575 - f1_score: 0.5498 - val_loss: 1.1582 - val_categorical_accuracy: 0.6529 - val_f1_score: 0.6319\n",
      "Epoch 12/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.3161 - categorical_accuracy: 0.5545 - f1_score: 0.5327\n",
      "Epoch 12: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 154s 2s/step - loss: 1.3161 - categorical_accuracy: 0.5545 - f1_score: 0.5327 - val_loss: 1.1624 - val_categorical_accuracy: 0.6512 - val_f1_score: 0.6128\n",
      "Epoch 13/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2630 - categorical_accuracy: 0.5780 - f1_score: 0.5652\n",
      "Epoch 13: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 152s 2s/step - loss: 1.2630 - categorical_accuracy: 0.5780 - f1_score: 0.5652 - val_loss: 1.1339 - val_categorical_accuracy: 0.6701 - val_f1_score: 0.6381\n",
      "Epoch 14/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2610 - categorical_accuracy: 0.5738 - f1_score: 0.5592\n",
      "Epoch 14: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 155s 2s/step - loss: 1.2610 - categorical_accuracy: 0.5738 - f1_score: 0.5592 - val_loss: 1.1429 - val_categorical_accuracy: 0.6615 - val_f1_score: 0.6121\n",
      "Epoch 15/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2421 - categorical_accuracy: 0.5853 - f1_score: 0.5723\n",
      "Epoch 15: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 156s 2s/step - loss: 1.2421 - categorical_accuracy: 0.5853 - f1_score: 0.5723 - val_loss: 1.1195 - val_categorical_accuracy: 0.6564 - val_f1_score: 0.6108\n",
      "Epoch 16/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2400 - categorical_accuracy: 0.5785 - f1_score: 0.5551\n",
      "Epoch 16: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 157s 2s/step - loss: 1.2400 - categorical_accuracy: 0.5785 - f1_score: 0.5551 - val_loss: 1.1261 - val_categorical_accuracy: 0.6426 - val_f1_score: 0.5927\n",
      "Epoch 17/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2374 - categorical_accuracy: 0.5712 - f1_score: 0.5486\n",
      "Epoch 17: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 154s 2s/step - loss: 1.2374 - categorical_accuracy: 0.5712 - f1_score: 0.5486 - val_loss: 1.1231 - val_categorical_accuracy: 0.6615 - val_f1_score: 0.6247\n",
      "Epoch 18/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.2435 - categorical_accuracy: 0.5815 - f1_score: 0.5668\n",
      "Epoch 18: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 159s 2s/step - loss: 1.2435 - categorical_accuracy: 0.5815 - f1_score: 0.5668 - val_loss: 1.1113 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6234\n",
      "Epoch 19/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1996 - categorical_accuracy: 0.5991 - f1_score: 0.5786\n",
      "Epoch 19: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 164s 2s/step - loss: 1.1996 - categorical_accuracy: 0.5991 - f1_score: 0.5786 - val_loss: 1.0978 - val_categorical_accuracy: 0.6838 - val_f1_score: 0.6363\n",
      "Epoch 20/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1867 - categorical_accuracy: 0.5952 - f1_score: 0.5794\n",
      "Epoch 20: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 161s 2s/step - loss: 1.1867 - categorical_accuracy: 0.5952 - f1_score: 0.5794 - val_loss: 1.1130 - val_categorical_accuracy: 0.6581 - val_f1_score: 0.6234\n",
      "Epoch 21/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1859 - categorical_accuracy: 0.5978 - f1_score: 0.5758\n",
      "Epoch 21: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 116s 2s/step - loss: 1.1859 - categorical_accuracy: 0.5978 - f1_score: 0.5758 - val_loss: 1.0901 - val_categorical_accuracy: 0.6804 - val_f1_score: 0.6358\n",
      "Epoch 22/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1804 - categorical_accuracy: 0.5965 - f1_score: 0.5721\n",
      "Epoch 22: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 116s 2s/step - loss: 1.1804 - categorical_accuracy: 0.5965 - f1_score: 0.5721 - val_loss: 1.0878 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6195\n",
      "Epoch 23/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1583 - categorical_accuracy: 0.6295 - f1_score: 0.6075\n",
      "Epoch 23: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 121s 2s/step - loss: 1.1583 - categorical_accuracy: 0.6295 - f1_score: 0.6075 - val_loss: 1.0765 - val_categorical_accuracy: 0.6701 - val_f1_score: 0.6244\n",
      "Epoch 24/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1725 - categorical_accuracy: 0.6033 - f1_score: 0.5923\n",
      "Epoch 24: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 119s 2s/step - loss: 1.1725 - categorical_accuracy: 0.6033 - f1_score: 0.5923 - val_loss: 1.0953 - val_categorical_accuracy: 0.6632 - val_f1_score: 0.6348\n",
      "Epoch 25/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1480 - categorical_accuracy: 0.6149 - f1_score: 0.6035\n",
      "Epoch 25: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 110s 2s/step - loss: 1.1480 - categorical_accuracy: 0.6149 - f1_score: 0.6035 - val_loss: 1.0756 - val_categorical_accuracy: 0.6581 - val_f1_score: 0.6293\n",
      "Epoch 26/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1508 - categorical_accuracy: 0.6239 - f1_score: 0.6140\n",
      "Epoch 26: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 107s 1s/step - loss: 1.1508 - categorical_accuracy: 0.6239 - f1_score: 0.6140 - val_loss: 1.0669 - val_categorical_accuracy: 0.6649 - val_f1_score: 0.6191\n",
      "Epoch 27/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1509 - categorical_accuracy: 0.6154 - f1_score: 0.6011\n",
      "Epoch 27: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 108s 1s/step - loss: 1.1509 - categorical_accuracy: 0.6154 - f1_score: 0.6011 - val_loss: 1.0670 - val_categorical_accuracy: 0.6753 - val_f1_score: 0.6201\n",
      "Epoch 28/100\n",
      "73/73 [==============================] - ETA: 0s - loss: 1.1259 - categorical_accuracy: 0.6282 - f1_score: 0.6108\n",
      "Epoch 28: saving model to ./models/base_target_with_TL_h_0.001\n",
      "73/73 [==============================] - 109s 1s/step - loss: 1.1259 - categorical_accuracy: 0.6282 - f1_score: 0.6108 - val_loss: 1.0644 - val_categorical_accuracy: 0.6684 - val_f1_score: 0.6402\n",
      "Epoch 29/100\n",
      "70/73 [===========================>..] - ETA: 4s - loss: 1.1139 - categorical_accuracy: 0.6281 - f1_score: 0.6066"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m      5\u001b[0m model_target \u001b[38;5;241m=\u001b[39m build_model(\u001b[38;5;28;01mFalse\u001b[39;00m, drop, reg_lambda)\n\u001b[0;32m----> 6\u001b[0m m_histories[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_with_TL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_hp_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(reg_lambda)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(drop)] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_target\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_target_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_callbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/base_target_with_TL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_h_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreg_lambda\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Fit the model for each combination of lambda and dropout values\n",
    "for reg_lambda in lambda_vals:\n",
    "  for drop in dropout_rate:\n",
    "   tf.keras.backend.clear_session()\n",
    "   model_target = build_model(False, drop, reg_lambda)\n",
    "   m_histories['target_with_TL'+ '_hp_' + str(reg_lambda)+str(drop)] = model_target.fit(train_pad, train_target_labels, batch_size=32, epochs=EPOCH, validation_data=(val_pad, val_target_labels), callbacks=get_callbacks('models/base_target_with_TL'+ '_h_' + str(reg_lambda),early_stop=True), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
