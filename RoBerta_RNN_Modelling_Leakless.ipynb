{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zf_qeA1A7JAT"
      },
      "outputs": [],
      "source": [
        "# !pip install plotly\n",
        "# !pip install seaborn\n",
        "# !pip install matplotlib\n",
        "# !pip install transformers\n",
        "# !pip install tokenizers\n",
        "# !pip install scikit-learn\n",
        "# !pip install tensorflow\n",
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install keras_tuner\n",
        "\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQM50iAu7IPf"
      },
      "source": [
        "#\n",
        "<a id=\"data-prep\"></a>\n",
        "<div style=\"background-color: #000D5B; color: white; text-align: center; padding: 6px 0 22px 0\">\n",
        "    <h3 style=\"background-color: #000D5B; color: white; text-align: left\">RMIT School of Computer Science and Technology</h3>\n",
        "    <br/>\n",
        "    <h1>COSC3007: Deep Learning</h1>\n",
        "    <h2>Assignment 2: Stance Twitter Sentiment Analysis and Detection </h2>\n",
        "    <h2> [2] MODELLING AND MODEL EVALUATIONS </h2>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moNIYISM7IPh"
      },
      "source": [
        "# Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v3G_-e3j7IPh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Enfxab1u7IPi"
      },
      "source": [
        "# [1] Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bohs2SFF7IPi"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/StanceDataset/processed_train_augumented_bernie.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "train_ori = train_df.copy()\n",
        "\n",
        "test_df = pd.read_csv(\"./drive/MyDrive/Colab Notebooks/StanceDataset/processed_test_augumented_bernie.csv\", encoding = \"ISO-8859-1\", engine=\"python\").drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBaP0MCGJ3ij",
        "outputId": "f7a69c7f-9f66-4db0-a2eb-3beef7653176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3314\n",
            "1956\n"
          ]
        }
      ],
      "source": [
        "print(len(train_ori))\n",
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtAPp-m17IPi"
      },
      "source": [
        "# [2] Prepare label and fit data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oisebO8u7IPi"
      },
      "source": [
        "## Split test and val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pCBu_71Q7IPj"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['Stance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz2v62Xg7IPj"
      },
      "source": [
        "## Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpUdtQ6y7IPj",
        "outputId": "d113423f-2a9f-4044-f8d5-20347cb2b1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum length across all datasets: 128\n",
            "(2651, 128)\n",
            "(663, 128)\n",
            "(1956, 128)\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFRobertaModel, RobertaTokenizer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the BERT tokenizer\n",
        "MAX_LENGTH = 512\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "roberta_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "\n",
        "# Assuming train_texts, val_texts, test_texts are your datasets\n",
        "train_processed_tweets = train_df['Tweet'].tolist()\n",
        "val_processed_tweets = val_df['Tweet'].tolist()\n",
        "test_processed_tweets = test_df['Tweet'].tolist()\n",
        "\n",
        "all_processed_tweets = train_processed_tweets + val_processed_tweets + test_processed_tweets\n",
        "tokenized_tweets = [tokenizer.encode(tweet, add_special_tokens=True) for tweet in all_processed_tweets]\n",
        "MAX_LENGTH = max(len(tweet) for tweet in tokenized_tweets)\n",
        "MAX_LENGTH = 128\n",
        "\n",
        "print(\"Maximum length across all datasets:\", MAX_LENGTH)\n",
        "\n",
        "target_names = {\n",
        "    0: \"Hillary Clinton\",\n",
        "    1: \"Legalization of Abortion\",\n",
        "    2: \"Atheism\",\n",
        "    3: \"Climate Change is a Real Concern\",\n",
        "    4: \"Feminist Movement\",\n",
        "    5: \"Donald Trump\",\n",
        "    6: \"Joe Biden\",\n",
        "    7: \"Barack Obama\",\n",
        "    8: \"Kamala Harris\",\n",
        "    9: \"Bernie Sanders\",\n",
        "    10: \"Vu\",\n",
        "}\n",
        "\n",
        "def bert_tokenize(texts, targets, max_length=MAX_LENGTH):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for idx, text in enumerate(texts):\n",
        "        targetID = targets[idx]\n",
        "        target_name = target_names.get(targetID, \"\")\n",
        "        formatted_text = f\"<s> {target_name} </s></s> {text} </s>\"\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            formatted_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='tf',\n",
        "        )\n",
        "\n",
        "        # Flatten the tensors and remove the extra dimension\n",
        "        input_ids.append(tf.squeeze(encoded['input_ids'], axis=0))\n",
        "        attention_masks.append(tf.squeeze(encoded['attention_mask'], axis=0))\n",
        "\n",
        "    return np.array(input_ids), np.array(attention_masks)\n",
        "\n",
        "# Assuming you have lists of preprocessed texts for training, validation, and test sets\n",
        "train_input_ids, train_attention_masks = bert_tokenize(train_df['Tweet'],  train_df['Target'].to_list())\n",
        "val_input_ids, val_attention_masks = bert_tokenize(val_df['Tweet'], val_df['Target'].to_list())\n",
        "test_input_ids, test_attention_masks = bert_tokenize(test_df['Tweet'], test_df['Target'].to_list())\n",
        "\n",
        "print(train_input_ids.shape)\n",
        "print(val_input_ids.shape)\n",
        "print(test_input_ids.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wELfIUZC7IPk"
      },
      "source": [
        "## Stances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GizLHQ1j7IPk"
      },
      "outputs": [],
      "source": [
        "def categorized_label(df, label_name):\n",
        "    label_encoder = LabelEncoder()\n",
        "    encoded_labels = label_encoder.fit_transform(df[label_name])\n",
        "    categorical_labels = to_categorical(encoded_labels)\n",
        "    return categorical_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "moCDHvRP7IPk"
      },
      "outputs": [],
      "source": [
        "train_labels = categorized_label(train_df, \"Stance\")\n",
        "test_labels = categorized_label(test_df, \"Stance\")\n",
        "val_labels = categorized_label(val_df, \"Stance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGuLZ7or7IPk"
      },
      "source": [
        "# [3] Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uyYbo9A77IPk"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from hyperopt import hp\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "# import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iuEOWHvi7IPk"
      },
      "outputs": [],
      "source": [
        "def f1_score_class(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    # Convert predictions to one-hot format\n",
        "    y_pred_one_hot = K.one_hot(K.argmax(y_pred), num_classes=3)\n",
        "\n",
        "    # Calculate F1 score for each class\n",
        "    f1s = [f1_score_class(y_true[:, i], y_pred_one_hot[:, i]) for i in range(3)]\n",
        "\n",
        "    # Average F1 scores across all classes\n",
        "    return K.mean(K.stack(f1s), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg1CDkjb7IPk"
      },
      "source": [
        "Set up call backs and learning rates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FW38TVTK7IPk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "\n",
        "# Define the EarlyStopping and ReduceLROnPlateau callbacks\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_path = \"roberta_best_model.h5\"\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,    # Only save a model if 'val_loss' has improved\n",
        "    monitor='val_loss',     # Monitor 'val_loss' during training\n",
        "    mode='min',             # The model is saved when 'val_loss' is minimized\n",
        "    verbose=1)\n",
        "\n",
        "# Combine all callbacks in a list\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "    model_checkpoint_callback\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ba5UUffQ7IPl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Flatten, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "# import keras_tuner as kt\n",
        "from transformers import TFRobertaModel\n",
        "\n",
        "def build_model(drop, regr, lr):\n",
        "    bert_model = TFRobertaModel.from_pretrained('roberta-base')\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    # Define model input (BERT expects two inputs: input_ids and attention_mask)\n",
        "    input_ids = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='input_ids')\n",
        "    attention_mask = Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='attention_mask')\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    bert_output = bert_model(input_ids, attention_mask=attention_mask)[0]  # Use the pooled output here\n",
        "\n",
        "    # Tuning the number of units in the first biLSTM layer\n",
        "    x = Bidirectional(LSTM(units=64,  dropout=drop, recurrent_dropout=drop,return_sequences=True,kernel_regularizer=tf.keras.regularizers.l2(regr))) (bert_output)\n",
        "\n",
        "    x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "    # Dense layer with tunable units\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(regr)) (x)\n",
        "\n",
        "    # Tunable dropout rate for the second layer\n",
        "    x = Dropout(drop)(x)\n",
        "\n",
        "    # Final Layer\n",
        "    x = Dense(3, activation='softmax')(x)\n",
        "\n",
        "    # Tuning the learning rate for the optimizer\n",
        "    optimizer = Adam(learning_rate=lr)\n",
        "    model = Model(inputs=[input_ids, attention_mask], outputs=x)\n",
        "    model.compile(loss='CategoricalCrossentropy', optimizer=optimizer, metrics=['categorical_accuracy',f1_score])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMYLou_97IPl"
      },
      "source": [
        "Recreate the best model with more training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn9_Rfyp7IPl",
        "outputId": "a26f46a8-ab9e-40f3-f8cb-f9184ed287c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
            "                                                                                                  \n",
            " attention_mask (InputLayer  [(None, 128)]                0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf_roberta_model_1 (TFRobe  TFBaseModelOutputWithPooli   1246456   ['input_ids[0][0]',           \n",
            " rtaModel)                   ngAndCrossAttentions(last_   32         'attention_mask[0][0]']      \n",
            "                             hidden_state=(None, 128, 7                                           \n",
            "                             68),                                                                 \n",
            "                              pooler_output=(None, 768)                                           \n",
            "                             , past_key_values=None, hi                                           \n",
            "                             dden_states=None, attentio                                           \n",
            "                             ns=None, cross_attentions=                                           \n",
            "                             None)                                                                \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, 128, 128)             426496    ['tf_roberta_model_1[0][0]']  \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " global_max_pooling1d (Glob  (None, 128)                  0         ['bidirectional[0][0]']       \n",
            " alMaxPooling1D)                                                                                  \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 128)                  16512     ['global_max_pooling1d[0][0]']\n",
            "                                                                                                  \n",
            " dropout_74 (Dropout)        (None, 128)                  0         ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 3)                    387       ['dropout_74[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 125089027 (477.18 MB)\n",
            "Trainable params: 443395 (1.69 MB)\n",
            "Non-trainable params: 124645632 (475.49 MB)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.5776 - categorical_accuracy: 0.4048 - f1_score: 0.3124\n",
            "Epoch 1: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 45s 1s/step - loss: 1.5776 - categorical_accuracy: 0.4048 - f1_score: 0.3124 - val_loss: 1.4922 - val_categorical_accuracy: 0.4902 - val_f1_score: 0.2990 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4640 - categorical_accuracy: 0.4621 - f1_score: 0.2362\n",
            "Epoch 2: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.4640 - categorical_accuracy: 0.4621 - f1_score: 0.2362 - val_loss: 1.4511 - val_categorical_accuracy: 0.4962 - val_f1_score: 0.3000 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.4106 - categorical_accuracy: 0.4681 - f1_score: 0.2177\n",
            "Epoch 3: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.4106 - categorical_accuracy: 0.4681 - f1_score: 0.2177 - val_loss: 1.3979 - val_categorical_accuracy: 0.4766 - val_f1_score: 0.2194 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.3697 - categorical_accuracy: 0.4776 - f1_score: 0.2338\n",
            "Epoch 4: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.3697 - categorical_accuracy: 0.4776 - f1_score: 0.2338 - val_loss: 1.3570 - val_categorical_accuracy: 0.4781 - val_f1_score: 0.2234 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.3264 - categorical_accuracy: 0.4810 - f1_score: 0.2514\n",
            "Epoch 5: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.3264 - categorical_accuracy: 0.4810 - f1_score: 0.2514 - val_loss: 1.3217 - val_categorical_accuracy: 0.5234 - val_f1_score: 0.3377 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.2857 - categorical_accuracy: 0.4813 - f1_score: 0.2808\n",
            "Epoch 6: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.2857 - categorical_accuracy: 0.4813 - f1_score: 0.2808 - val_loss: 1.2938 - val_categorical_accuracy: 0.5505 - val_f1_score: 0.3914 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.2498 - categorical_accuracy: 0.4859 - f1_score: 0.2629\n",
            "Epoch 7: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.2498 - categorical_accuracy: 0.4859 - f1_score: 0.2629 - val_loss: 1.2621 - val_categorical_accuracy: 0.5354 - val_f1_score: 0.3794 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.2283 - categorical_accuracy: 0.4866 - f1_score: 0.3101\n",
            "Epoch 8: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.2283 - categorical_accuracy: 0.4866 - f1_score: 0.3101 - val_loss: 1.2177 - val_categorical_accuracy: 0.5490 - val_f1_score: 0.3955 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1964 - categorical_accuracy: 0.5025 - f1_score: 0.3382\n",
            "Epoch 9: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.1964 - categorical_accuracy: 0.5025 - f1_score: 0.3382 - val_loss: 1.1783 - val_categorical_accuracy: 0.5732 - val_f1_score: 0.4798 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1749 - categorical_accuracy: 0.5123 - f1_score: 0.3505\n",
            "Epoch 10: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.1749 - categorical_accuracy: 0.5123 - f1_score: 0.3505 - val_loss: 1.1624 - val_categorical_accuracy: 0.5611 - val_f1_score: 0.4676 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1519 - categorical_accuracy: 0.5168 - f1_score: 0.3932\n",
            "Epoch 11: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.1519 - categorical_accuracy: 0.5168 - f1_score: 0.3932 - val_loss: 1.1901 - val_categorical_accuracy: 0.4374 - val_f1_score: 0.3455 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1384 - categorical_accuracy: 0.5273 - f1_score: 0.3944\n",
            "Epoch 12: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.1384 - categorical_accuracy: 0.5273 - f1_score: 0.3944 - val_loss: 1.1011 - val_categorical_accuracy: 0.5596 - val_f1_score: 0.5136 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1238 - categorical_accuracy: 0.5292 - f1_score: 0.4237\n",
            "Epoch 13: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.1238 - categorical_accuracy: 0.5292 - f1_score: 0.4237 - val_loss: 1.1363 - val_categorical_accuracy: 0.5234 - val_f1_score: 0.4961 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.1128 - categorical_accuracy: 0.5285 - f1_score: 0.4006\n",
            "Epoch 14: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.1128 - categorical_accuracy: 0.5285 - f1_score: 0.4006 - val_loss: 1.0755 - val_categorical_accuracy: 0.5762 - val_f1_score: 0.5242 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0879 - categorical_accuracy: 0.5398 - f1_score: 0.4497\n",
            "Epoch 15: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.0879 - categorical_accuracy: 0.5398 - f1_score: 0.4497 - val_loss: 1.0620 - val_categorical_accuracy: 0.5701 - val_f1_score: 0.4745 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0781 - categorical_accuracy: 0.5417 - f1_score: 0.4324\n",
            "Epoch 16: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.0781 - categorical_accuracy: 0.5417 - f1_score: 0.4324 - val_loss: 1.0580 - val_categorical_accuracy: 0.5701 - val_f1_score: 0.5362 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0661 - categorical_accuracy: 0.5488 - f1_score: 0.4492\n",
            "Epoch 17: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0661 - categorical_accuracy: 0.5488 - f1_score: 0.4492 - val_loss: 1.0945 - val_categorical_accuracy: 0.4781 - val_f1_score: 0.4035 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0506 - categorical_accuracy: 0.5590 - f1_score: 0.4593\n",
            "Epoch 18: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0506 - categorical_accuracy: 0.5590 - f1_score: 0.4593 - val_loss: 1.0577 - val_categorical_accuracy: 0.5611 - val_f1_score: 0.4765 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0699 - categorical_accuracy: 0.5341 - f1_score: 0.4171\n",
            "Epoch 19: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0699 - categorical_accuracy: 0.5341 - f1_score: 0.4171 - val_loss: 1.0881 - val_categorical_accuracy: 0.5189 - val_f1_score: 0.5195 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0412 - categorical_accuracy: 0.5534 - f1_score: 0.4572\n",
            "Epoch 20: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0412 - categorical_accuracy: 0.5534 - f1_score: 0.4572 - val_loss: 1.0642 - val_categorical_accuracy: 0.5505 - val_f1_score: 0.4927 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0310 - categorical_accuracy: 0.5602 - f1_score: 0.4681\n",
            "Epoch 21: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0310 - categorical_accuracy: 0.5602 - f1_score: 0.4681 - val_loss: 1.1276 - val_categorical_accuracy: 0.4676 - val_f1_score: 0.4488 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0204 - categorical_accuracy: 0.5681 - f1_score: 0.4860\n",
            "Epoch 22: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.0204 - categorical_accuracy: 0.5681 - f1_score: 0.4860 - val_loss: 1.0223 - val_categorical_accuracy: 0.5551 - val_f1_score: 0.5440 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0254 - categorical_accuracy: 0.5692 - f1_score: 0.4825\n",
            "Epoch 23: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 1.0254 - categorical_accuracy: 0.5692 - f1_score: 0.4825 - val_loss: 1.0133 - val_categorical_accuracy: 0.5611 - val_f1_score: 0.5491 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.0062 - categorical_accuracy: 0.5786 - f1_score: 0.4952\n",
            "Epoch 24: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 1.0062 - categorical_accuracy: 0.5786 - f1_score: 0.4952 - val_loss: 1.0616 - val_categorical_accuracy: 0.5113 - val_f1_score: 0.5127 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9769 - categorical_accuracy: 0.5975 - f1_score: 0.5415\n",
            "Epoch 25: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.9769 - categorical_accuracy: 0.5975 - f1_score: 0.5415 - val_loss: 1.0170 - val_categorical_accuracy: 0.5656 - val_f1_score: 0.5527 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9887 - categorical_accuracy: 0.5960 - f1_score: 0.5393\n",
            "Epoch 26: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.9887 - categorical_accuracy: 0.5960 - f1_score: 0.5393 - val_loss: 1.0003 - val_categorical_accuracy: 0.5792 - val_f1_score: 0.5535 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9785 - categorical_accuracy: 0.5979 - f1_score: 0.5430\n",
            "Epoch 27: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9785 - categorical_accuracy: 0.5979 - f1_score: 0.5430 - val_loss: 1.0116 - val_categorical_accuracy: 0.5897 - val_f1_score: 0.5484 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9805 - categorical_accuracy: 0.5964 - f1_score: 0.5320\n",
            "Epoch 28: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.9805 - categorical_accuracy: 0.5964 - f1_score: 0.5320 - val_loss: 0.9864 - val_categorical_accuracy: 0.6109 - val_f1_score: 0.6003 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9745 - categorical_accuracy: 0.5968 - f1_score: 0.5363\n",
            "Epoch 29: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.9745 - categorical_accuracy: 0.5968 - f1_score: 0.5363 - val_loss: 0.9796 - val_categorical_accuracy: 0.5641 - val_f1_score: 0.5422 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9691 - categorical_accuracy: 0.5994 - f1_score: 0.5555\n",
            "Epoch 30: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9691 - categorical_accuracy: 0.5994 - f1_score: 0.5555 - val_loss: 1.0096 - val_categorical_accuracy: 0.5234 - val_f1_score: 0.5207 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9426 - categorical_accuracy: 0.6262 - f1_score: 0.5774\n",
            "Epoch 31: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9426 - categorical_accuracy: 0.6262 - f1_score: 0.5774 - val_loss: 0.9715 - val_categorical_accuracy: 0.5777 - val_f1_score: 0.5789 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9528 - categorical_accuracy: 0.6213 - f1_score: 0.5727\n",
            "Epoch 32: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9528 - categorical_accuracy: 0.6213 - f1_score: 0.5727 - val_loss: 0.9464 - val_categorical_accuracy: 0.6139 - val_f1_score: 0.6021 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9550 - categorical_accuracy: 0.6122 - f1_score: 0.5683\n",
            "Epoch 33: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9550 - categorical_accuracy: 0.6122 - f1_score: 0.5683 - val_loss: 0.9528 - val_categorical_accuracy: 0.5973 - val_f1_score: 0.5910 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9287 - categorical_accuracy: 0.6235 - f1_score: 0.5746\n",
            "Epoch 34: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9287 - categorical_accuracy: 0.6235 - f1_score: 0.5746 - val_loss: 0.9706 - val_categorical_accuracy: 0.6003 - val_f1_score: 0.5786 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9395 - categorical_accuracy: 0.6145 - f1_score: 0.5655\n",
            "Epoch 35: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9395 - categorical_accuracy: 0.6145 - f1_score: 0.5655 - val_loss: 0.9606 - val_categorical_accuracy: 0.6048 - val_f1_score: 0.5987 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9420 - categorical_accuracy: 0.6183 - f1_score: 0.5751\n",
            "Epoch 36: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9420 - categorical_accuracy: 0.6183 - f1_score: 0.5751 - val_loss: 0.9205 - val_categorical_accuracy: 0.6018 - val_f1_score: 0.5904 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9096 - categorical_accuracy: 0.6371 - f1_score: 0.5892\n",
            "Epoch 37: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9096 - categorical_accuracy: 0.6371 - f1_score: 0.5892 - val_loss: 0.9589 - val_categorical_accuracy: 0.6094 - val_f1_score: 0.6186 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9289 - categorical_accuracy: 0.6220 - f1_score: 0.5750\n",
            "Epoch 38: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9289 - categorical_accuracy: 0.6220 - f1_score: 0.5750 - val_loss: 0.9248 - val_categorical_accuracy: 0.6124 - val_f1_score: 0.5979 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9107 - categorical_accuracy: 0.6367 - f1_score: 0.5919\n",
            "Epoch 39: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9107 - categorical_accuracy: 0.6367 - f1_score: 0.5919 - val_loss: 0.9272 - val_categorical_accuracy: 0.6078 - val_f1_score: 0.6041 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9211 - categorical_accuracy: 0.6281 - f1_score: 0.5883\n",
            "Epoch 40: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9211 - categorical_accuracy: 0.6281 - f1_score: 0.5883 - val_loss: 0.9590 - val_categorical_accuracy: 0.5686 - val_f1_score: 0.5330 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.9283 - categorical_accuracy: 0.6337 - f1_score: 0.5804\n",
            "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "\n",
            "Epoch 41: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.9283 - categorical_accuracy: 0.6337 - f1_score: 0.5804 - val_loss: 0.9347 - val_categorical_accuracy: 0.6094 - val_f1_score: 0.6203 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8968 - categorical_accuracy: 0.6428 - f1_score: 0.6136\n",
            "Epoch 42: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8968 - categorical_accuracy: 0.6428 - f1_score: 0.6136 - val_loss: 0.9048 - val_categorical_accuracy: 0.6199 - val_f1_score: 0.6009 - lr: 2.0000e-04\n",
            "Epoch 43/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8831 - categorical_accuracy: 0.6458 - f1_score: 0.6088\n",
            "Epoch 43: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8831 - categorical_accuracy: 0.6458 - f1_score: 0.6088 - val_loss: 0.8962 - val_categorical_accuracy: 0.6199 - val_f1_score: 0.6021 - lr: 2.0000e-04\n",
            "Epoch 44/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8835 - categorical_accuracy: 0.6620 - f1_score: 0.6277\n",
            "Epoch 44: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8835 - categorical_accuracy: 0.6620 - f1_score: 0.6277 - val_loss: 0.8961 - val_categorical_accuracy: 0.6169 - val_f1_score: 0.6093 - lr: 2.0000e-04\n",
            "Epoch 45/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8783 - categorical_accuracy: 0.6552 - f1_score: 0.6228\n",
            "Epoch 45: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8783 - categorical_accuracy: 0.6552 - f1_score: 0.6228 - val_loss: 0.8991 - val_categorical_accuracy: 0.6169 - val_f1_score: 0.6199 - lr: 2.0000e-04\n",
            "Epoch 46/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8707 - categorical_accuracy: 0.6613 - f1_score: 0.6292\n",
            "Epoch 46: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 21s 1s/step - loss: 0.8707 - categorical_accuracy: 0.6613 - f1_score: 0.6292 - val_loss: 0.9071 - val_categorical_accuracy: 0.6169 - val_f1_score: 0.6120 - lr: 2.0000e-04\n",
            "Epoch 47/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8625 - categorical_accuracy: 0.6677 - f1_score: 0.6342\n",
            "Epoch 47: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8625 - categorical_accuracy: 0.6677 - f1_score: 0.6342 - val_loss: 0.8952 - val_categorical_accuracy: 0.6214 - val_f1_score: 0.6219 - lr: 2.0000e-04\n",
            "Epoch 48/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8715 - categorical_accuracy: 0.6567 - f1_score: 0.6236\n",
            "Epoch 48: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 21s 1s/step - loss: 0.8715 - categorical_accuracy: 0.6567 - f1_score: 0.6236 - val_loss: 0.9001 - val_categorical_accuracy: 0.6259 - val_f1_score: 0.6327 - lr: 2.0000e-04\n",
            "Epoch 49/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8592 - categorical_accuracy: 0.6688 - f1_score: 0.6392\n",
            "Epoch 49: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8592 - categorical_accuracy: 0.6688 - f1_score: 0.6392 - val_loss: 0.9109 - val_categorical_accuracy: 0.6275 - val_f1_score: 0.6336 - lr: 2.0000e-04\n",
            "Epoch 50/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8774 - categorical_accuracy: 0.6488 - f1_score: 0.6212\n",
            "Epoch 50: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 21s 1s/step - loss: 0.8774 - categorical_accuracy: 0.6488 - f1_score: 0.6212 - val_loss: 0.9004 - val_categorical_accuracy: 0.6109 - val_f1_score: 0.6167 - lr: 2.0000e-04\n",
            "Epoch 51/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8536 - categorical_accuracy: 0.6582 - f1_score: 0.6260\n",
            "Epoch 51: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 21s 1s/step - loss: 0.8536 - categorical_accuracy: 0.6582 - f1_score: 0.6260 - val_loss: 0.8968 - val_categorical_accuracy: 0.6184 - val_f1_score: 0.6249 - lr: 2.0000e-04\n",
            "Epoch 52/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8630 - categorical_accuracy: 0.6624 - f1_score: 0.6327\n",
            "Epoch 52: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "\n",
            "Epoch 52: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8630 - categorical_accuracy: 0.6624 - f1_score: 0.6327 - val_loss: 0.8966 - val_categorical_accuracy: 0.6139 - val_f1_score: 0.6172 - lr: 2.0000e-04\n",
            "Epoch 53/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8441 - categorical_accuracy: 0.6718 - f1_score: 0.6396\n",
            "Epoch 53: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8441 - categorical_accuracy: 0.6718 - f1_score: 0.6396 - val_loss: 0.9004 - val_categorical_accuracy: 0.6154 - val_f1_score: 0.6230 - lr: 4.0000e-05\n",
            "Epoch 54/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8482 - categorical_accuracy: 0.6605 - f1_score: 0.6309\n",
            "Epoch 54: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8482 - categorical_accuracy: 0.6605 - f1_score: 0.6309 - val_loss: 0.9093 - val_categorical_accuracy: 0.6139 - val_f1_score: 0.6211 - lr: 4.0000e-05\n",
            "Epoch 55/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8570 - categorical_accuracy: 0.6631 - f1_score: 0.6320\n",
            "Epoch 55: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8570 - categorical_accuracy: 0.6631 - f1_score: 0.6320 - val_loss: 0.9021 - val_categorical_accuracy: 0.6244 - val_f1_score: 0.6340 - lr: 4.0000e-05\n",
            "Epoch 56/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8444 - categorical_accuracy: 0.6594 - f1_score: 0.6286\n",
            "Epoch 56: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 22s 1s/step - loss: 0.8444 - categorical_accuracy: 0.6594 - f1_score: 0.6286 - val_loss: 0.8974 - val_categorical_accuracy: 0.6184 - val_f1_score: 0.6267 - lr: 4.0000e-05\n",
            "Epoch 57/100\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.8606 - categorical_accuracy: 0.6545 - f1_score: 0.6234Restoring model weights from the end of the best epoch: 47.\n",
            "\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\n",
            "Epoch 57: saving model to roberta_best_model.h5\n",
            "21/21 [==============================] - 23s 1s/step - loss: 0.8606 - categorical_accuracy: 0.6545 - f1_score: 0.6234 - val_loss: 0.9028 - val_categorical_accuracy: 0.6199 - val_f1_score: 0.6284 - lr: 4.0000e-05\n",
            "Epoch 57: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = {}\n",
        "inital_model = build_model(0.8, 0.0005, 0.001)\n",
        "history['tuned_stance_model_custom'] = inital_model.fit([train_input_ids, train_attention_masks], train_labels,\n",
        "                    epochs=100,\n",
        "                    validation_data=([val_input_ids, val_attention_masks], val_labels),\n",
        "                    batch_size=128,\n",
        "                    callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p8ahqNJ9JA4",
        "outputId": "e18822bc-0a58-41ab-8b6b-4402016c5c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 10s 160ms/step - loss: 0.9728 - categorical_accuracy: 0.5757 - f1_score: 0.4095\n",
            "Test accuracy: [0.9727636575698853, 0.5756646394729614, 0.4095032811164856]\n"
          ]
        }
      ],
      "source": [
        "results = inital_model.evaluate([test_input_ids, test_attention_masks], test_labels)\n",
        "print('Test accuracy:', results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioai3mLD9Pza",
        "outputId": "d9ca1ed9-3958-494c-cb04-3a1055be85ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 13s 158ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.60      0.64      1014\n",
            "           1       0.60      0.38      0.46       452\n",
            "           2       0.43      0.71      0.54       490\n",
            "\n",
            "    accuracy                           0.58      1956\n",
            "   macro avg       0.58      0.56      0.55      1956\n",
            "weighted avg       0.61      0.58      0.58      1956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "predictions = inital_model.predict([test_input_ids, test_attention_masks])\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels are one-hot encoded, convert them to class labels\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0BO_wLOUiGjY"
      },
      "outputs": [],
      "source": [
        "def load_classification_rp_per_target(model):\n",
        "    targets = test_df.Target.unique()\n",
        "    metrics_df = pd.DataFrame()\n",
        "    for target in targets:\n",
        "        extracted_df = test_df[test_df['Target'] == target]\n",
        "        input_ids, attention_masks = bert_tokenize(extracted_df['Tweet'], extracted_df['Target'].to_list())\n",
        "        labels = categorized_label(extracted_df, \"Stance\")\n",
        "\n",
        "        # Convert one-hot encoded labels to single integer class labels\n",
        "        true_labels = np.argmax(labels, axis=1)\n",
        "\n",
        "        # Get model predictions\n",
        "        predictions = model.predict([input_ids, attention_masks])\n",
        "\n",
        "        # Convert predictions to class labels\n",
        "        predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "        # Generate a classification report\n",
        "        report = classification_report(true_labels, predicted_labels, target_names=['AGAINST', 'FAVOR', 'NONE'])\n",
        "        target_name = \"\"\n",
        "        if target == 0:\n",
        "            target_name = \"Hillary Clinton\"\n",
        "        if target == 1:\n",
        "            target_name = \"Legalization of Abortion\"\n",
        "        if target == 2:\n",
        "            target_name = \"Atheism\"\n",
        "        if target == 3:\n",
        "            target_name = \"Climate Change is a Real Concern\"\n",
        "        if target == 4:\n",
        "            target_name = \"Feminist Movement\"\n",
        "        if target == 5:\n",
        "            target_name = \"Donald Trump\"\n",
        "\n",
        "        print('Target: ', target_name)\n",
        "        print(report)\n",
        "        print(\"-----------------------------------------\", \"\\n\")\n",
        "\n",
        "        # Flatten the report into a single row and add target name\n",
        "        report = classification_report(true_labels, predicted_labels, target_names=['AGAINST', 'FAVOR', 'NONE'], output_dict=True)\n",
        "\n",
        "        # Extract weighted f1, macro f1, and accuracy\n",
        "        report_data = {\n",
        "            'Target': target_name,\n",
        "            'Weighted F1': report['weighted avg']['f1-score'],\n",
        "            'Macro F1': report['macro avg']['f1-score'],\n",
        "            'Accuracy': report['accuracy']\n",
        "        }\n",
        "\n",
        "        # Append to the DataFrame\n",
        "        metrics_df = metrics_df.append(report_data, ignore_index=True)\n",
        "    metrics_df.set_index('Target', inplace=True)\n",
        "\n",
        "    return metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h-UGgHLpivYn",
        "outputId": "b9f91784-4b6a-421d-9fbc-068b0fa5ee1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 1s 160ms/step\n",
            "Target:  Atheism\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.78      0.86      0.82       160\n",
            "       FAVOR       0.40      0.06      0.11        32\n",
            "        NONE       0.41      0.57      0.48        28\n",
            "\n",
            "    accuracy                           0.70       220\n",
            "   macro avg       0.53      0.50      0.47       220\n",
            "weighted avg       0.68      0.70      0.67       220\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 144ms/step\n",
            "Target:  Climate Change is a Real Concern\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.82      0.83      0.83       123\n",
            "        NONE       0.49      0.63      0.55        35\n",
            "\n",
            "    accuracy                           0.73       169\n",
            "   macro avg       0.44      0.49      0.46       169\n",
            "weighted avg       0.70      0.73      0.72       169\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 157ms/step\n",
            "Target:  Feminist Movement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.68      0.70       183\n",
            "       FAVOR       0.35      0.41      0.38        58\n",
            "        NONE       0.45      0.45      0.45        44\n",
            "\n",
            "    accuracy                           0.59       285\n",
            "   macro avg       0.51      0.52      0.51       285\n",
            "weighted avg       0.61      0.59      0.60       285\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 152ms/step\n",
            "Target:  Hillary Clinton\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.69      0.80      0.74       172\n",
            "       FAVOR       0.45      0.38      0.41        45\n",
            "        NONE       0.63      0.46      0.53        78\n",
            "\n",
            "    accuracy                           0.65       295\n",
            "   macro avg       0.59      0.55      0.56       295\n",
            "weighted avg       0.64      0.65      0.64       295\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 156ms/step\n",
            "Target:  Legalization of Abortion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.79      0.70      0.74       189\n",
            "       FAVOR       0.45      0.20      0.27        46\n",
            "        NONE       0.40      0.82      0.54        45\n",
            "\n",
            "    accuracy                           0.64       280\n",
            "   macro avg       0.55      0.57      0.52       280\n",
            "weighted avg       0.67      0.64      0.63       280\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 4s 155ms/step\n",
            "Target:  Donald Trump\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.48      0.26      0.34       299\n",
            "       FAVOR       0.59      0.11      0.19       148\n",
            "        NONE       0.41      0.83      0.55       260\n",
            "\n",
            "    accuracy                           0.44       707\n",
            "   macro avg       0.49      0.40      0.36       707\n",
            "weighted avg       0.48      0.44      0.39       707\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Weighted F1  Macro F1  Accuracy\n",
              "Target                                                           \n",
              "Atheism                              0.669585  0.467065  0.704545\n",
              "Climate Change is a Real Concern     0.715012  0.458637  0.733728\n",
              "Feminist Movement                    0.598619  0.512582  0.592982\n",
              "Hillary Clinton                      0.636090  0.561636  0.647458\n",
              "Legalization of Abortion             0.631547  0.516844  0.635714\n",
              "Donald Trump                         0.385409  0.360108  0.437058"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1295e22-6aa4-4a9b-8607-a9877a85f4da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>0.669585</td>\n",
              "      <td>0.467065</td>\n",
              "      <td>0.704545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>0.715012</td>\n",
              "      <td>0.458637</td>\n",
              "      <td>0.733728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>0.598619</td>\n",
              "      <td>0.512582</td>\n",
              "      <td>0.592982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>0.636090</td>\n",
              "      <td>0.561636</td>\n",
              "      <td>0.647458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>0.631547</td>\n",
              "      <td>0.516844</td>\n",
              "      <td>0.635714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>0.385409</td>\n",
              "      <td>0.360108</td>\n",
              "      <td>0.437058</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1295e22-6aa4-4a9b-8607-a9877a85f4da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d1295e22-6aa4-4a9b-8607-a9877a85f4da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d1295e22-6aa4-4a9b-8607-a9877a85f4da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1e6f9205-530d-4ef0-a81b-8a4af1bcc75c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1e6f9205-530d-4ef0-a81b-8a4af1bcc75c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1e6f9205-530d-4ef0-a81b-8a4af1bcc75c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8a7077d5-8b48-42c1-b87c-2fd9d42c37fe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8a7077d5-8b48-42c1-b87c-2fd9d42c37fe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Use the function to get the metrics DataFrame\n",
        "model_metrics_df = load_classification_rp_per_target(inital_model)\n",
        "model_metrics_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcCRugBtjsz1"
      },
      "source": [
        "[4] Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBRlPb3ljy18",
        "outputId": "869f8d79-5797-4e4f-83fa-313a87a5f6b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_1/roberta/pooler/dense/kernel:0', 'tf_roberta_model_1/roberta/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "83/83 [==============================] - ETA: 0s - loss: 0.8980 - categorical_accuracy: 0.6420 - f1_score: 0.5881\n",
            "Epoch 1: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 99s 949ms/step - loss: 0.8980 - categorical_accuracy: 0.6420 - f1_score: 0.5881 - val_loss: 0.8469 - val_categorical_accuracy: 0.6456 - val_f1_score: 0.6413 - lr: 1.0000e-05\n",
            "Epoch 2/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.8114 - categorical_accuracy: 0.6835 - f1_score: 0.6498\n",
            "Epoch 2: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 75s 910ms/step - loss: 0.8114 - categorical_accuracy: 0.6835 - f1_score: 0.6498 - val_loss: 0.8080 - val_categorical_accuracy: 0.6757 - val_f1_score: 0.6563 - lr: 1.0000e-05\n",
            "Epoch 3/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7494 - categorical_accuracy: 0.7126 - f1_score: 0.6881\n",
            "Epoch 3: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 75s 901ms/step - loss: 0.7494 - categorical_accuracy: 0.7126 - f1_score: 0.6881 - val_loss: 0.8143 - val_categorical_accuracy: 0.6637 - val_f1_score: 0.6413 - lr: 1.0000e-05\n",
            "Epoch 4/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.7608 - categorical_accuracy: 0.7092 - f1_score: 0.6763\n",
            "Epoch 4: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 75s 902ms/step - loss: 0.7608 - categorical_accuracy: 0.7092 - f1_score: 0.6763 - val_loss: 0.8093 - val_categorical_accuracy: 0.6546 - val_f1_score: 0.6327 - lr: 1.0000e-05\n",
            "Epoch 5/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6921 - categorical_accuracy: 0.7405 - f1_score: 0.7120\n",
            "Epoch 5: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 898ms/step - loss: 0.6921 - categorical_accuracy: 0.7405 - f1_score: 0.7120 - val_loss: 0.8116 - val_categorical_accuracy: 0.6652 - val_f1_score: 0.6578 - lr: 1.0000e-05\n",
            "Epoch 6/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6247 - categorical_accuracy: 0.7895 - f1_score: 0.7710\n",
            "Epoch 6: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 75s 908ms/step - loss: 0.6247 - categorical_accuracy: 0.7895 - f1_score: 0.7710 - val_loss: 0.7766 - val_categorical_accuracy: 0.6983 - val_f1_score: 0.6844 - lr: 1.0000e-05\n",
            "Epoch 7/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.6067 - categorical_accuracy: 0.8001 - f1_score: 0.7823\n",
            "Epoch 7: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 894ms/step - loss: 0.6067 - categorical_accuracy: 0.8001 - f1_score: 0.7823 - val_loss: 0.8312 - val_categorical_accuracy: 0.6953 - val_f1_score: 0.6807 - lr: 1.0000e-05\n",
            "Epoch 8/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5496 - categorical_accuracy: 0.8208 - f1_score: 0.8070\n",
            "Epoch 8: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 898ms/step - loss: 0.5496 - categorical_accuracy: 0.8208 - f1_score: 0.8070 - val_loss: 0.8470 - val_categorical_accuracy: 0.6787 - val_f1_score: 0.6717 - lr: 1.0000e-05\n",
            "Epoch 9/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.5222 - categorical_accuracy: 0.8344 - f1_score: 0.8268\n",
            "Epoch 9: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 887ms/step - loss: 0.5222 - categorical_accuracy: 0.8344 - f1_score: 0.8268 - val_loss: 0.8478 - val_categorical_accuracy: 0.6878 - val_f1_score: 0.6900 - lr: 1.0000e-05\n",
            "Epoch 10/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4912 - categorical_accuracy: 0.8442 - f1_score: 0.8350\n",
            "Epoch 10: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 896ms/step - loss: 0.4912 - categorical_accuracy: 0.8442 - f1_score: 0.8350 - val_loss: 0.8862 - val_categorical_accuracy: 0.6863 - val_f1_score: 0.6749 - lr: 1.0000e-05\n",
            "Epoch 11/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4486 - categorical_accuracy: 0.8736 - f1_score: 0.8687\n",
            "Epoch 11: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 895ms/step - loss: 0.4486 - categorical_accuracy: 0.8736 - f1_score: 0.8687 - val_loss: 0.8562 - val_categorical_accuracy: 0.7029 - val_f1_score: 0.6997 - lr: 1.0000e-05\n",
            "Epoch 12/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.4202 - categorical_accuracy: 0.8910 - f1_score: 0.8800\n",
            "Epoch 12: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 896ms/step - loss: 0.4202 - categorical_accuracy: 0.8910 - f1_score: 0.8800 - val_loss: 0.8572 - val_categorical_accuracy: 0.7059 - val_f1_score: 0.6971 - lr: 1.0000e-05\n",
            "Epoch 13/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3854 - categorical_accuracy: 0.9008 - f1_score: 0.8936\n",
            "Epoch 13: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 896ms/step - loss: 0.3854 - categorical_accuracy: 0.9008 - f1_score: 0.8936 - val_loss: 0.8979 - val_categorical_accuracy: 0.6998 - val_f1_score: 0.6869 - lr: 1.0000e-05\n",
            "Epoch 14/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3832 - categorical_accuracy: 0.9023 - f1_score: 0.8966\n",
            "Epoch 14: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 894ms/step - loss: 0.3832 - categorical_accuracy: 0.9023 - f1_score: 0.8966 - val_loss: 0.8688 - val_categorical_accuracy: 0.6968 - val_f1_score: 0.6898 - lr: 1.0000e-05\n",
            "Epoch 15/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3467 - categorical_accuracy: 0.9166 - f1_score: 0.9121\n",
            "Epoch 15: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 74s 897ms/step - loss: 0.3467 - categorical_accuracy: 0.9166 - f1_score: 0.9121 - val_loss: 0.9463 - val_categorical_accuracy: 0.7164 - val_f1_score: 0.7005 - lr: 1.0000e-05\n",
            "Epoch 16/30\n",
            "83/83 [==============================] - ETA: 0s - loss: 0.3276 - categorical_accuracy: 0.9332 - f1_score: 0.9248Restoring model weights from the end of the best epoch: 6.\n",
            "\n",
            "Epoch 16: saving model to roberta_best_model.h5\n",
            "83/83 [==============================] - 75s 905ms/step - loss: 0.3276 - categorical_accuracy: 0.9332 - f1_score: 0.9248 - val_loss: 0.9555 - val_categorical_accuracy: 0.7149 - val_f1_score: 0.7085 - lr: 1.0000e-05\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ],
      "source": [
        "for layer in inital_model.layers:\n",
        "    layer.trainable = True\n",
        "   # Tuning the learning rate for the optimizer\n",
        "inital_model.compile(optimizer=tf.keras.optimizers.legacy.Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['categorical_accuracy', f1_score])\n",
        "\n",
        "history['fine_tuned_bert'] = inital_model.fit([train_input_ids, train_attention_masks], train_labels,\n",
        "                    epochs=30,\n",
        "                    validation_data=([val_input_ids, val_attention_masks], val_labels),\n",
        "                    batch_size=32,\n",
        "                    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WAOA3PAJoSuU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73051bea-87e8-44d0-dcd0-b99387d1875d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 4s 158ms/step\n",
            "Target:  Atheism\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.83      0.84      0.84       160\n",
            "       FAVOR       0.45      0.31      0.37        32\n",
            "        NONE       0.53      0.68      0.59        28\n",
            "\n",
            "    accuracy                           0.75       220\n",
            "   macro avg       0.61      0.61      0.60       220\n",
            "weighted avg       0.74      0.75      0.74       220\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 147ms/step\n",
            "Target:  Climate Change is a Real Concern\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.88      0.85      0.87       123\n",
            "        NONE       0.60      0.83      0.70        35\n",
            "\n",
            "    accuracy                           0.79       169\n",
            "   macro avg       0.50      0.56      0.52       169\n",
            "weighted avg       0.77      0.79      0.78       169\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 155ms/step\n",
            "Target:  Feminist Movement\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.64      0.72       183\n",
            "       FAVOR       0.44      0.66      0.52        58\n",
            "        NONE       0.52      0.64      0.57        44\n",
            "\n",
            "    accuracy                           0.65       285\n",
            "   macro avg       0.59      0.65      0.61       285\n",
            "weighted avg       0.70      0.65      0.66       285\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 151ms/step\n",
            "Target:  Hillary Clinton\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.85      0.80       172\n",
            "       FAVOR       0.68      0.56      0.61        45\n",
            "        NONE       0.77      0.63      0.69        78\n",
            "\n",
            "    accuracy                           0.75       295\n",
            "   macro avg       0.73      0.68      0.70       295\n",
            "weighted avg       0.75      0.75      0.74       295\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 153ms/step\n",
            "Target:  Legalization of Abortion\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.83      0.76      0.79       189\n",
            "       FAVOR       0.53      0.41      0.46        46\n",
            "        NONE       0.51      0.80      0.62        45\n",
            "\n",
            "    accuracy                           0.71       280\n",
            "   macro avg       0.62      0.66      0.62       280\n",
            "weighted avg       0.73      0.71      0.71       280\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 4s 155ms/step\n",
            "Target:  Donald Trump\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.46      0.28      0.35       299\n",
            "       FAVOR       0.75      0.22      0.34       148\n",
            "        NONE       0.44      0.82      0.57       260\n",
            "\n",
            "    accuracy                           0.47       707\n",
            "   macro avg       0.55      0.44      0.42       707\n",
            "weighted avg       0.52      0.47      0.43       707\n",
            "\n",
            "----------------------------------------- \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-cdaa14f0a2b9>:50: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  metrics_df = metrics_df.append(report_data, ignore_index=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  Weighted F1  Macro F1  Accuracy\n",
              "Target                                                           \n",
              "Atheism                              0.739265  0.600877  0.745455\n",
              "Climate Change is a Real Concern     0.776292  0.522188  0.792899\n",
              "Feminist Movement                    0.658303  0.605760  0.645614\n",
              "Hillary Clinton                      0.743844  0.701059  0.749153\n",
              "Legalization of Abortion             0.709173  0.624720  0.707143\n",
              "Donald Trump                         0.430122  0.421726  0.465347"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac1d98d5-d258-4b53-a3a0-883b653b7229\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weighted F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>0.739265</td>\n",
              "      <td>0.600877</td>\n",
              "      <td>0.745455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>0.776292</td>\n",
              "      <td>0.522188</td>\n",
              "      <td>0.792899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>0.658303</td>\n",
              "      <td>0.605760</td>\n",
              "      <td>0.645614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>0.743844</td>\n",
              "      <td>0.701059</td>\n",
              "      <td>0.749153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>0.709173</td>\n",
              "      <td>0.624720</td>\n",
              "      <td>0.707143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Donald Trump</th>\n",
              "      <td>0.430122</td>\n",
              "      <td>0.421726</td>\n",
              "      <td>0.465347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac1d98d5-d258-4b53-a3a0-883b653b7229')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ac1d98d5-d258-4b53-a3a0-883b653b7229 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ac1d98d5-d258-4b53-a3a0-883b653b7229');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ec45678-c2ab-4a40-9fb5-911c0d11a5b1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ec45678-c2ab-4a40-9fb5-911c0d11a5b1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ec45678-c2ab-4a40-9fb5-911c0d11a5b1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7db470ef-a06c-4c68-9ef2-989141eb00ab\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('model_metrics_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7db470ef-a06c-4c68-9ef2-989141eb00ab button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('model_metrics_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Use the function to get the metrics DataFrame\n",
        "model_metrics_df = load_classification_rp_per_target(inital_model)\n",
        "model_metrics_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9YRDLteVolOe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3e771e5-099c-4c93-c13f-fb777e524aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62/62 [==============================] - 10s 156ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.62      0.67      1014\n",
            "           1       0.67      0.51      0.58       452\n",
            "           2       0.49      0.76      0.60       490\n",
            "\n",
            "    accuracy                           0.63      1956\n",
            "   macro avg       0.63      0.63      0.62      1956\n",
            "weighted avg       0.66      0.63      0.63      1956\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get model predictions\n",
        "predictions = inital_model.predict([test_input_ids, test_attention_masks])\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming test_labels are one-hot encoded, convert them to class labels\n",
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "byHt9y_SpOCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95a60879-1ad6-4e86-934b-d33081505a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "inital_model.save('roberta_model_66.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}